import os
import time
import argparse
import pandas as pd
from ctgan import CTGAN
from util_functions import extract_boolean_like_columns

def main(args):
    # 0. ê²½ë¡œ ì„¤ì •
    workload = args.workload  # ì˜ˆ: ycsb_AA
    multiplier = args.multiplier
    base_dir = f"../../../data/workloads/mysql/{workload}"
    knob_info_path = "../../../data/workloads/mysql/Knob_Information_MySQL_v5.7.csv"
    external_metrics_path = os.path.join(base_dir, "results", f"external_metrics_{workload.split('_')[1]}.csv")

    # 1. ë°ì´í„° ë¡œë“œ
    real_data = pd.read_csv(external_metrics_path)
    if 'Unnamed: 0' in real_data.columns:
        real_data.drop(columns=['Unnamed: 0'], inplace=True)

    # 2. Boolean knob ì¶”ì¶œ (type == boolean)
    discrete_columns = extract_boolean_like_columns(knob_info_path)

    # 3. CTGAN í•™ìŠµ
    print("[CTGAN] ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    ctgan = CTGAN(epochs=10)
    ctgan.fit(real_data, discrete_columns=discrete_columns)

    # 4. ì¦ê°• ë°ì´í„° ìƒì„±
    n_samples = len(real_data) * multiplier
    synthetic_data = ctgan.sample(n_samples)

    # 5. config vs metric ì»¬ëŸ¼ ë¶„ë¦¬
    knob_info = pd.read_csv(knob_info_path)
    knob_columns = [col for col in knob_info['name'].tolist() if col in synthetic_data.columns]
    metric_columns = ["tps", "latency"]

    # 6. ì €ì¥ ê²½ë¡œ ì„¤ì •
    config_save_dir = os.path.join(base_dir, "configs_augmented")
    result_save_path = os.path.join(base_dir, "results", f"augmented_external_metrics_{workload.split('_')[1]}_{multiplier}x.csv")
    os.makedirs(config_save_dir, exist_ok=True)
    os.makedirs(os.path.dirname(result_save_path), exist_ok=True)

    # 7. íŒŒì¼ ì €ì¥
    print("[SAVE] ì¦ê°•ëœ ë°ì´í„° ì €ì¥ ì¤‘...")
    performance_rows = []
    for idx, row in synthetic_data.iterrows():
        config_filename = f"my_{idx}.cnf"
        config_path = os.path.join(config_save_dir, config_filename)

        # .cnf íŒŒì¼ ì €ì¥
        with open(config_path, "w") as f:
            f.write("[mysqld]\n")
            for col in knob_columns:
                value = row[col]
                value = round(value, 6) if isinstance(value, float) else value
                f.write(f"{col} = {value}\n")

        # metrics ì €ì¥ìš©
        perf_data = {col: row[col] for col in metric_columns}
        perf_data["config_id"] = config_filename
        performance_rows.append(perf_data)

    # 8. ì„±ëŠ¥ ê²°ê³¼ ì €ì¥
    perf_df = pd.DataFrame(performance_rows)
    perf_df = perf_df[["config_id"] + metric_columns]
    perf_df.to_csv(result_save_path, index=False)

    # 9. ë¡œê·¸ ì¶œë ¥
    print(f"[âœ”] {n_samples}ê°œì˜ ì¦ê°• ìƒ˜í”Œ ì €ì¥ ì™„ë£Œ")
    print(f"[ğŸ’¾] ì„¤ì • íŒŒì¼ ê²½ë¡œ: {config_save_dir}")
    print(f"[ğŸ’¾] ì„±ëŠ¥ ê²°ê³¼ ê²½ë¡œ: {result_save_path}")

if __name__ == "__main__":
    print("[Start] CTGAN augmentation...")
    start_time = time.time()
    parser = argparse.ArgumentParser(description="CTGAN-based data augmentation for MySQL YCSB workload")
    parser.add_argument("--workload", type=str, default="ycsb_AA", help="Workload folder name (e.g., ycsb_AA)")
    parser.add_argument("--multiplier", type=int, default=5, help="How many times to augment the data (e.g., 5x)")
    args = parser.parse_args()
    main(args)
    print(f"[Finish] ì†Œìš” ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ")
