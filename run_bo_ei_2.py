import os
import torch
import re
import pandas as pd
import numpy as np
import ast
import joblib
from typing import Dict, Any, Optional, Tuple
import logging
import argparse
from dotenv import load_dotenv  # pip install python-dotenv
import openai
from tabulate import tabulate # For table logging
import csv

# BoTorch
from botorch.models.model import Model
from botorch.models import SingleTaskGP
from botorch.fit import fit_gpytorch_mll
from botorch.acquisition import UpperConfidenceBound, AcquisitionFunction, ExpectedImprovement
from botorch.optim import optimize_acqf
from gpytorch.mlls import ExactMarginalLogLikelihood
from botorch.exceptions import BadInitialCandidatesWarning
import warnings

# Scikit-learn
from sklearn.preprocessing import MinMaxScaler

# ì‚¬ìš©ì ì •ì˜ ëª¨ë“ˆ
from knob_dependency_score import DependencyScore
from LLM_expert import query_openai, parse_llm_response, build_dependency_prompt


load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
assistant_id = os.getenv("OPENAI_ASSISTANT_ID")
# ì¿¼ë¦¬ í˜¸ì¶œ í•¨ìˆ˜
openai.api_key = api_key


# --- ëª…ë ¹ì¤„ì¸ì ---
parser = argparse.ArgumentParser()

# logfile ì´ë¦„
parser.add_argument("--logfile", type=str, required=True)
# worklaod ì¢…ë¥˜ ì´ë¦„
parser.add_argument("--workload", type=str, required=True)
# dependency score parameter(ë¯¼ê°ë„ íŒŒë¼ë¯¸í„°, ê°’ì´ ì‘ì„ìˆ˜ë¡ ì™„ë§Œí•´ì§€ëŠ” ê·¸ë˜í”„, ë” ë¯¼ê°í•œ ì°¨ì´ë„ ì˜ ë°˜ì˜í•¨)
parser.add_argument("--alpha", type=float, required=True)
parser.add_argument("--beta", type=float, required=True)
parser.add_argument("--gamma", type=float, required=True)
# bayesian optimization iteration íšŸìˆ˜
parser.add_argument("--iter", type=int, required=True)

args = parser.parse_args()

# --- ë¡œê¹… ì„¤ì • ---
log_formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')
logger = logging.getLogger('BO_Logger')
logger.setLevel(logging.INFO) # ë¡œê·¸ ë ˆë²¨ ì„¤ì •

# íŒŒì¼ í•¸ë“¤ëŸ¬ ì„¤ì • (ì‹¤ì‹œê°„ ê¸°ë¡)
log_file_path = f'../../../data/bo_result/{args.logfile}.log'
file_handler = logging.FileHandler(log_file_path, mode='a', encoding = 'utf-8') # 'a' ëª¨ë“œë¡œ ì´ì–´ì“°ê¸°
file_handler.setFormatter(log_formatter)
# íŒŒì¼ í•¸ë“¤ëŸ¬ ì¶”ê°€ ì‹œ ì¦‰ì‹œ íŒŒì¼ì— ì“°ë„ë¡ ì„¤ì • (ë²„í¼ë§ ìµœì†Œí™”)
# Python 3.7+ ì—ì„œëŠ” FileHandlerê°€ ê¸°ë³¸ì ìœ¼ë¡œ ë²„í¼ë§í•˜ì§€ ì•ŠìŒ, ëª…ì‹œì  flush ë¶ˆí•„ìš”
logger.addHandler(file_handler)

warnings.filterwarnings("ignore", category=BadInitialCandidatesWarning)
warnings.filterwarnings("ignore", category=RuntimeWarning)

# --- 3. Log Parsed Arguments as a Table (ìˆ˜ì •ëœ ë°©ì‹) ---
logger.info("") # ë¡œê·¸ ì‹œì‘ ì „ ë¹ˆ ì¤„ ì¶”ê°€ (ì„ íƒ ì‚¬í•­)
logger.info("=" * 60)
logger.info("ğŸš€ Script Execution Started with Arguments:")
logger.info("=" * 60)

# Convert args namespace to dictionary
args_dict = vars(args)

# Create table string using tabulate
args_table = tabulate(args_dict.items(), headers=["Argument", "Value"], tablefmt="grid")

# <<< í•µì‹¬ ìˆ˜ì •: í…Œì´ë¸”ì„ í•œ ì¤„ì”© ë¡œê¹… >>>
for line in args_table.splitlines():
    logger.info(line)
# <<< ìˆ˜ì • ë >>>

logger.info("-" * 60)
logger.info("") # ë¡œê·¸ ëë‚œ í›„ ë¹ˆ ì¤„ ì¶”ê°€ (ì„ íƒ ì‚¬í•­)

# --- ì´ˆê¸° ì„¤ì • ë° ê²½ë¡œ ---
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
DTYPE = torch.double

# --- BO ì„¤ì • ---
PERFORMANCE_THRESHOLD = 1.1 # ì„±ëŠ¥ 10í”„ë¡œ ì´ìƒ í–¥ìƒ(1.1~1.3)
INITIAL_DEPENDENCY_WEIGHT = 1.0
RANDOM_STATE = 42
torch.manual_seed(RANDOM_STATE)

# --- ëª©ì  í•¨ìˆ˜ ê´€ë ¨ ì„¤ì • ---
TPS_METRIC_INDEX = 0 # 0: tps, 1: latency
LTC_METRIC_INDEX = 1
IS_MAXIMIZATION = True
N_ITERATIONS = args.iter

'''
# í•¨ìˆ˜ ì •ì˜
    ï¿® load_data_and_components: df, xgb_model, x_scaler, y_scaler, knob_names ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜
    ï¿® prepare_initial_data:  X(conf), Y(perf) ë°ì´í„° MinMaxScalingí•˜ëŠ” í•¨ìˆ˜
    ï¿® predict_performance_scaled: performance ì˜ˆì¸¡ê°’ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜(í•™ìŠµëœ xgboost ë¡œë“œ)
    ï¿® calculate_dependency_weight: knobê°„ì˜ dependency_score ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    ï¿® parse_llm_response: LLM output íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜(dependency_score í•¨ìˆ˜ì— ë„£ì„ ë§¤ê°œë³€ìˆ˜ íŒŒì‹±)
    ï¿® get_fitted_model: GP(surrogate model) ì—…ë°ì´íŠ¸ í•¨ìˆ˜
    ï¿® find_best_initial_point_scaled: ì´ˆê¸° ë°ì´í„°ì…‹ì¤‘ ê°€ì¥ ì„±ëŠ¥ ì¢‹ì€ ë°ì´í„° ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜(íƒìƒ‰ ì‹œì‘ì  ì„¤ì •)
    ï¿® select_random_initial_point_scaled: ì´ˆê¸° ë°ì´í„°ì…‹ì¤‘ ëœë¤ ë°ì´í„° ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜(íƒìƒ‰ ì‹œì‘ì  ì„¤ì •)
    ï¿® select_random_initial_point_scaled: ì´ˆê¸° ë°ì´í„°ì…‹ì¤‘ ëœë¤ ë°ì´í„° ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜(íƒìƒ‰ ì‹œì‘ì  ì„¤ì •)
    â—† DependencyWeightedAcquisitionFunction: ì»¤ìŠ¤í…€ Acquisition í•¨ìˆ˜ ì •ì˜ í´ë˜ìŠ¤
        ï¿®
        ï¿®
'''
global tps_importance
tps_importance = 2.0

def load_data_and_components(csv_path: str, model_path: str, x_scaler_path: str, y_scaler_path: str, knob_names_path: str) \
        -> Tuple[pd.DataFrame, Any, MinMaxScaler, MinMaxScaler, list]:
    """ë°ì´í„°, ëª¨ë¸, ìŠ¤ì¼€ì¼ëŸ¬, Knob ì´ë¦„ì„ ë¡œë“œ"""
    # ì´ì „ ë‹µë³€ê³¼ ë™ì¼
    logger.info("--- ë°ì´í„° ë° êµ¬ì„± ìš”ì†Œ ë¡œë”© ì‹œì‘ ---")
    try:
        df = pd.read_csv(csv_path)
        logger.info(f"âœ… CSV ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {csv_path} (Shape: {df.shape})")
        xgb_model = joblib.load(model_path)
        logger.info(f"âœ… XGBoost ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        x_scaler = joblib.load(x_scaler_path)
        logger.info(f"âœ… X Scaler ë¡œë“œ ì™„ë£Œ: {x_scaler_path}")
        y_scaler = joblib.load(y_scaler_path)
        logger.info(f"âœ… Y Scaler ë¡œë“œ ì™„ë£Œ: {y_scaler_path}")
        knob_names = joblib.load(knob_names_path)
        logger.info(f"âœ… Knob ì´ë¦„ ë¡œë“œ ì™„ë£Œ: {knob_names_path} ({len(knob_names)}ê°œ)")
        logger.info("--- ëª¨ë“  êµ¬ì„± ìš”ì†Œ ë¡œë”© ì„±ê³µ ---\n")
        return df, xgb_model, x_scaler, y_scaler, knob_names
    except FileNotFoundError as e: print(f"âŒ ì˜¤ë¥˜: í•„ìˆ˜ íŒŒì¼ ì—†ìŒ - {e}"); exit()
    except Exception as e: print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ ë¡œë”© ì¤‘ ë¬¸ì œ - {e}"); exit()

def prepare_initial_data(df: pd.DataFrame, knob_names: list, x_scaler: MinMaxScaler, y_scaler: MinMaxScaler) \
        -> Tuple[torch.Tensor, torch.Tensor, np.ndarray, np.ndarray]:
    """ë¡œë“œëœ Scalerë¡œ ì´ˆê¸° ë°ì´í„°ë¥¼ ìŠ¤ì¼€ì¼ë§í•˜ê³  í…ì„œ/ì›ë³¸ ë°°ì—´ ë°˜í™˜."""
    # ì´ì „ ë‹µë³€ê³¼ ë™ì¼
    logger.info("--- ì´ˆê¸° ë°ì´í„° ì¤€ë¹„ ì‹œì‘ ---")
    try:
        X_all = df[knob_names].values
        Y_all = df[['tps', 'latency']].values
        logger.info(f"ì›ë³¸ ë°ì´í„° Shape: X={X_all.shape}, Y={Y_all.shape}")
        scaled_X_all = x_scaler.transform(X_all)
        scaled_Y_all = y_scaler.transform(Y_all)
        logger.info("âœ… ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ ([0, 1] ë²”ìœ„)")
        logger.info(f"âœ… scaled_X_all: {scaled_X_all}")
        logger.info(f"âœ… scaled_Y_all: {scaled_Y_all}")

        epsilon = 1e-9
        scaled_scores = (tps_importance*scaled_Y_all[:, 0])/(scaled_Y_all[:, 1]+epsilon)  #shape: (N, )
        train_X = torch.tensor(scaled_X_all, device=DEVICE, dtype=DTYPE)
        train_Y = torch.tensor(scaled_scores, device=DEVICE, dtype=DTYPE).unsqueeze(-1)
        logger.info(f"ì´ˆê¸° í•™ìŠµ í…ì„œ ìƒì„± ì™„ë£Œ: train_X={train_X.shape}, train_Y={train_Y.shape}")
        logger.info("--- ì´ˆê¸° ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ ---\n")
        return train_X, train_Y, X_all, Y_all # ì›ë³¸ ë°°ì—´ë„ ë°˜í™˜
    except KeyError as e: logger.info(f"âŒ ì˜¤ë¥˜: CSV ì»¬ëŸ¼ ì—†ìŒ - {e}"); exit()
    except Exception as e: logger.info(f"âŒ ì˜¤ë¥˜: ì´ˆê¸° ë°ì´í„° ì¤€ë¹„ ì¤‘ ë¬¸ì œ - {e}"); exit()

# --- XGBoost ì˜ˆì¸¡ í•¨ìˆ˜ (ìŠ¤ì¼€ì¼ë§ëœ ì…ë ¥/ì¶œë ¥ ë²„ì „) ---
def predict_performance_scaled(scaled_input_np: np.ndarray, xgb_model: Any) \
        -> Optional[Dict[str, float]]:
    """
    ìŠ¤ì¼€ì¼ë§ëœ knob ì„¤ì •(scaled_input_np)ì„ ë°›ì•„ XGBoost ëª¨ë¸ë¡œ
    ìŠ¤ì¼€ì¼ë§ëœ ì„±ëŠ¥ {'scaled_tps': ..., 'scaled_latency': ...} ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
    """
    # ì…ë ¥ shape í™•ì¸ (1, DIM)
    if scaled_input_np.shape != (1, len(knob_names)):
         logger.info(f"âŒ ì˜¤ë¥˜: predict_performance_scaled ì…ë ¥ shape ì˜¤ë¥˜ - ê¸°ëŒ€: (1, {len(knob_names)}), ì‹¤ì œ: {scaled_input_np.shape}")
         return None

    # logger.info(f"--- ìŠ¤ì¼€ì¼ë§ëœ ì„±ëŠ¥ ì˜ˆì¸¡ ì‹œì‘ ---")
    try:
        # XGBoost ëª¨ë¸ ì˜ˆì¸¡ (ìŠ¤ì¼€ì¼ë§ëœ X ì…ë ¥ -> ìŠ¤ì¼€ì¼ë§ëœ Y ì¶œë ¥ ê°€ì •)
        scaled_predictions = xgb_model.predict(scaled_input_np) # shape (1, 2) ê°€ì •

        scaled_tps = scaled_predictions[0, 0]
        scaled_latency = scaled_predictions[0, 1]

        return {'scaled_tps': scaled_tps, 'scaled_latency': scaled_latency}

    except Exception as e:
        logger.info(f"âŒ ì˜¤ë¥˜: XGBoost ì˜ˆì¸¡ ì¤‘ ë¬¸ì œ ë°œìƒ - {e}")
        return None

# --- ì˜ì¡´ì„± ê°€ì¤‘ì¹˜ ê³„ì‚° í•¨ìˆ˜ ---
# ì…ë ¥: ì›ë³¸ ìŠ¤ì¼€ì¼ ê°’ë“¤, ë°˜í™˜: ê°€ì¤‘ì¹˜ (float)
def calculate_dependency_weight(
    prev_config_scaled: Optional[Dict[str, float]],
    prev_perf_scaled: Optional[Dict[str, float]],
    curr_config_scaled: Dict[str, float],
    curr_perf_scaled: Dict[str, float],
    knob_names: list
) -> float:

    weight = INITIAL_DEPENDENCY_WEIGHT
    if prev_perf_scaled is None or prev_config_scaled is None:
        logger.info("INFO: ì²« ë°˜ë³µ, ê¸°ë³¸ ê°€ì¤‘ì¹˜ 1.0 ì‚¬ìš©.")
        return weight

    # ì„±ëŠ¥ ë³€í™” ê³„ì‚° (ìŠ¤ì¼€ì¼ë§ëœ ê°’ ê¸°ì¤€)
    # í‚¤ ì´ë¦„ì´ 'scaled_tps', 'scaled_latency' ì„ì— ì£¼ì˜
    prev_latency_scaled = prev_perf_scaled.get('scaled_latency', 0)
    curr_latency_scaled = curr_perf_scaled.get('scaled_latency', 0)
    prev_tps_scaled = prev_perf_scaled.get('scaled_tps', 0)
    curr_tps_scaled = curr_perf_scaled.get('scaled_tps', 0)

    # ìŠ¤ì¼€ì¼ë§ëœ ê°’ìœ¼ë¡œ ì„±ëŠ¥ ë¹„ìœ¨ ê³„ì‚° (ì´ ë¹„êµ ë°©ì‹ì´ ìœ íš¨í•œì§€ í™•ì¸ í•„ìš”)
    # ì˜ˆë¥¼ ë“¤ì–´, latencyê°€ 0ì— ê°€ê¹Œì›Œì§€ë©´ ë¹„ìœ¨ì´ ë¶ˆì•ˆì •í•´ì§ˆ ìˆ˜ ìˆìŒ
    prev_metric = prev_tps_scaled / (prev_latency_scaled + 1e-9)
    curr_metric = curr_tps_scaled / (curr_latency_scaled + 1e-9)

    # ìŠ¤ì¼€ì¼ë§ëœ ê°’ ê¸°ì¤€ì˜ ì„±ëŠ¥ í–¥ìƒ ì„ê³„ê°’ ë¹„êµ
    perf_improvement = curr_metric / prev_metric
    logger.info(f"ğŸ“ˆ ì„±ëŠ¥ í–¥ìƒê°’: {perf_improvement}")
    if perf_improvement >= PERFORMANCE_THRESHOLD: # PERFORMANCE_THRESHOLD ê°’ì˜ ì˜ë¯¸ê°€ ë‹¬ë¼ì§
        logger.info("ğŸ”¥ INFO: ìœ ì˜ë¯¸í•œ ì„±ëŠ¥ í–¥ìƒ ê°ì§€ (ìŠ¤ì¼€ì¼ë§ ê°’ ê¸°ì¤€), LLM í˜¸ì¶œ...")
        try:
            prompt = build_dependency_prompt(prev_config_scaled, prev_perf_scaled, curr_config_scaled, curr_perf_scaled)
            response = query_openai(prompt)
            logger.info(f"ğŸ’¬LLM Resposne: {response}")
            parsed_data = parse_llm_response(response)
            relation_type = parsed_data.get("relation_type"); knob_names_from_llm = parsed_data.get("knob_names")
            logger.info(f"ğŸ“ŠLLM ê²°ê³¼: ê´€ê³„='{relation_type}', Knobs='{knob_names_from_llm}'")
            # POSITIVE, INVERSE
            if relation_type in ["positive", "inverse"] and knob_names_from_llm and len(knob_names_from_llm) >= 2:
                knob1_name, knob2_name = knob_names_from_llm[0], knob_names_from_llm[1]

                A_prev_scaled, A_curr_scaled = prev_config_scaled[knob1_name], curr_config_scaled[knob1_name]
                B_prev_scaled, B_curr_scaled = prev_config_scaled[knob2_name], curr_config_scaled[knob2_name]

                if relation_type == "positive": weight = DependencyScore("positive", alpha=args.alpha).dependency_score_func_ver2(A_prev_scaled, A_curr_scaled, B_prev_scaled, B_curr_scaled)
                else: weight = DependencyScore("inverse", beta=args.beta).dependency_score_func_ver2(A_prev_scaled, A_curr_scaled, B_prev_scaled, B_curr_scaled)
            # THRESHOLD
            elif relation_type == "threshold":
                 threshold_knob_name, affected_knob_name = knob_names_from_llm[0], knob_names_from_llm[1]
                 threshold_value = parsed_data.get("threshold_value")

                 A_prev_scaled, A_curr_scaled = prev_config_scaled[threshold_knob_name], curr_config_scaled[threshold_knob_name]
                 B_prev_scaled, B_curr_scaled = prev_config_scaled[affected_knob_name], curr_config_scaled[affected_knob_name]
                 weight = DependencyScore("threshold", gamma=args.gamma).dependency_score_func_ver2(A_prev_scaled, A_curr_scaled, B_prev_scaled, B_curr_scaled, threshold_value)

            # NOTHING
            elif relation_type == "nothing": print("â›” INFO: LLM ë¶„ì„ ê²°ê³¼: ì˜ì¡´ì„± ì—†ìŒ."); weight = INITIAL_DEPENDENCY_WEIGHT
            else: logger.info("WARN: LLM ì‘ë‹µì—ì„œ ìœ íš¨ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨."); weight = INITIAL_DEPENDENCY_WEIGHT
        except KeyError as e: logger.info(f"âŒ ì˜¤ë¥˜: LLM ë°˜í™˜ knob ì´ë¦„ '{e}' ì—†ìŒ."); weight = INITIAL_DEPENDENCY_WEIGHT
        except Exception as e: logger.info(f"âŒ ì˜¤ë¥˜: LLM/ì˜ì¡´ì„± ê³„ì‚° ì¤‘ ë¬¸ì œ - {e}"); weight = INITIAL_DEPENDENCY_WEIGHT
    else: logger.info("ğŸ’€ INFO: ì„±ëŠ¥ ë³€í™” ë¯¸ë¯¸ (ìŠ¤ì¼€ì¼ë§ ê°’ ê¸°ì¤€), LLM í˜¸ì¶œ ê±´ë„ˆëœ€."); weight = INITIAL_DEPENDENCY_WEIGHT
    weight = max(0.1, float(weight))
    logger.info(f"INFO: ë‹¤ìŒ ë°˜ë³µ ê°€ì¤‘ì¹˜: {weight:.4f}")
    return weight



# --- ì»¤ìŠ¤í…€ Acquisition í•¨ìˆ˜ ---
class DependencyWeightedAcquisitionFunction(AcquisitionFunction):
    """ì»¤ìŠ¤í…€ Acquisition í•¨ìˆ˜"""
    # ì´ì „ ë‹µë³€ í´ë˜ìŠ¤ ë‚´ìš©ê³¼ ë™ì¼
    def __init__(self, model: Model, base_acquisition_function: AcquisitionFunction, dependency_weight: float):
        super().__init__(model=model); self.base_acqf = base_acquisition_function; self.dependency_weight = dependency_weight
    def forward(self, X: torch.Tensor) -> torch.Tensor:
        base_acqf_value = self.base_acqf(X); weight_tensor = torch.tensor(self.dependency_weight, device=X.device, dtype=X.dtype)
        return base_acqf_value * weight_tensor

# --- GP ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜ ---
def get_fitted_model(train_X: torch.Tensor, train_Y: torch.Tensor) -> SingleTaskGP:
    """GP ëª¨ë¸ í•™ìŠµ (Y ë‚´ë¶€ í‘œì¤€í™” ì œê±°ë¨, [0, 1] ìŠ¤ì¼€ì¼ ì…ë ¥ ì‚¬ìš©)."""
    # ì´ì „ ë‹µë³€ í•¨ìˆ˜ ë‚´ìš©ê³¼ ë™ì¼ (ë‚´ë¶€ í‘œì¤€í™” ì œê±° ë²„ì „)
    logger.info("INFO: GP ëª¨ë¸ í•™ìŠµ ì‹œì‘..."); model = SingleTaskGP(train_X, train_Y); mll = ExactMarginalLogLikelihood(model.likelihood, model)
    try: fit_gpytorch_mll(mll); logger.info("INFO: GP ëª¨ë¸ í•™ìŠµ ì™„ë£Œ."); return model
    except Exception as e: logger.info(f"âŒ ì˜¤ë¥˜: GP ëª¨ë¸ í•™ìŠµ ì¤‘ ë¬¸ì œ - {e}"); raise e

# --- ì´ˆê¸° ìµœê³ ì  íƒìƒ‰ í•¨ìˆ˜ (ìŠ¤ì¼€ì¼ë§ëœ ê°’ ê¸°ì¤€) ---
def find_best_initial_point_scaled(scaled_score_Y_all_np: np.ndarray) -> Tuple[float, int]:
    """ì´ˆê¸° ë°ì´í„°ì…‹ì—ì„œ ìµœê³  ì„±ëŠ¥ ì§€ì ì˜ ì¸ë±ìŠ¤ì™€ ìŠ¤ì¼€ì¼ë§ëœ Yê°’ ì°¾ê¸°"""
    target_y_scaled = scaled_score_Y_all_np
    # ë¹„êµìš© ê°’ (ìµœì†Œí™” ë¬¸ì œ ì‹œ ë¶€í˜¸ ë°˜ì „)
    y_for_comparison = target_y_scaled if IS_MAXIMIZATION else -target_y_scaled

    best_idx = y_for_comparison.argmax()
    best_y_scaled = target_y_scaled[best_idx] # ì‹¤ì œ ìŠ¤ì¼€ì¼ë§ëœ ëª©í‘œê°’

    logger.info(f"INFO: ì´ˆê¸° ë°ì´í„° ìµœê³  ì„±ëŠ¥ (TPS/Latency, ìŠ¤ì¼€ì¼ë§ ê°’): {best_y_scaled:.4f} at index {best_idx}")
    return best_y_scaled, best_idx # ìŠ¤ì¼€ì¼ë§ëœ ìµœê³  Yê°’ê³¼ í•´ë‹¹ ì¸ë±ìŠ¤ ë°˜í™˜

# --- ì´ˆê¸° ëœë¤ ì§€ì  ì„ íƒ í•¨ìˆ˜ (ìŠ¤ì¼€ì¼ë§ëœ ê°’ ê¸°ì¤€) ---
def select_random_initial_point_scaled(scaled_score_Y_all_np: np.ndarray) -> Tuple[float, int]:
    """ì´ˆê¸° ë°ì´í„°ì…‹ì—ì„œ ëœë¤ ì§€ì ì˜ ì¸ë±ìŠ¤ì™€ ìŠ¤ì¼€ì¼ë§ëœ ëª©í‘œ Yê°’ì„ ì„ íƒí•©ë‹ˆë‹¤."""
    num_initial_points = scaled_score_Y_all_np.shape[0]
    if num_initial_points == 0:
        raise ValueError("ì´ˆê¸° ë°ì´í„°ì…‹ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    # 0ë¶€í„° (ë°ì´í„° ê°œìˆ˜ - 1) ì‚¬ì´ì˜ ì •ìˆ˜ ì¸ë±ìŠ¤ë¥¼ ëœë¤í•˜ê²Œ ì„ íƒ
    random_idx = np.random.randint(0, num_initial_points)

    # ì„ íƒëœ ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ìŠ¤ì¼€ì¼ë§ëœ ëª©í‘œ Y ê°’
    selected_y_score_scaled = scaled_score_Y_all_np[random_idx]
    # print(f"selected_y_score_scaled: {selected_y_score_scaled}")
    # print(f"selected_y_score_scaled.shape: {selected_y_score_scaled.shape}")

    logger.info(f"INFO: ì´ˆê¸° ì§€ì ìœ¼ë¡œ ëœë¤ ì„ íƒ (TPS/Latency, ìŠ¤ì¼€ì¼ë§ ê°’): {selected_y_score_scaled} at index {random_idx}")
    return selected_y_score_scaled, random_idx # ì„ íƒëœ ìŠ¤ì¼€ì¼ë§ëœ Yê°’ê³¼ í•´ë‹¹ ì¸ë±ìŠ¤ ë°˜í™˜


# =============================================================================
# ë©”ì¸ ì‹¤í–‰ ë¡œì§
# =============================================================================

if __name__ == "__main__":

    BASE_DIR = "../../../data"
    CSV_FILE_PATH = os.path.join(BASE_DIR, f"workloads/mysql/original_data/preprocess/knob_filter/{args.workload}.csv") # MYSQL_YCSB_{AA/BB/EE/FF}_ORIGIN -> Historical Tuning Data
    MODEL_SAVE_DIR = os.path.join(BASE_DIR, "models/xgboost_mysql/scale") # pre-trained X, Y Scaler
    BASE_FILENAME = args.workload

    MODEL_PATH = os.path.join(MODEL_SAVE_DIR, f"{BASE_FILENAME}._model.pkl") # performance prediction model
    X_SCALER_PATH = os.path.join(MODEL_SAVE_DIR, f"{BASE_FILENAME}._x_scaler.pkl")
    Y_SCALER_PATH = os.path.join(MODEL_SAVE_DIR, f"{BASE_FILENAME}._y_scaler.pkl")
    KNOB_NAMES_PATH = os.path.join(MODEL_SAVE_DIR, f"{BASE_FILENAME}._knobs.pkl")
    # 1. ë°ì´í„° ë° êµ¬ì„± ìš”ì†Œ ë¡œë“œ
    df, xgb_model, x_scaler, y_scaler, knob_names = load_data_and_components(
        CSV_FILE_PATH, MODEL_PATH, X_SCALER_PATH, Y_SCALER_PATH, KNOB_NAMES_PATH
    )
    DIM = len(knob_names) # input dimension
    bounds = torch.tensor([[0.0] * DIM, [1.0] * DIM], device=DEVICE, dtype=DTYPE)

    # 2. ì´ˆê¸° ë°ì´í„° ì¤€ë¹„ ([0, 1] ìŠ¤ì¼€ì¼ í…ì„œ ë° ì›ë³¸ ë°°ì—´), train_Y = scaled_score(TPS/Latency)
    train_X, train_Y, X_all_orig, Y_all_orig = prepare_initial_data(
        df, knob_names, x_scaler, y_scaler
    )
    scaled_Y_all_np = y_scaler.transform(Y_all_orig) # ì—­ë³€í™˜ ìœ„í•´ ì›ë³¸ Yë„ ìŠ¤ì¼€ì¼ë§ -> ì´ê²Œ ë¨¼ì†”? ë¬´ìŠ¨ ì—­ë³€í™˜?
    # print(f"scaled_Y_all_np: {scaled_Y_all_np.shape}")
    epsilon = 1e-9
    scaled_score_Y_all_np = (
        scaled_Y_all_np[:, 0] / scaled_Y_all_np[:, 1] + epsilon #(1000,)
    )
    # print(f"scaled_score_Y_all_np: {scaled_score_Y_all_np.shape}")

    # 3. ì´ˆê¸° ìƒíƒœ ë° ìµœê³  ì„±ëŠ¥ ì¶”ì  ë³€ìˆ˜ ì´ˆê¸°í™”
    # <<< ìˆ˜ì • ì‹œì‘: ìƒíƒœ ë³€ìˆ˜ë¥¼ ìŠ¤ì¼€ì¼ë§ëœ ê°’ìœ¼ë¡œ ì €ì¥ >>>
    prev_config_scaled: Optional[Dict[str, float]]
    prev_perf_scaled: Optional[Dict[str, float]]
    # <<< ìˆ˜ì • ë >>>
    current_dependency_weight: float = INITIAL_DEPENDENCY_WEIGHT

    # ìµœê³  ì„±ëŠ¥ ì¶”ì  (ìŠ¤ì¼€ì¼ë§ëœ ê°’ ê¸°ì¤€), ì²˜ìŒ ì‹œì‘ì ì€ ëœë¤ìœ¼ë¡œ ì„¤ì •
    best_y_scaled, best_idx_init = select_random_initial_point_scaled(scaled_score_Y_all_np)
    #best_y_scaled, best_idx_init = find_best_initial_point_scaled(scaled_Y_all_np)
    best_x_scaled_tensor = train_X[best_idx_init].unsqueeze(0)

    ## ((ì¶”ê°€)) ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸
    history_weights = []
    history_best_y_scaled = [best_y_scaled]

    # 4. ë² ì´ì¦ˆ ìµœì í™” ë£¨í”„
    logger.info(f"\n=== ë² ì´ì¦ˆ ìµœì í™” ì‹œì‘ ({N_ITERATIONS}íšŒ ë°˜ë³µ) ===")
    for iteration in range(1, N_ITERATIONS + 1):
        logger.info(f"\n--- ë°˜ë³µ {iteration}/{N_ITERATIONS} ---")

        # --- GP ëª¨ë¸(surrogate model) í•™ìŠµ ---
        try:
            gp_model = get_fitted_model(train_X, train_Y)
        except Exception:
            logger.info("WARN: GP ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨, ì´ë²ˆ ë°˜ë³µ ê±´ë„ˆëœ€."); continue
            history_weights.append(current_dependency_weight)
            history_best_y_scaled.append(best_y_scaled)
            continue
        # history_best_y_scaled.append(best_y_scaled)

        # --- Acquisition Function ì¤€ë¹„ ---
        # ucb = UpperConfidenceBound(model=gp_model, beta=6.25) # exploration(betaê°€ ì»¤ì§ˆìˆ˜ë¡ íƒìƒ‰ ë²”ìœ„ ë„“ì–´ì§)
        base_ei = ExpectedImprovement(model=gp_model, best_f=best_y_scaled, maximize=True)
        # Acquisition Function: GP(surrogate model)ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ
        custom_acqf = DependencyWeightedAcquisitionFunction(gp_model, base_ei, current_dependency_weight)
        logger.info(f"INFO: íšë“ í•¨ìˆ˜ í˜„ì¬ ì ìš© ê°€ì¤‘ì¹˜: {current_dependency_weight:.4f}")

        # --- ë‹¤ìŒ í›„ë³´ ì§€ì  íƒìƒ‰ ([0, 1] ìŠ¤ì¼€ì¼) ---
        logger.info("INFO: ë‹¤ìŒ í›„ë³´ ì§€ì  íƒìƒ‰ ì¤‘...")
        try:
            candidate_normalized, acqf_value = optimize_acqf(
                custom_acqf, bounds=bounds, q=1, num_restarts=10, raw_samples=1024,
                options={"batch_limit": 5, "maxiter": 200},
            )
            logger.info("INFO: í›„ë³´ ì§€ì  íƒìƒ‰ ì™„ë£Œ.")
        except Exception as e:
            logger.info(f"âŒ ì˜¤ë¥˜: Acq Func ìµœì í™” ì¤‘ - {e}\nWARN: ì´ë²ˆ ë°˜ë³µ ê±´ë„ˆëœ€."); continue
            history_weights.append(current_dependency_weight)
            history_best_y_scaled.append(best_y_scaled)
            continue

        # --- í›„ë³´ ì§€ì  ì„±ëŠ¥ ì˜ˆì¸¡ (ìŠ¤ì¼€ì¼ë§ëœ ê°’ ì‚¬ìš©) ---
        scaled_candidate_np = candidate_normalized.cpu().numpy()
        curr_perf_dict_scaled: Optional[Dict[str, float]] = predict_performance_scaled(scaled_candidate_np, xgb_model)

        if curr_perf_dict_scaled is None:
            logger.info("WARN: í›„ë³´ ì§€ì  ì„±ëŠ¥ ì˜ˆì¸¡ ì‹¤íŒ¨, ì´ë²ˆ ë°˜ë³µ ê±´ë„ˆëœ€.")
            history_weights.append(current_dependency_weight)
            history_best_y_scaled.append(best_y_scaled)
            continue

        epsilon = 1e-9
        new_objective_value_scaled: float = (tps_importance*curr_perf_dict_scaled['scaled_tps']) / (curr_perf_dict_scaled['scaled_latency']+epsilon)
        logger.info(f"  - ì˜ˆì¸¡ëœ ì„±ëŠ¥ (TPS/Latency, ìŠ¤ì¼€ì¼ë§ ê°’): {new_objective_value_scaled:.4f}")

        ############################  save tuning history data   ############################       
        # (ì°¸ì¡°)
        info_df = pd.read_csv("Knob_Information_MySQL_v5.7.csv")
        info_df.columns = info_df.columns.str.strip().str.replace("\ufeff", "", regex=False)
        # ì‹¤ì œ csv ì»¬ëŸ¼ëª… ë§ì¶°ì£¼ê¸°(ex) Name, Default Value)
        default_values = dict(zip(info_df['name'], info_df['d_f_default']))
        # print(f"ğŸ¢ğŸ¢ğŸ¢default values: {default_values}")
        full_knob_list = list(default_values.keys())

        # tuning data ì €ì¥í•˜ëŠ” ì½”ë“œ 
        HISTORICAL_TUNING_DATA_FILE_PATH = os.path.join(BASE_DIR, f"workloads/mysql/original_data/preprocess/historical_data_{args.workload}.csv")
        ORIGINAL_TUNING_DATA_FILE_PATH = os.path.join(BASE_DIR, f"workloads/mysql/original_data/preprocess/MYSQL_YCSB_AA_ORIGIN.csv")
        # iteration == 1ì´ë©´ csv header ì´ˆê¸°í™”
        # (ì°¸ì¡°) (ë°”ê¿”ì•¼ í•  ë¶€ë¶„)
        if os.path.exists(ORIGINAL_TUNING_DATA_FILE_PATH):
            hist_df = pd.read_csv(ORIGINAL_TUNING_DATA_FILE_PATH)
        else: # teration == 1 and not os.path.exists(HISTORICAL_TUNING_DATA_FILE_PATH):
            with open(HISTORICAL_TUNING_DATA_FILE_PATH, mode = 'w', newline = '') as f:
                writer = csv.writer(f)
                # header = knob_names + ['tps', 'latency']
                header = full_knob_list + ['tps', 'latency'] # (ì°¸ì¡°)
                writer.writerow(header)


        # 1) í›„ë³´ config ì—­ìŠ¤ì¼€ì¼ë§
        candidate_unscaled = x_scaler.inverse_transform(candidate_normalized.cpu().numpy())

        # 2) ì˜ˆì¸¡ëœ ì„±ëŠ¥ ì—­ìŠ¤ì¼€ì¼ë§
        perf_unscaled = y_scaler.inverse_transform(
            [[curr_perf_dict_scaled['scaled_tps'], curr_perf_dict_scaled['scaled_latency']]]
        )

        # tuningëœ knob ê°’ ë§¤í•‘ -> í˜„ì¬ íŠœë‹í•œ knobë“¤ì˜ ì‹¤ì œ ê°’
        tuned_knob_dict = dict(zip(knob_names, candidate_unscaled[0]))


        # 3) CSV í–‰ êµ¬ì„±
        # row = list(candidate_unscaled[0]) + list(perf_unscaled[0])
        row = []
        for knob in full_knob_list:
            value = tuned_knob_dict.get(knob, default_values[knob]) # tuning ì•ˆ ëœ knobì€ default ì‚¬ìš©
            row.append(value)

        row += list(perf_unscaled[0]) # [tps, latency]

        # 4) csv fileì— append
        # (ì°¸ì¡°) (ë°”ê¿”ì•¼ í•  ë¶€ë¶„)
        with open(ORIGINAL_TUNING_DATA_FILE_PATH, mode='a', newline = '') as f:
            writer = csv.writer(f)
            writer.writerow(row)
        #####################################################################################


        # ì˜ì¡´ì„± ê°€ì¤‘ì¹˜ ê³„ì‚°
        curr_config_scaled_dict = {knob_names[i]: scaled_candidate_np[0, i] for i in range(DIM)}
        logger.info("INFO: ë‹¤ìŒ ë°˜ë³µì„ ìœ„í•œ ì˜ì¡´ì„± ê°€ì¤‘ì¹˜ ê³„ì‚°")
        try:
            # (ì°¸ì¡°) ì˜ì¡´ì„± ê°€ì¤‘ì¹˜ ê³„ì‚°
            next_dependency_weight = calculate_dependency_weight(prev_config_scaled, prev_perf_scaled, curr_config_scaled_dict, curr_perf_dict_scaled, knob_names)
        except Exception as e:
            logger.info(f"âŒ {e}. ê¸°ë³¸ ê°€ì¤‘ì¹˜ ì‚¬ìš©.")
            next_dependency_weight = INITIAL_DEPENDENCY_WEIGHT


        # --- GP ë°ì´í„° ì—…ë°ì´íŠ¸(ìƒˆë¡œìš´ config ì¶”ê°€) ---
        new_objective_value_scaled_tensor = torch.tensor(
            [[new_objective_value_scaled]], device=DEVICE, dtype=DTYPE
        )
        train_X = torch.cat([train_X, candidate_normalized], dim=0)
        train_Y = torch.cat([train_Y, new_objective_value_scaled_tensor], dim=0)
        logger.info(f"INFO: GP í•™ìŠµ ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ. í˜„ì¬ ë°ì´í„° ìˆ˜: {train_X.shape[0]}")

        # --- ìµœê³  ì„±ëŠ¥ ì—…ë°ì´íŠ¸ (ìŠ¤ì¼€ì¼ë§ëœ ê°’ ê¸°ì¤€) ---
        # print(f"best_y_scaled: {best_y_scaled}")
        objective_value_for_comparison = new_objective_value_scaled if IS_MAXIMIZATION else -new_objective_value_scaled
        best_y_scaled_comparison = best_y_scaled if IS_MAXIMIZATION else -best_y_scaled

        # logger.info(f"objective_value_for_comparison: {objective_value_for_comparison}")
        # logger.info(f"best_y_scaled_comparison: {best_y_scaled_comparison}")
        # print(f"objective_value_for_comparison: {objective_value_for_comparison}")
        # print(f"best_y_scaled_comparison: {best_y_scaled_comparison}")
        if objective_value_for_comparison > best_y_scaled_comparison:
            best_y_scaled = new_objective_value_scaled
            best_x_scaled_tensor = candidate_normalized # (ì°¸ì¡°) ìƒˆ í›„ë³´ì§€ì  ì„ íƒ
            logger.info(f" M_")
            logger.info(f"| âœ¨ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥ ë°œê²¬! (TPS/Latency, ìŠ¤ì¼€ì¼ë§ ê°’: {best_y_scaled:.4f}) âœ¨ |")
            logger.info(f" L_")
        else:
            logger.info(f"INFO: ìµœê³  ì„±ëŠ¥ ìœ ì§€ (TPS/Latency, ìŠ¤ì¼€ì¼ë§ ê°’: {best_y_scaled:.4f})")

        prev_config_scaled = curr_config_scaled_dict
        prev_perf_scaled = curr_perf_dict_scaled

        current_dependency_weight = next_dependency_weight

        history_weights.append(current_dependency_weight)
        history_best_y_scaled.append(best_y_scaled)


    # 5. ìµœì¢… ê²°ê³¼ ì¶œë ¥ (ì—­ìŠ¤ì¼€ì¼ë§)

    logger.info("\n=== ìµœì í™” ì™„ë£Œ ===")
    if best_x_scaled_tensor is not None:

        best_x_scaled_np = best_x_scaled_tensor.cpu().numpy()
        final_perf_scaled_dict = predict_performance_scaled(best_x_scaled_np, xgb_model) # (ì°¸ì¡°) ì„±ëŠ¥ ì˜ˆì¸¡
        # ... ì •ê·œí™” ë°ì´í„° ì—­ë³€í™˜ ...
        if final_perf_scaled_dict:
             final_tps_scaled = final_perf_scaled_dict['scaled_tps']; final_latency_scaled = final_perf_scaled_dict['scaled_latency']
             final_perf_unscaled = y_scaler.inverse_transform([[final_tps_scaled, final_latency_scaled]])
             final_tps_unscaled = final_perf_unscaled[0, 0]; final_latency_unscaled = final_perf_unscaled[0, 1]
        else:
             logger.info("WARN: ìµœì¢… ì„±ëŠ¥ ì˜ˆì¸¡ ì‹¤íŒ¨. ì €ì¥ëœ ëª©í‘œê°’ë§Œ ì—­ë³€í™˜ ì‹œë„.")
             temp_y_scaled = np.zeros((1, 2))
             final_perf_unscaled = y_scaler.inverse_transform(temp_y_scaled)
             final_tps_unscaled = final_perf_unscaled[0, 0] if TARGET_METRIC_INDEX == 0 else np.nan
             final_latency_unscaled = final_perf_unscaled[0, 1] if TARGET_METRIC_INDEX == 1 else np.nan
        final_x_unscaled_np = x_scaler.inverse_transform(best_x_scaled_np)
        final_x_unscaled_config = {knob_names[j]: final_x_unscaled_np[0, j] for j in range(DIM)}
        logger.info("ğŸ† ìµœì¢… ìµœì  ì„¤ì • (ì›ë˜ ìŠ¤ì¼€ì¼):")
        config_str = ", ".join([f"{k}: {v:.4f}" if isinstance(v, float) else f"{k}: {v}" for k, v in final_x_unscaled_config.items()])
        logger.info(f"  - Knobs: {{{config_str}}}")
        logger.info(f"  - ì„±ëŠ¥ (TPS): {final_tps_unscaled:.4f}")
        logger.info(f"  - ì„±ëŠ¥ (Latency): {final_latency_unscaled:.4f}")
        final_target_metric_value = final_tps_unscaled/final_latency_unscaled
    else:
        logger.info("âŒ ìµœì  ì„¤ì •ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
