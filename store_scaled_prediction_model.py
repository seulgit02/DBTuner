from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np
import pandas as pd
import os
import joblib

def keep_xgboost_for_bo(input_dir, output_dir, knob_info_path):
    # 0. Knob Info Î°úÎî©
    try:
        knob_info_df = pd.read_csv(knob_info_path)
        knob_info_df = knob_info_df.set_index('name')  # Knob Ïù¥Î¶ÑÏúºÎ°ú Ïù∏Îç±Ïã±
        print(f"‚úÖ Knob Ï†ïÎ≥¥ Î°úÎìú ÏôÑÎ£å: {knob_info_path}")
    except FileNotFoundError:
        print(f"‚ùå ERROR: Knob Ï†ïÎ≥¥ ÌååÏùº({knob_info_path})ÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. Ïä§ÌÅ¨Î¶ΩÌä∏Î•º Ï§ëÎã®Ìï©ÎãàÎã§.")
        return
    except Exception as e:
        print(f"‚ùå ERROR: Knob Ï†ïÎ≥¥ ÌååÏùº Î°úÎìú Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}. Ïä§ÌÅ¨Î¶ΩÌä∏Î•º Ï§ëÎã®Ìï©ÎãàÎã§.")
        return

    # 1. Îç∞Ïù¥ÌÑ∞ Î°úÎî©
    for file_name in os.listdir(input_dir):
        if not file_name.endswith(".csv"):
            continue

        file_path = f"{input_dir}/{file_name}"
        print("üíæfile_path: ", file_path)
        df = pd.read_csv(file_path)

        # Knob Ïù¥Î¶Ñ ÏàúÏÑú Ïú†ÏßÄ Ï§ëÏöî
        knob_names = df.drop(columns=["tps", "latency", "Unnamed: 0", "conf_id"], errors='ignore').columns.tolist()
        print(f"  - ÏÇ¨Ïö©Îê† Knobs ({len(knob_names)}Í∞ú): {knob_names}")
        A_config = df[knob_names] # Knob ÏàúÏÑú Î≥¥Ïû•
        ex_metrics = df[["tps", "latency"]]

        X_all  = np.array(A_config)
        Y_all = np.array(ex_metrics)

        # Xgboost Î™®Îç∏ ÌïôÏäµ
        n = 1
        while (True):
            X_train, X_test, y_train, y_test = train_test_split(X_all, Y_all, test_size=0.3, shuffle=True)
            X_scaler = MinMaxScaler().fit(X_train)
            y_scaler = MinMaxScaler().fit(y_train)

            print("  - X_scaler ÏÑ§Ï†ï ÏãúÏûë (Knob Ï†ïÎ≥¥ Í∏∞Ï§Ä)...")
            X_scaler = MinMaxScaler(feature_range=(0, 1))

            num_knobs = len(knob_names)
            data_min_ = np.zeros(num_knobs)
            data_max_ = np.zeros(num_knobs)
            valid_knobs_mask = np.ones(num_knobs, dtype=bool) # Knob Ï†ïÎ≥¥Í∞Ä ÏûàÎäî KnobÎßå ÌëúÏãú

            for i, knob_name in enumerate(knob_names):
                if knob_name in knob_info_df.index:
                    print(f"knob_name: {knob_name}")
                    data_min_[i] = knob_info_df.loc[knob_name, 'raw_min']
                    data_max_[i] = knob_info_df.loc[knob_name, 'raw_max']
                    print(f"{knob_name}Ïùò min: {data_min_[i]}")
                    print(f"{knob_name}Ïùò max: {data_max_[i]}")
                else:
                    print(f"    ‚ö†Ô∏è WARNING: Knob '{knob_name}' Ï†ïÎ≥¥Í∞Ä CSVÏóê ÏóÜÏäµÎãàÎã§. Ïù¥ KnobÏùÄ Ïä§ÏºÄÏùºÎßÅÏóêÏÑú Ï†úÏô∏Îê©ÎãàÎã§ (ÏõêÎ≥∏ Í∞í ÏÇ¨Ïö©).")
                    valid_knobs_mask[i] = False

            # MinMaxScaler ÎÇ¥Î∂Ä ÏÜçÏÑ± ÏßÅÏ†ë ÏÑ§Ï†ï(fit Ìò∏Ï∂ú Ïïà Ìï®.)
            X_scaler.n_features_in_ = num_knobs
            if hasattr(X_scaler, 'feature_names_in_'):  # ÏµúÏã† Î≤ÑÏ†Ñ Ìò∏ÌôòÏÑ±
                X_scaler.feature_names_in_ = np.array(knob_names, dtype=object)
            X_scaler.data_min_ = data_min_
            X_scaler.data_max_ = data_max_

            # scale_Í≥º min_ Í≥ÑÏÇ∞ (MinMaxScaler ÎÇ¥Î∂Ä Î°úÏßÅ Ï∞∏Í≥†)
            feature_range = X_scaler.feature_range
            data_range = data_max_ - data_min_
            # 0ÏúºÎ°ú ÎÇòÎàÑÍ∏∞ Î∞©ÏßÄ: min==maxÏù∏ Í≤ΩÏö∞ scale=1, min=0 (ÎòêÎäî Îã§Î•∏ Ìï©Î¶¨Ï†Å Í∞í)ÏúºÎ°ú Ï≤òÎ¶¨
            scale_ = (feature_range[1] - feature_range[0]) / np.where(data_range == 0, 1, data_range)
            min_ = feature_range[0] - data_min_ * scale_

            # Knob Ï†ïÎ≥¥Í∞Ä ÏóÜÎäî Í≤ΩÏö∞ scale=1, min=0ÏúºÎ°ú ÏÑ§Ï†ïÌïòÏó¨ ÏõêÎ≥∏ Í∞í Ïú†ÏßÄ
            scale_[~valid_knobs_mask] = 1.0
            min_[~valid_knobs_mask] = 0.0

            X_scaler.scale_ = scale_
            X_scaler.min_ = min_
            X_scaler.n_samples_seen_ = -1  # fitÏùÑ Ìò∏Ï∂úÌïòÏßÄ ÏïäÏïòÏùåÏùÑ ÏùòÎØ∏

            print("  - X_scaler ÏÑ§Ï†ï ÏôÑÎ£å.")
            # --- X_scaler ÏàòÎèô ÏÑ§Ï†ï ÎÅù ---

            # --- y_scalerÎäî Í∏∞Ï°¥ Î∞©Ïãù Ïú†ÏßÄ ---
            y_scaler = MinMaxScaler().fit(y_train)
            # --- y_scaler ÎÅù ---

            # ÏÑ§Ï†ïÎêú Ïä§ÏºÄÏùºÎü¨Î°ú Î≥ÄÌôò
            scaled_X_train = X_scaler.transform(X_train)
            scaled_X_test = X_scaler.transform(X_test)
            scaled_y_train = y_scaler.transform(y_train)
            scaled_y_test = y_scaler.transform(y_test)

            # --- XGBoost Î™®Îç∏ ÌïôÏäµ (scaled_X ÏÇ¨Ïö©) ---
            print("  - XGBoost Î™®Îç∏ ÌïôÏäµ ÏãúÏûë...")
            xgb_model = XGBRegressor(
                objective='reg:squarederror',
                random_state=2, n_estimators=100, max_depth=6, learning_rate=0.1)

            xgb_model.fit(scaled_X_train, scaled_y_train)
            print("  - XGBoost Î™®Îç∏ ÌïôÏäµ ÏôÑÎ£å.")

            pred = xgb_model.predict(scaled_X_test)

            accuracy = r2_score(scaled_y_test, pred)
            print('RMSE : ', np.sqrt(mean_squared_error(scaled_y_test, pred)))
            print('R2_SCORE : ', r2_score(scaled_y_test, pred))

            if accuracy > 0.9:
                # ÌõÑÏóê Î™®Îç∏ Î°úÎìúÎ•º ÏúÑÌï¥ Ï†ÄÏû•
                base_name = file_name.replace("csv","")
                model_path = os.path.join(output_dir, f"{base_name}_model.pkl")
                x_scaler_path = os.path.join(output_dir, f"{base_name}_x_scaler.pkl")
                y_scaler_path = os.path.join(output_dir, f"{base_name}_y_scaler.pkl")
                knob_names_path = os.path.join(output_dir, f"{base_name}_knobs.pkl")

                # Ï†ÄÏû•
                joblib.dump(xgb_model, model_path)
                joblib.dump(X_scaler, x_scaler_path)
                joblib.dump(y_scaler, y_scaler_path)
                joblib.dump(A_config.columns.tolist(), knob_names_path)
                break

            # rmse
        print('RMSE : ', np.sqrt(mean_squared_error(scaled_y_test, pred)))
        print('R2_SCORE : ', r2_score(scaled_y_test, pred))

        print("scaled_X: ", scaled_X_test.shape)


if __name__ == "__main__":
    input_dir = "../../../data/workloads/mysql/original_data/preprocess/knob_filter"
    output_dir = "../../../data/models/xgboost_mysql/scale"
    knob_info_path = "../../../data/knob_info/Knob_Information_MySQL_v5.7.csv"
    keep_xgboost_for_bo(input_dir, output_dir, knob_info_path)

