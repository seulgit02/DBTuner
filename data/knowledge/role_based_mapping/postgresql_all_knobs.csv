knob_name,type,description
data_directory,string,Specifies the directory to use for data storage. This parameter can only be set at server start.
config_file,string,Specifies the main server configuration file (customarily calledpostgresql.conf). This parameter can only be set on thepostgrescommand line.
hba_file,string,Specifies the configuration file for host-based authentication (customarily calledpg_hba.conf). This parameter can only be set at server start.
ident_file,string,Specifies the configuration file for user name mapping (customarily calledpg_ident.conf). This parameter can only be set at server start. See alsoSection 20.2.
external_pid_file,string,Specifies the name of an additional process-ID (PID) file that the server should create for use by server administration programs. This parameter can only be set at server start.
listen_addresses,string,"Specifies the TCP/IP address(es) on which the server is to listen for connections from client applications. The value takes the form of a comma-separated list of host names and/or numeric IP addresses. The special entry*corresponds to all available IP interfaces. The entry0.0.0.0allows listening for all IPv4 addresses and::allows listening for all IPv6 addresses. If the list is empty, the server does not listen on any IP interface at all, in which case only Unix-domain sockets can be used to connect to it. If the list is not empty, the server will start if it can listen on at least one TCP/IP address. A warning will be emitted for any TCP/IP address which cannot be opened. The default value islocalhost, which allows only local TCP/IP“loopback”connections to be made.While client authentication (Chapter 20) allows fine-grained control over who can access the server,listen_addressescontrols which interfaces accept connection attempts, which can help prevent repeated malicious connection requests on insecure network interfaces. This parameter can only be set at server start."
port,integer,The TCP port the server listens on; 5432 by default. Note that the same port number is used for all IP addresses the server listens on. This parameter can only be set at server start.
max_connections,integer,"Determines the maximum number of concurrent connections to the database server. The default is typically 100 connections, but might be less if your kernel settings will not support it (as determined duringinitdb). This parameter can only be set at server start.PostgreSQL sizes certain resources based directly on the value ofmax_connections. Increasing its value leads to higher allocation of those resources, including shared memory.When running a standby server, you must set this parameter to the same or higher value than on the primary server. Otherwise, queries will not be allowed in the standby server."
reserved_connections,integer,"Determines the number of connection“slots”that are reserved for connections by roles with privileges of thepg_use_reserved_connectionsrole. Whenever the number of free connection slots is greater thansuperuser_reserved_connectionsbut less than or equal to the sum ofsuperuser_reserved_connectionsandreserved_connections, new connections will be accepted only for superusers and roles with privileges ofpg_use_reserved_connections. Ifsuperuser_reserved_connectionsor fewer connection slots are available, new connections will be accepted only for superusers.The default value is zero connections. The value must be less thanmax_connectionsminussuperuser_reserved_connections. This parameter can only be set at server start."
superuser_reserved_connections,integer,"Determines the number of connection“slots”that are reserved for connections byPostgreSQLsuperusers. At mostmax_connectionsconnections can ever be active simultaneously. Whenever the number of active concurrent connections is at leastmax_connectionsminussuperuser_reserved_connections, new connections will be accepted only for superusers. The connection slots reserved by this parameter are intended as final reserve for emergency use after the slots reserved byreserved_connectionshave been exhausted.The default value is three connections. The value must be less thanmax_connectionsminusreserved_connections. This parameter can only be set at server start."
unix_socket_directories,string,"Specifies the directory of the Unix-domain socket(s) on which the server is to listen for connections from client applications. Multiple sockets can be created by listing multiple directories separated by commas. Whitespace between entries is ignored; surround a directory name with double quotes if you need to include whitespace or commas in the name. An empty value specifies not listening on any Unix-domain sockets, in which case only TCP/IP sockets can be used to connect to the server.A value that starts with@specifies that a Unix-domain socket in the abstract namespace should be created (currently supported on Linux only). In that case, this value does not specify a“directory”but a prefix from which the actual socket name is computed in the same manner as for the file-system namespace. While the abstract socket name prefix can be chosen freely, since it is not a file-system location, the convention is to nonetheless use file-system-like values such as@/tmp.The default value is normally/tmp, but that can be changed at build time. On Windows, the default is empty, which means no Unix-domain socket is created by default. This parameter can only be set at server start.In addition to the socket file itself, which is named.s.PGSQL.nnnnwherennnnis the server's port number, an ordinary file named.s.PGSQL.nnnn.lockwill be created in each of theunix_socket_directoriesdirectories. Neither file should ever be removed manually. For sockets in the abstract namespace, no lock file is created."
unix_socket_group,string,"Sets the owning group of the Unix-domain socket(s). (The owning user of the sockets is always the user that starts the server.) In combination with the parameterunix_socket_permissionsthis can be used as an additional access control mechanism for Unix-domain connections. By default this is the empty string, which uses the default group of the server user. This parameter can only be set at server start.This parameter is not supported on Windows. Any setting will be ignored. Also, sockets in the abstract namespace have no file owner, so this setting is also ignored in that case."
unix_socket_permissions,integer,"Sets the access permissions of the Unix-domain socket(s). Unix-domain sockets use the usual Unix file system permission set. The parameter value is expected to be a numeric mode specified in the format accepted by thechmodandumasksystem calls. (To use the customary octal format the number must start with a0(zero).)The default permissions are0777, meaning anyone can connect. Reasonable alternatives are0770(only user and group, see alsounix_socket_group) and0700(only user). (Note that for a Unix-domain socket, only write permission matters, so there is no point in setting or revoking read or execute permissions.)This access control mechanism is independent of the one described inChapter 20.This parameter can only be set at server start.This parameter is irrelevant on systems, notably Solaris as of Solaris 10, that ignore socket permissions entirely. There, one can achieve a similar effect by pointingunix_socket_directoriesto a directory having search permission limited to the desired audience.Sockets in the abstract namespace have no file permissions, so this setting is also ignored in that case."
bonjour,boolean,Enables advertising the server's existence viaBonjour. The default is off. This parameter can only be set at server start.
bonjour_name,string,Specifies theBonjourservice name. The computer name is used if this parameter is set to the empty string''(which is the default). This parameter is ignored if the server was not compiled withBonjoursupport. This parameter can only be set at server start.
tcp_keepalives_idle,integer,"Specifies the amount of time with no network activity after which the operating system should send a TCP keepalive message to the client. If this value is specified without units, it is taken as seconds. A value of 0 (the default) selects the operating system's default. On Windows, setting a value of 0 will set this parameter to 2 hours, since Windows does not provide a way to read the system default value. This parameter is supported only on systems that supportTCP_KEEPIDLEor an equivalent socket option, and on Windows; on other systems, it must be zero. In sessions connected via a Unix-domain socket, this parameter is ignored and always reads as zero."
tcp_keepalives_interval,integer,"Specifies the amount of time after which a TCP keepalive message that has not been acknowledged by the client should be retransmitted. If this value is specified without units, it is taken as seconds. A value of 0 (the default) selects the operating system's default. On Windows, setting a value of 0 will set this parameter to 1 second, since Windows does not provide a way to read the system default value. This parameter is supported only on systems that supportTCP_KEEPINTVLor an equivalent socket option, and on Windows; on other systems, it must be zero. In sessions connected via a Unix-domain socket, this parameter is ignored and always reads as zero."
tcp_keepalives_count,integer,"Specifies the number of TCP keepalive messages that can be lost before the server's connection to the client is considered dead. A value of 0 (the default) selects the operating system's default. This parameter is supported only on systems that supportTCP_KEEPCNTor an equivalent socket option (which does not include Windows); on other systems, it must be zero. In sessions connected via a Unix-domain socket, this parameter is ignored and always reads as zero."
tcp_user_timeout,integer,"Specifies the amount of time that transmitted data may remain unacknowledged before the TCP connection is forcibly closed. If this value is specified without units, it is taken as milliseconds. A value of 0 (the default) selects the operating system's default. This parameter is supported only on systems that supportTCP_USER_TIMEOUT(which does not include Windows); on other systems, it must be zero. In sessions connected via a Unix-domain socket, this parameter is ignored and always reads as zero."
client_connection_check_interval,integer,"Sets the time interval between optional checks that the client is still connected, while running queries. The check is performed by polling the socket, and allows long running queries to be aborted sooner if the kernel reports that the connection is closed.This option relies on kernel events exposed by Linux, macOS, illumos and the BSD family of operating systems, and is not currently available on other systems.If the value is specified without units, it is taken as milliseconds. The default value is0, which disables connection checks. Without connection checks, the server will detect the loss of the connection only at the next interaction with the socket, when it waits for, receives or sends data.For the kernel itself to detect lost TCP connections reliably and within a known timeframe in all scenarios including network failure, it may also be necessary to adjust the TCP keepalive settings of the operating system, or thetcp_keepalives_idle,tcp_keepalives_intervalandtcp_keepalives_countsettings ofPostgreSQL."
authentication_timeout,integer,"Maximum amount of time allowed to complete client authentication. If a would-be client has not completed the authentication protocol in this much time, the server closes the connection. This prevents hung clients from occupying a connection indefinitely. If this value is specified without units, it is taken as seconds. The default is one minute (1m). This parameter can only be set in thepostgresql.conffile or on the server command line."
password_encryption,enum,"When a password is specified inCREATE ROLEorALTER ROLE, this parameter determines the algorithm to use to encrypt the password. Possible values arescram-sha-256, which will encrypt the password with SCRAM-SHA-256, andmd5, which stores the password as an MD5 hash. The default isscram-sha-256.Note that older clients might lack support for the SCRAM authentication mechanism, and hence not work with passwords encrypted with SCRAM-SHA-256. SeeSection 20.5for more details."
scram_iterations,integer,"The number of computational iterations to be performed when encrypting a password using SCRAM-SHA-256. The default is4096. A higher number of iterations provides additional protection against brute-force attacks on stored passwords, but makes authentication slower. Changing the value has no effect on existing passwords encrypted with SCRAM-SHA-256 as the iteration count is fixed at the time of encryption. In order to make use of a changed value, a new password must be set."
krb_server_keyfile,string,"Sets the location of the server's Kerberos key file. The default isFILE:/usr/local/pgsql/etc/krb5.keytab(where the directory part is whatever was specified assysconfdirat build time; usepg_config --sysconfdirto determine that). If this parameter is set to an empty string, it is ignored and a system-dependent default is used. This parameter can only be set in thepostgresql.conffile or on the server command line. SeeSection 20.6for more information."
krb_caseins_users,boolean,Sets whether GSSAPI user names should be treated case-insensitively. The default isoff(case sensitive). This parameter can only be set in thepostgresql.conffile or on the server command line.
gss_accept_delegation,boolean,Sets whether GSSAPI delegation should be accepted from the client. The default isoffmeaning credentials from the client willnotbe accepted. Changing this toonwill make the server accept credentials delegated to it from the client. This parameter can only be set in thepostgresql.conffile or on the server command line.
ssl,boolean,EnablesSSLconnections. This parameter can only be set in thepostgresql.conffile or on the server command line. The default isoff.
ssl_ca_file,string,"Specifies the name of the file containing the SSL server certificate authority (CA). Relative paths are relative to the data directory. This parameter can only be set in thepostgresql.conffile or on the server command line. The default is empty, meaning no CA file is loaded, and client certificate verification is not performed."
ssl_cert_file,string,Specifies the name of the file containing the SSL server certificate. Relative paths are relative to the data directory. This parameter can only be set in thepostgresql.conffile or on the server command line. The default isserver.crt.
ssl_crl_file,string,"Specifies the name of the file containing the SSL client certificate revocation list (CRL). Relative paths are relative to the data directory. This parameter can only be set in thepostgresql.conffile or on the server command line. The default is empty, meaning no CRL file is loaded (unlessssl_crl_diris set)."
ssl_crl_dir,string,"Specifies the name of the directory containing the SSL client certificate revocation list (CRL). Relative paths are relative to the data directory. This parameter can only be set in thepostgresql.conffile or on the server command line. The default is empty, meaning no CRLs are used (unlessssl_crl_fileis set).The directory needs to be prepared with theOpenSSLcommandopenssl rehashorc_rehash. See its documentation for details.When using this setting, CRLs in the specified directory are loaded on-demand at connection time. New CRLs can be added to the directory and will be used immediately. This is unlikessl_crl_file, which causes the CRL in the file to be loaded at server start time or when the configuration is reloaded. Both settings can be used together."
ssl_key_file,string,Specifies the name of the file containing the SSL server private key. Relative paths are relative to the data directory. This parameter can only be set in thepostgresql.conffile or on the server command line. The default isserver.key.
ssl_ciphers,string,"Specifies a list ofSSLcipher suites that are allowed to be used by SSL connections. See theciphersmanual page in theOpenSSLpackage for the syntax of this setting and a list of supported values. Only connections using TLS version 1.2 and lower are affected. There is currently no setting that controls the cipher choices used by TLS version 1.3 connections. The default value isHIGH:MEDIUM:+3DES:!aNULL. The default is usually a reasonable choice unless you have specific security requirements.This parameter can only be set in thepostgresql.conffile or on the server command line.Explanation of the default value:HIGH#Cipher suites that use ciphers fromHIGHgroup (e.g., AES, Camellia, 3DES)MEDIUM#Cipher suites that use ciphers fromMEDIUMgroup (e.g., RC4, SEED)+3DES#TheOpenSSLdefault order forHIGHis problematic because it orders 3DES higher than AES128. This is wrong because 3DES offers less security than AES128, and it is also much slower.+3DESreorders it after all otherHIGHandMEDIUMciphers.!aNULL#Disables anonymous cipher suites that do no authentication. Such cipher suites are vulnerable toMITMattacks and therefore should not be used.Available cipher suite details will vary acrossOpenSSLversions. Use the commandopenssl ciphers -v 'HIGH:MEDIUM:+3DES:!aNULL'to see actual details for the currently installedOpenSSLversion. Note that this list is filtered at run time based on the server key type."
ssl_prefer_server_ciphers,boolean,"Specifies whether to use the server's SSL cipher preferences, rather than the client's. This parameter can only be set in thepostgresql.conffile or on the server command line. The default ison.PostgreSQLversions before 9.4 do not have this setting and always use the client's preferences. This setting is mainly for backward compatibility with those versions. Using the server's preferences is usually better because it is more likely that the server is appropriately configured."
ssl_ecdh_curve,string,"Specifies the name of the curve to use inECDHkey exchange. It needs to be supported by all clients that connect. It does not need to be the same curve used by the server's Elliptic Curve key. This parameter can only be set in thepostgresql.conffile or on the server command line. The default isprime256v1.OpenSSLnames for the most common curves are:prime256v1(NIST P-256),secp384r1(NIST P-384),secp521r1(NIST P-521). The full list of available curves can be shown with the commandopenssl ecparam -list_curves. Not all of them are usable inTLSthough."
ssl_min_protocol_version,enum,"Sets the minimum SSL/TLS protocol version to use. Valid values are currently:TLSv1,TLSv1.1,TLSv1.2,TLSv1.3. Older versions of theOpenSSLlibrary do not support all values; an error will be raised if an unsupported setting is chosen. Protocol versions before TLS 1.0, namely SSL version 2 and 3, are always disabled.The default isTLSv1.2, which satisfies industry best practices as of this writing.This parameter can only be set in thepostgresql.conffile or on the server command line."
ssl_max_protocol_version,enum,"Sets the maximum SSL/TLS protocol version to use. Valid values are as forssl_min_protocol_version, with addition of an empty string, which allows any protocol version. The default is to allow any version. Setting the maximum protocol version is mainly useful for testing or if some component has issues working with a newer protocol.This parameter can only be set in thepostgresql.conffile or on the server command line."
ssl_dh_params_file,string,"Specifies the name of the file containing Diffie-Hellman parameters used for so-called ephemeral DH family of SSL ciphers. The default is empty, in which case compiled-in default DH parameters used. Using custom DH parameters reduces the exposure if an attacker manages to crack the well-known compiled-in DH parameters. You can create your own DH parameters file with the commandopenssl dhparam -out dhparams.pem 2048.This parameter can only be set in thepostgresql.conffile or on the server command line."
ssl_passphrase_command,string,"Sets an external command to be invoked when a passphrase for decrypting an SSL file such as a private key needs to be obtained. By default, this parameter is empty, which means the built-in prompting mechanism is used.The command must print the passphrase to the standard output and exit with code 0. In the parameter value,%pis replaced by a prompt string. (Write%%for a literal%.) Note that the prompt string will probably contain whitespace, so be sure to quote adequately. A single newline is stripped from the end of the output if present.The command does not actually have to prompt the user for a passphrase. It can read it from a file, obtain it from a keychain facility, or similar. It is up to the user to make sure the chosen mechanism is adequately secure.This parameter can only be set in thepostgresql.conffile or on the server command line."
ssl_passphrase_command_supports_reload,boolean,"This parameter determines whether the passphrase command set byssl_passphrase_commandwill also be called during a configuration reload if a key file needs a passphrase. If this parameter is off (the default), thenssl_passphrase_commandwill be ignored during a reload and the SSL configuration will not be reloaded if a passphrase is needed. That setting is appropriate for a command that requires a TTY for prompting, which might not be available when the server is running. Setting this parameter to on might be appropriate if the passphrase is obtained from a file, for example.This parameter can only be set in thepostgresql.conffile or on the server command line."
shared_buffers,integer,"Sets the amount of memory the database server uses for shared memory buffers. The default is typically 128 megabytes (128MB), but might be less if your kernel settings will not support it (as determined duringinitdb). This setting must be at least 128 kilobytes. However, settings significantly higher than the minimum are usually needed for good performance. If this value is specified without units, it is taken as blocks, that isBLCKSZbytes, typically 8kB. (Non-default values ofBLCKSZchange the minimum value.) This parameter can only be set at server start.If you have a dedicated database server with 1GB or more of RAM, a reasonable starting value forshared_buffersis 25% of the memory in your system. There are some workloads where even larger settings forshared_buffersare effective, but becausePostgreSQLalso relies on the operating system cache, it is unlikely that an allocation of more than 40% of RAM toshared_bufferswill work better than a smaller amount. Larger settings forshared_buffersusually require a corresponding increase inmax_wal_size, in order to spread out the process of writing large quantities of new or changed data over a longer period of time.On systems with less than 1GB of RAM, a smaller percentage of RAM is appropriate, so as to leave adequate space for the operating system."
huge_pages,enum,"Controls whether huge pages are requested for the main shared memory area. Valid values aretry(the default),on, andoff. Withhuge_pagesset totry, the server will try to request huge pages, but fall back to the default if that fails. Withon, failure to request huge pages will prevent the server from starting up. Withoff, huge pages will not be requested. The actual state of huge pages is indicated by the server variablehuge_pages_status.At present, this setting is supported only on Linux and Windows. The setting is ignored on other systems when set totry. On Linux, it is only supported whenshared_memory_typeis set tommap(the default).The use of huge pages results in smaller page tables and less CPU time spent on memory management, increasing performance. For more details about using huge pages on Linux, seeSection 18.4.5.Huge pages are known as large pages on Windows. To use them, you need to assign the user right“Lock pages in memory”to the Windows user account that runsPostgreSQL. You can use Windows Group Policy tool (gpedit.msc) to assign the user right“Lock pages in memory”. To start the database server on the command prompt as a standalone process, not as a Windows service, the command prompt must be run as an administrator or User Access Control (UAC) must be disabled. When the UAC is enabled, the normal command prompt revokes the user right“Lock pages in memory”when started.Note that this setting only affects the main shared memory area. Operating systems such as Linux, FreeBSD, and Illumos can also use huge pages (also known as“super”pages or“large”pages) automatically for normal memory allocation, without an explicit request fromPostgreSQL. On Linux, this is called“transparent huge pages”(THP). That feature has been known to cause performance degradation withPostgreSQLfor some users on some Linux versions, so its use is currently discouraged (unlike explicit use ofhuge_pages)."
huge_page_size,integer,"Controls the size of huge pages, when they are enabled withhuge_pages. The default is zero (0). When set to0, the default huge page size on the system will be used. This parameter can only be set at server start.Some commonly available page sizes on modern 64 bit server architectures include:2MBand1GB(Intel and AMD),16MBand16GB(IBM POWER), and64kB,2MB,32MBand1GB(ARM). For more information about usage and support, seeSection 18.4.5.Non-default settings are currently supported only on Linux."
temp_buffers,integer,"Sets the maximum amount of memory used for temporary buffers within each database session. These are session-local buffers used only for access to temporary tables. If this value is specified without units, it is taken as blocks, that isBLCKSZbytes, typically 8kB. The default is eight megabytes (8MB). (IfBLCKSZis not 8kB, the default value scales proportionally to it.) This setting can be changed within individual sessions, but only before the first use of temporary tables within the session; subsequent attempts to change the value will have no effect on that session.A session will allocate temporary buffers as needed up to the limit given bytemp_buffers. The cost of setting a large value in sessions that do not actually need many temporary buffers is only a buffer descriptor, or about 64 bytes, per increment intemp_buffers. However if a buffer is actually used an additional 8192 bytes will be consumed for it (or in general,BLCKSZbytes)."
max_prepared_transactions,integer,"Sets the maximum number of transactions that can be in the“prepared”state simultaneously (seePREPARE TRANSACTION). Setting this parameter to zero (which is the default) disables the prepared-transaction feature. This parameter can only be set at server start.If you are not planning to use prepared transactions, this parameter should be set to zero to prevent accidental creation of prepared transactions. If you are using prepared transactions, you will probably wantmax_prepared_transactionsto be at least as large asmax_connections, so that every session can have a prepared transaction pending.When running a standby server, you must set this parameter to the same or higher value than on the primary server. Otherwise, queries will not be allowed in the standby server."
work_mem,integer,"Sets the base maximum amount of memory to be used by a query operation (such as a sort or hash table) before writing to temporary disk files. If this value is specified without units, it is taken as kilobytes. The default value is four megabytes (4MB). Note that a complex query might perform several sort and hash operations at the same time, with each operation generally being allowed to use as much memory as this value specifies before it starts to write data into temporary files. Also, several running sessions could be doing such operations concurrently. Therefore, the total memory used could be many times the value ofwork_mem; it is necessary to keep this fact in mind when choosing the value. Sort operations are used forORDER BY,DISTINCT, and merge joins. Hash tables are used in hash joins, hash-based aggregation, memoize nodes and hash-based processing ofINsubqueries.Hash-based operations are generally more sensitive to memory availability than equivalent sort-based operations. The memory limit for a hash table is computed by multiplyingwork_membyhash_mem_multiplier. This makes it possible for hash-based operations to use an amount of memory that exceeds the usualwork_membase amount."
hash_mem_multiplier,floating point,"Used to compute the maximum amount of memory that hash-based operations can use. The final limit is determined by multiplyingwork_membyhash_mem_multiplier. The default value is 2.0, which makes hash-based operations use twice the usualwork_membase amount.Consider increasinghash_mem_multiplierin environments where spilling by query operations is a regular occurrence, especially when simply increasingwork_memresults in memory pressure (memory pressure typically takes the form of intermittent out of memory errors). The default setting of 2.0 is often effective with mixed workloads. Higher settings in the range of 2.0 - 8.0 or more may be effective in environments wherework_memhas already been increased to 40MB or more."
maintenance_work_mem,integer,"Specifies the maximum amount of memory to be used by maintenance operations, such asVACUUM,CREATE INDEX, andALTER TABLE ADD FOREIGN KEY. If this value is specified without units, it is taken as kilobytes. It defaults to 64 megabytes (64MB). Since only one of these operations can be executed at a time by a database session, and an installation normally doesn't have many of them running concurrently, it's safe to set this value significantly larger thanwork_mem. Larger settings might improve performance for vacuuming and for restoring database dumps.Note that when autovacuum runs, up toautovacuum_max_workerstimes this memory may be allocated, so be careful not to set the default value too high. It may be useful to control for this by separately settingautovacuum_work_mem."
autovacuum_work_mem,integer,"Specifies the maximum amount of memory to be used by each autovacuum worker process. If this value is specified without units, it is taken as kilobytes. It defaults to -1, indicating that the value ofmaintenance_work_memshould be used instead. The setting has no effect on the behavior ofVACUUMwhen run in other contexts. This parameter can only be set in thepostgresql.conffile or on the server command line."
vacuum_buffer_usage_limit,integer,"Specifies the size of theBuffer Access Strategyused by theVACUUMandANALYZEcommands. A setting of0will allow the operation to use any number ofshared_buffers. Otherwise valid sizes range from128 kBto16 GB. If the specified size would exceed 1/8 the size ofshared_buffers, the size is silently capped to that value. The default value is2MB. If this value is specified without units, it is taken as kilobytes. This parameter can be set at any time. It can be overridden forVACUUMandANALYZEwhen passing theBUFFER_USAGE_LIMIToption. Higher settings can allowVACUUMandANALYZEto run more quickly, but having too large a setting may cause too many other useful pages to be evicted from shared buffers."
logical_decoding_work_mem,integer,"Specifies the maximum amount of memory to be used by logical decoding, before some of the decoded changes are written to local disk. This limits the amount of memory used by logical streaming replication connections. It defaults to 64 megabytes (64MB). Since each replication connection only uses a single buffer of this size, and an installation normally doesn't have many such connections concurrently (as limited bymax_wal_senders), it's safe to set this value significantly higher thanwork_mem, reducing the amount of decoded changes written to disk."
commit_timestamp_buffers,integer,"Specifies the amount of memory to use to cache the contents ofpg_commit_ts(seeTable 65.1). If this value is specified without units, it is taken as blocks, that isBLCKSZbytes, typically 8kB. The default value is0, which requestsshared_buffers/512 up to 1024 blocks, but not fewer than 16 blocks. This parameter can only be set at server start."
multixact_member_buffers,integer,"Specifies the amount of shared memory to use to cache the contents ofpg_multixact/members(seeTable 65.1). If this value is specified without units, it is taken as blocks, that isBLCKSZbytes, typically 8kB. The default value is32. This parameter can only be set at server start."
multixact_offset_buffers,integer,"Specifies the amount of shared memory to use to cache the contents ofpg_multixact/offsets(seeTable 65.1). If this value is specified without units, it is taken as blocks, that isBLCKSZbytes, typically 8kB. The default value is16. This parameter can only be set at server start."
notify_buffers,integer,"Specifies the amount of shared memory to use to cache the contents ofpg_notify(seeTable 65.1). If this value is specified without units, it is taken as blocks, that isBLCKSZbytes, typically 8kB. The default value is16. This parameter can only be set at server start."
serializable_buffers,integer,"Specifies the amount of shared memory to use to cache the contents ofpg_serial(seeTable 65.1). If this value is specified without units, it is taken as blocks, that isBLCKSZbytes, typically 8kB. The default value is32. This parameter can only be set at server start."
subtransaction_buffers,integer,"Specifies the amount of shared memory to use to cache the contents ofpg_subtrans(seeTable 65.1). If this value is specified without units, it is taken as blocks, that isBLCKSZbytes, typically 8kB. The default value is0, which requestsshared_buffers/512 up to 1024 blocks, but not fewer than 16 blocks. This parameter can only be set at server start."
transaction_buffers,integer,"Specifies the amount of shared memory to use to cache the contents ofpg_xact(seeTable 65.1). If this value is specified without units, it is taken as blocks, that isBLCKSZbytes, typically 8kB. The default value is0, which requestsshared_buffers/512 up to 1024 blocks, but not fewer than 16 blocks. This parameter can only be set at server start."
max_stack_depth,integer,"Specifies the maximum safe depth of the server's execution stack. The ideal setting for this parameter is the actual stack size limit enforced by the kernel (as set byulimit -sor local equivalent), less a safety margin of a megabyte or so. The safety margin is needed because the stack depth is not checked in every routine in the server, but only in key potentially-recursive routines. If this value is specified without units, it is taken as kilobytes. The default setting is two megabytes (2MB), which is conservatively small and unlikely to risk crashes. However, it might be too small to allow execution of complex functions. Only superusers and users with the appropriateSETprivilege can change this setting.Settingmax_stack_depthhigher than the actual kernel limit will mean that a runaway recursive function can crash an individual backend process. On platforms wherePostgreSQLcan determine the kernel limit, the server will not allow this variable to be set to an unsafe value. However, not all platforms provide the information, so caution is recommended in selecting a value."
shared_memory_type,enum,"Specifies the shared memory implementation that the server should use for the main shared memory region that holdsPostgreSQL's shared buffers and other shared data. Possible values aremmap(for anonymous shared memory allocated usingmmap),sysv(for System V shared memory allocated viashmget) andwindows(for Windows shared memory). Not all values are supported on all platforms; the first supported option is the default for that platform. The use of thesysvoption, which is not the default on any platform, is generally discouraged because it typically requires non-default kernel settings to allow for large allocations (seeSection 18.4.1)."
dynamic_shared_memory_type,enum,"Specifies the dynamic shared memory implementation that the server should use. Possible values areposix(for POSIX shared memory allocated usingshm_open),sysv(for System V shared memory allocated viashmget),windows(for Windows shared memory), andmmap(to simulate shared memory using memory-mapped files stored in the data directory). Not all values are supported on all platforms; the first supported option is usually the default for that platform. The use of themmapoption, which is not the default on any platform, is generally discouraged because the operating system may write modified pages back to disk repeatedly, increasing system I/O load; however, it may be useful for debugging, when thepg_dynshmemdirectory is stored on a RAM disk, or when other shared memory facilities are not available."
min_dynamic_shared_memory,integer,"Specifies the amount of memory that should be allocated at server startup for use by parallel queries. When this memory region is insufficient or exhausted by concurrent queries, new parallel queries try to allocate extra shared memory temporarily from the operating system using the method configured withdynamic_shared_memory_type, which may be slower due to memory management overheads. Memory that is allocated at startup withmin_dynamic_shared_memoryis affected by thehuge_pagessetting on operating systems where that is supported, and may be more likely to benefit from larger pages on operating systems where that is managed automatically. The default value is0(none). This parameter can only be set at server start."
temp_file_limit,integer,"Specifies the maximum amount of disk space that a process can use for temporary files, such as sort and hash temporary files, or the storage file for a held cursor. A transaction attempting to exceed this limit will be canceled. If this value is specified without units, it is taken as kilobytes.-1(the default) means no limit. Only superusers and users with the appropriateSETprivilege can change this setting.This setting constrains the total space used at any instant by all temporary files used by a givenPostgreSQLprocess. It should be noted that disk space used for explicit temporary tables, as opposed to temporary files used behind-the-scenes in query execution, doesnotcount against this limit."
max_notify_queue_pages,integer,Specifies the maximum amount of allocated pages forNOTIFY/LISTENqueue. The default value is 1048576. For 8 KB pages it allows to consume up to 8 GB of disk space.
max_files_per_process,integer,"Sets the maximum number of simultaneously open files allowed to each server subprocess. The default is one thousand files. If the kernel is enforcing a safe per-process limit, you don't need to worry about this setting. But on some platforms (notably, most BSD systems), the kernel will allow individual processes to open many more files than the system can actually support if many processes all try to open that many files. If you find yourself seeing“Too many open files”failures, try reducing this setting. This parameter can only be set at server start."
vacuum_cost_delay,floating point,"The amount of time that the process will sleep when the cost limit has been exceeded. If this value is specified without units, it is taken as milliseconds. The default value is zero, which disables the cost-based vacuum delay feature. Positive values enable cost-based vacuuming.When using cost-based vacuuming, appropriate values forvacuum_cost_delayare usually quite small, perhaps less than 1 millisecond. Whilevacuum_cost_delaycan be set to fractional-millisecond values, such delays may not be measured accurately on older platforms. On such platforms, increasingVACUUM's throttled resource consumption above what you get at 1ms will require changing the other vacuum cost parameters. You should, nonetheless, keepvacuum_cost_delayas small as your platform will consistently measure; large delays are not helpful."
vacuum_cost_page_hit,integer,"The estimated cost for vacuuming a buffer found in the shared buffer cache. It represents the cost to lock the buffer pool, lookup the shared hash table and scan the content of the page. The default value is one."
vacuum_cost_page_miss,integer,"The estimated cost for vacuuming a buffer that has to be read from disk. This represents the effort to lock the buffer pool, lookup the shared hash table, read the desired block in from the disk and scan its content. The default value is 2."
vacuum_cost_page_dirty,integer,The estimated cost charged when vacuum modifies a block that was previously clean. It represents the extra I/O required to flush the dirty block out to disk again. The default value is 20.
vacuum_cost_limit,integer,This is the accumulated cost that will cause the vacuuming process to sleep forvacuum_cost_delay. The default is 200.
bgwriter_delay,integer,"Specifies the delay between activity rounds for the background writer. In each round the writer issues writes for some number of dirty buffers (controllable by the following parameters). It then sleeps for the length ofbgwriter_delay, and repeats. When there are no dirty buffers in the buffer pool, though, it goes into a longer sleep regardless ofbgwriter_delay. If this value is specified without units, it is taken as milliseconds. The default value is 200 milliseconds (200ms). Note that on some systems, the effective resolution of sleep delays is 10 milliseconds; settingbgwriter_delayto a value that is not a multiple of 10 might have the same results as setting it to the next higher multiple of 10. This parameter can only be set in thepostgresql.conffile or on the server command line."
bgwriter_lru_maxpages,integer,"In each round, no more than this many buffers will be written by the background writer. Setting this to zero disables background writing. (Note that checkpoints, which are managed by a separate, dedicated auxiliary process, are unaffected.) The default value is 100 buffers. This parameter can only be set in thepostgresql.conffile or on the server command line."
bgwriter_lru_multiplier,floating point,"The number of dirty buffers written in each round is based on the number of new buffers that have been needed by server processes during recent rounds. The average recent need is multiplied bybgwriter_lru_multiplierto arrive at an estimate of the number of buffers that will be needed during the next round. Dirty buffers are written until there are that many clean, reusable buffers available. (However, no more thanbgwriter_lru_maxpagesbuffers will be written per round.) Thus, a setting of 1.0 represents a“just in time”policy of writing exactly the number of buffers predicted to be needed. Larger values provide some cushion against spikes in demand, while smaller values intentionally leave writes to be done by server processes. The default is 2.0. This parameter can only be set in thepostgresql.conffile or on the server command line."
bgwriter_flush_after,integer,"Whenever more than this amount of data has been written by the background writer, attempt to force the OS to issue these writes to the underlying storage. Doing so will limit the amount of dirty data in the kernel's page cache, reducing the likelihood of stalls when anfsyncis issued at the end of a checkpoint, or when the OS writes data back in larger batches in the background. Often that will result in greatly reduced transaction latency, but there also are some cases, especially with workloads that are bigger thanshared_buffers, but smaller than the OS's page cache, where performance might degrade. This setting may have no effect on some platforms. If this value is specified without units, it is taken as blocks, that isBLCKSZbytes, typically 8kB. The valid range is between0, which disables forced writeback, and2MB. The default is512kBon Linux,0elsewhere. (IfBLCKSZis not 8kB, the default and maximum values scale proportionally to it.) This parameter can only be set in thepostgresql.conffile or on the server command line."
backend_flush_after,integer,"Whenever more than this amount of data has been written by a single backend, attempt to force the OS to issue these writes to the underlying storage. Doing so will limit the amount of dirty data in the kernel's page cache, reducing the likelihood of stalls when anfsyncis issued at the end of a checkpoint, or when the OS writes data back in larger batches in the background. Often that will result in greatly reduced transaction latency, but there also are some cases, especially with workloads that are bigger thanshared_buffers, but smaller than the OS's page cache, where performance might degrade. This setting may have no effect on some platforms. If this value is specified without units, it is taken as blocks, that isBLCKSZbytes, typically 8kB. The valid range is between0, which disables forced writeback, and2MB. The default is0, i.e., no forced writeback. (IfBLCKSZis not 8kB, the maximum value scales proportionally to it.)"
effective_io_concurrency,integer,"Sets the number of concurrent disk I/O operations thatPostgreSQLexpects can be executed simultaneously. Raising this value will increase the number of I/O operations that any individualPostgreSQLsession attempts to initiate in parallel. The allowed range is 1 to 1000, or zero to disable issuance of asynchronous I/O requests. Currently, this setting only affects bitmap heap scans.For magnetic drives, a good starting point for this setting is the number of separate drives comprising a RAID 0 stripe or RAID 1 mirror being used for the database. (For RAID 5 the parity drive should not be counted.) However, if the database is often busy with multiple queries issued in concurrent sessions, lower values may be sufficient to keep the disk array busy. A value higher than needed to keep the disks busy will only result in extra CPU overhead. SSDs and other memory-based storage can often process many concurrent requests, so the best value might be in the hundreds.Asynchronous I/O depends on an effectiveposix_fadvisefunction, which some operating systems lack. If the function is not present then setting this parameter to anything but zero will result in an error. On some operating systems (e.g., Solaris), the function is present but does not actually do anything.The default is 1 on supported systems, otherwise 0. This value can be overridden for tables in a particular tablespace by setting the tablespace parameter of the same name (seeALTER TABLESPACE)."
maintenance_io_concurrency,integer,"Similar toeffective_io_concurrency, but used for maintenance work that is done on behalf of many client sessions.The default is 10 on supported systems, otherwise 0. This value can be overridden for tables in a particular tablespace by setting the tablespace parameter of the same name (seeALTER TABLESPACE)."
io_combine_limit,integer,Controls the largest I/O size in operations that combine I/O. The default is 128kB.
max_worker_processes,integer,"Sets the maximum number of background processes that the cluster can support. This parameter can only be set at server start. The default is 8.When running a standby server, you must set this parameter to the same or higher value than on the primary server. Otherwise, queries will not be allowed in the standby server.When changing this value, consider also adjustingmax_parallel_workers,max_parallel_maintenance_workers, andmax_parallel_workers_per_gather."
max_parallel_workers_per_gather,integer,"Sets the maximum number of workers that can be started by a singleGatherorGather Mergenode. Parallel workers are taken from the pool of processes established bymax_worker_processes, limited bymax_parallel_workers. Note that the requested number of workers may not actually be available at run time. If this occurs, the plan will run with fewer workers than expected, which may be inefficient. The default value is 2. Setting this value to 0 disables parallel query execution.Note that parallel queries may consume very substantially more resources than non-parallel queries, because each worker process is a completely separate process which has roughly the same impact on the system as an additional user session. This should be taken into account when choosing a value for this setting, as well as when configuring other settings that control resource utilization, such aswork_mem. Resource limits such aswork_memare applied individually to each worker, which means the total utilization may be much higher across all processes than it would normally be for any single process. For example, a parallel query using 4 workers may use up to 5 times as much CPU time, memory, I/O bandwidth, and so forth as a query which uses no workers at all.For more information on parallel query, seeChapter 15."
max_parallel_maintenance_workers,integer,"Sets the maximum number of parallel workers that can be started by a single utility command. Currently, the parallel utility commands that support the use of parallel workers areCREATE INDEXwhen building a B-tree or BRIN index, andVACUUMwithoutFULLoption. Parallel workers are taken from the pool of processes established bymax_worker_processes, limited bymax_parallel_workers. Note that the requested number of workers may not actually be available at run time. If this occurs, the utility operation will run with fewer workers than expected. The default value is 2. Setting this value to 0 disables the use of parallel workers by utility commands.Note that parallel utility commands should not consume substantially more memory than equivalent non-parallel operations. This strategy differs from that of parallel query, where resource limits generally apply per worker process. Parallel utility commands treat the resource limitmaintenance_work_memas a limit to be applied to the entire utility command, regardless of the number of parallel worker processes. However, parallel utility commands may still consume substantially more CPU resources and I/O bandwidth."
max_parallel_workers,integer,"Sets the maximum number of workers that the cluster can support for parallel operations. The default value is 8. When increasing or decreasing this value, consider also adjustingmax_parallel_maintenance_workersandmax_parallel_workers_per_gather. Also, note that a setting for this value which is higher thanmax_worker_processeswill have no effect, since parallel workers are taken from the pool of worker processes established by that setting."
parallel_leader_participation,boolean,"Allows the leader process to execute the query plan underGatherandGather Mergenodes instead of waiting for worker processes. The default ison. Setting this value tooffreduces the likelihood that workers will become blocked because the leader is not reading tuples fast enough, but requires the leader process to wait for worker processes to start up before the first tuples can be produced. The degree to which the leader can help or hinder performance depends on the plan type, number of workers and query duration."
wal_level,enum,"wal_leveldetermines how much information is written to the WAL. The default value isreplica, which writes enough data to support WAL archiving and replication, including running read-only queries on a standby server.minimalremoves all logging except the information required to recover from a crash or immediate shutdown. Finally,logicaladds information necessary to support logical decoding. Each level includes the information logged at all lower levels. This parameter can only be set at server start.Theminimallevel generates the least WAL volume. It logs no row information for permanent relations in transactions that create or rewrite them. This can make operations much faster (seeSection 14.4.7). Operations that initiate this optimization include:ALTER ... SET TABLESPACECLUSTERCREATE TABLEREFRESH MATERIALIZED VIEW(withoutCONCURRENTLY)REINDEXTRUNCATEHowever, minimal WAL does not contain sufficient information for point-in-time recovery, soreplicaor higher must be used to enable continuous archiving (archive_mode) and streaming binary replication. In fact, the server will not even start in this mode ifmax_wal_sendersis non-zero. Note that changingwal_leveltominimalmakes previous base backups unusable for point-in-time recovery and standby servers.Inlogicallevel, the same information is logged as withreplica, plus information needed to extract logical change sets from the WAL. Using a level oflogicalwill increase the WAL volume, particularly if many tables are configured forREPLICA IDENTITY FULLand manyUPDATEandDELETEstatements are executed.In releases prior to 9.6, this parameter also allowed the valuesarchiveandhot_standby. These are still accepted but mapped toreplica."
fsync,boolean,"If this parameter is on, thePostgreSQLserver will try to make sure that updates are physically written to disk, by issuingfsync()system calls or various equivalent methods (seewal_sync_method). This ensures that the database cluster can recover to a consistent state after an operating system or hardware crash.While turning offfsyncis often a performance benefit, this can result in unrecoverable data corruption in the event of a power failure or system crash. Thus it is only advisable to turn offfsyncif you can easily recreate your entire database from external data.Examples of safe circumstances for turning offfsyncinclude the initial loading of a new database cluster from a backup file, using a database cluster for processing a batch of data after which the database will be thrown away and recreated, or for a read-only database clone which gets recreated frequently and is not used for failover. High quality hardware alone is not a sufficient justification for turning offfsync.For reliable recovery when changingfsyncoff to on, it is necessary to force all modified buffers in the kernel to durable storage. This can be done while the cluster is shutdown or whilefsyncis on by runninginitdb --sync-only, runningsync, unmounting the file system, or rebooting the server.In many situations, turning offsynchronous_commitfor noncritical transactions can provide much of the potential performance benefit of turning offfsync, without the attendant risks of data corruption.fsynccan only be set in thepostgresql.conffile or on the server command line. If you turn this parameter off, also consider turning offfull_page_writes."
synchronous_commit,enum,"Specifies how much WAL processing must complete before the database server returns a“success”indication to the client. Valid values areremote_apply,on(the default),remote_write,local, andoff.Ifsynchronous_standby_namesis empty, the only meaningful settings areonandoff;remote_apply,remote_writeandlocalall provide the same local synchronization level ason. The local behavior of all non-offmodes is to wait for local flush of WAL to disk. Inoffmode, there is no waiting, so there can be a delay between when success is reported to the client and when the transaction is later guaranteed to be safe against a server crash. (The maximum delay is three timeswal_writer_delay.) Unlikefsync, setting this parameter tooffdoes not create any risk of database inconsistency: an operating system or database crash might result in some recent allegedly-committed transactions being lost, but the database state will be just the same as if those transactions had been aborted cleanly. So, turningsynchronous_commitoff can be a useful alternative when performance is more important than exact certainty about the durability of a transaction. For more discussion seeSection 28.4.Ifsynchronous_standby_namesis non-empty,synchronous_commitalso controls whether transaction commits will wait for their WAL records to be processed on the standby server(s).When set toremote_apply, commits will wait until replies from the current synchronous standby(s) indicate they have received the commit record of the transaction and applied it, so that it has become visible to queries on the standby(s), and also written to durable storage on the standbys. This will cause much larger commit delays than previous settings since it waits for WAL replay. When set toon, commits wait until replies from the current synchronous standby(s) indicate they have received the commit record of the transaction and flushed it to durable storage. This ensures the transaction will not be lost unless both the primary and all synchronous standbys suffer corruption of their database storage. When set toremote_write, commits will wait until replies from the current synchronous standby(s) indicate they have received the commit record of the transaction and written it to their file systems. This setting ensures data preservation if a standby instance ofPostgreSQLcrashes, but not if the standby suffers an operating-system-level crash because the data has not necessarily reached durable storage on the standby. The settinglocalcauses commits to wait for local flush to disk, but not for replication. This is usually not desirable when synchronous replication is in use, but is provided for completeness.This parameter can be changed at any time; the behavior for any one transaction is determined by the setting in effect when it commits. It is therefore possible, and useful, to have some transactions commit synchronously and others asynchronously. For example, to make a single multistatement transaction commit asynchronously when the default is the opposite, issueSET LOCAL synchronous_commit TO OFFwithin the transaction.Table 19.1summarizes the capabilities of thesynchronous_commitsettings.Table 19.1. synchronous_commit Modessynchronous_commit settinglocal durable commitstandby durable commit after PG crashstandby durable commit after OS crashstandby query consistencyremote_apply••••on•••remote_write••local•off"
wal_sync_method,enum,"Method used for forcing WAL updates out to disk. Iffsyncis off then this setting is irrelevant, since WAL file updates will not be forced out at all. Possible values are:open_datasync(write WAL files withopen()optionO_DSYNC)fdatasync(callfdatasync()at each commit)fsync(callfsync()at each commit)fsync_writethrough(callfsync()at each commit, forcing write-through of any disk write cache)open_sync(write WAL files withopen()optionO_SYNC)Not all of these choices are available on all platforms. The default is the first method in the above list that is supported by the platform, except thatfdatasyncis the default on Linux and FreeBSD. The default is not necessarily ideal; it might be necessary to change this setting or other aspects of your system configuration in order to create a crash-safe configuration or achieve optimal performance. These aspects are discussed inSection 28.1. This parameter can only be set in thepostgresql.conffile or on the server command line."
full_page_writes,boolean,"When this parameter is on, thePostgreSQLserver writes the entire content of each disk page to WAL during the first modification of that page after a checkpoint. This is needed because a page write that is in process during an operating system crash might be only partially completed, leading to an on-disk page that contains a mix of old and new data. The row-level change data normally stored in WAL will not be enough to completely restore such a page during post-crash recovery. Storing the full page image guarantees that the page can be correctly restored, but at the price of increasing the amount of data that must be written to WAL. (Because WAL replay always starts from a checkpoint, it is sufficient to do this during the first change of each page after a checkpoint. Therefore, one way to reduce the cost of full-page writes is to increase the checkpoint interval parameters.)Turning this parameter off speeds normal operation, but might lead to either unrecoverable data corruption, or silent data corruption, after a system failure. The risks are similar to turning offfsync, though smaller, and it should be turned off only based on the same circumstances recommended for that parameter.Turning off this parameter does not affect use of WAL archiving for point-in-time recovery (PITR) (seeSection 25.3).This parameter can only be set in thepostgresql.conffile or on the server command line. The default ison."
wal_log_hints,boolean,"When this parameter ison, thePostgreSQLserver writes the entire content of each disk page to WAL during the first modification of that page after a checkpoint, even for non-critical modifications of so-called hint bits.If data checksums are enabled, hint bit updates are always WAL-logged and this setting is ignored. You can use this setting to test how much extra WAL-logging would occur if your database had data checksums enabled.This parameter can only be set at server start. The default value isoff."
wal_compression,enum,"This parameter enables compression of WAL using the specified compression method. When enabled, thePostgreSQLserver compresses full page images written to WAL whenfull_page_writesis on or during a base backup. A compressed page image will be decompressed during WAL replay. The supported methods arepglz,lz4(ifPostgreSQLwas compiled with--with-lz4) andzstd(ifPostgreSQLwas compiled with--with-zstd). The default value isoff. Only superusers and users with the appropriateSETprivilege can change this setting.Enabling compression can reduce the WAL volume without increasing the risk of unrecoverable data corruption, but at the cost of some extra CPU spent on the compression during WAL logging and on the decompression during WAL replay."
wal_init_zero,boolean,"If set toon(the default), this option causes new WAL files to be filled with zeroes. On some file systems, this ensures that space is allocated before we need to write WAL records. However,Copy-On-Write(COW) file systems may not benefit from this technique, so the option is given to skip the unnecessary work. If set tooff, only the final byte is written when the file is created so that it has the expected size."
wal_recycle,boolean,"If set toon(the default), this option causes WAL files to be recycled by renaming them, avoiding the need to create new ones. On COW file systems, it may be faster to create new ones, so the option is given to disable this behavior."
wal_buffers,integer,"The amount of shared memory used for WAL data that has not yet been written to disk. The default setting of -1 selects a size equal to 1/32nd (about 3%) ofshared_buffers, but not less than64kBnor more than the size of one WAL segment, typically16MB. This value can be set manually if the automatic choice is too large or too small, but any positive value less than32kBwill be treated as32kB. If this value is specified without units, it is taken as WAL blocks, that isXLOG_BLCKSZbytes, typically 8kB. This parameter can only be set at server start.The contents of the WAL buffers are written out to disk at every transaction commit, so extremely large values are unlikely to provide a significant benefit. However, setting this value to at least a few megabytes can improve write performance on a busy server where many clients are committing at once. The auto-tuning selected by the default setting of -1 should give reasonable results in most cases."
wal_writer_delay,integer,"Specifies how often the WAL writer flushes WAL, in time terms. After flushing WAL the writer sleeps for the length of time given bywal_writer_delay, unless woken up sooner by an asynchronously committing transaction. If the last flush happened less thanwal_writer_delayago and less thanwal_writer_flush_afterworth of WAL has been produced since, then WAL is only written to the operating system, not flushed to disk. If this value is specified without units, it is taken as milliseconds. The default value is 200 milliseconds (200ms). Note that on some systems, the effective resolution of sleep delays is 10 milliseconds; settingwal_writer_delayto a value that is not a multiple of 10 might have the same results as setting it to the next higher multiple of 10. This parameter can only be set in thepostgresql.conffile or on the server command line."
wal_writer_flush_after,integer,"Specifies how often the WAL writer flushes WAL, in volume terms. If the last flush happened less thanwal_writer_delayago and less thanwal_writer_flush_afterworth of WAL has been produced since, then WAL is only written to the operating system, not flushed to disk. Ifwal_writer_flush_afteris set to0then WAL data is always flushed immediately. If this value is specified without units, it is taken as WAL blocks, that isXLOG_BLCKSZbytes, typically 8kB. The default is1MB. This parameter can only be set in thepostgresql.conffile or on the server command line."
wal_skip_threshold,integer,"Whenwal_levelisminimaland a transaction commits after creating or rewriting a permanent relation, this setting determines how to persist the new data. If the data is smaller than this setting, write it to the WAL log; otherwise, use an fsync of affected files. Depending on the properties of your storage, raising or lowering this value might help if such commits are slowing concurrent transactions. If this value is specified without units, it is taken as kilobytes. The default is two megabytes (2MB)."
commit_delay,integer,"Settingcommit_delayadds a time delay before a WAL flush is initiated. This can improve group commit throughput by allowing a larger number of transactions to commit via a single WAL flush, if system load is high enough that additional transactions become ready to commit within the given interval. However, it also increases latency by up to thecommit_delayfor each WAL flush. Because the delay is just wasted if no other transactions become ready to commit, a delay is only performed if at leastcommit_siblingsother transactions are active when a flush is about to be initiated. Also, no delays are performed iffsyncis disabled. If this value is specified without units, it is taken as microseconds. The defaultcommit_delayis zero (no delay). Only superusers and users with the appropriateSETprivilege can change this setting.InPostgreSQLreleases prior to 9.3,commit_delaybehaved differently and was much less effective: it affected only commits, rather than all WAL flushes, and waited for the entire configured delay even if the WAL flush was completed sooner. Beginning inPostgreSQL9.3, the first process that becomes ready to flush waits for the configured interval, while subsequent processes wait only until the leader completes the flush operation."
commit_siblings,integer,Minimum number of concurrent open transactions to require before performing thecommit_delaydelay. A larger value makes it more probable that at least one other transaction will become ready to commit during the delay interval. The default is five transactions.
checkpoint_timeout,integer,"Maximum time between automatic WAL checkpoints. If this value is specified without units, it is taken as seconds. The valid range is between 30 seconds and one day. The default is five minutes (5min). Increasing this parameter can increase the amount of time needed for crash recovery. This parameter can only be set in thepostgresql.conffile or on the server command line."
checkpoint_completion_target,floating point,"Specifies the target of checkpoint completion, as a fraction of total time between checkpoints. The default is 0.9, which spreads the checkpoint across almost all of the available interval, providing fairly consistent I/O load while also leaving some time for checkpoint completion overhead. Reducing this parameter is not recommended because it causes the checkpoint to complete faster. This results in a higher rate of I/O during the checkpoint followed by a period of less I/O between the checkpoint completion and the next scheduled checkpoint. This parameter can only be set in thepostgresql.conffile or on the server command line."
checkpoint_flush_after,integer,"Whenever more than this amount of data has been written while performing a checkpoint, attempt to force the OS to issue these writes to the underlying storage. Doing so will limit the amount of dirty data in the kernel's page cache, reducing the likelihood of stalls when anfsyncis issued at the end of the checkpoint, or when the OS writes data back in larger batches in the background. Often that will result in greatly reduced transaction latency, but there also are some cases, especially with workloads that are bigger thanshared_buffers, but smaller than the OS's page cache, where performance might degrade. This setting may have no effect on some platforms. If this value is specified without units, it is taken as blocks, that isBLCKSZbytes, typically 8kB. The valid range is between0, which disables forced writeback, and2MB. The default is256kBon Linux,0elsewhere. (IfBLCKSZis not 8kB, the default and maximum values scale proportionally to it.) This parameter can only be set in thepostgresql.conffile or on the server command line."
checkpoint_warning,integer,"Write a message to the server log if checkpoints caused by the filling of WAL segment files happen closer together than this amount of time (which suggests thatmax_wal_sizeought to be raised). If this value is specified without units, it is taken as seconds. The default is 30 seconds (30s). Zero disables the warning. No warnings will be generated ifcheckpoint_timeoutis less thancheckpoint_warning. This parameter can only be set in thepostgresql.conffile or on the server command line."
max_wal_size,integer,"Maximum size to let the WAL grow during automatic checkpoints. This is a soft limit; WAL size can exceedmax_wal_sizeunder special circumstances, such as heavy load, a failingarchive_commandorarchive_library, or a highwal_keep_sizesetting. If this value is specified without units, it is taken as megabytes. The default is 1 GB. Increasing this parameter can increase the amount of time needed for crash recovery. This parameter can only be set in thepostgresql.conffile or on the server command line."
min_wal_size,integer,"As long as WAL disk usage stays below this setting, old WAL files are always recycled for future use at a checkpoint, rather than removed. This can be used to ensure that enough WAL space is reserved to handle spikes in WAL usage, for example when running large batch jobs. If this value is specified without units, it is taken as megabytes. The default is 80 MB. This parameter can only be set in thepostgresql.conffile or on the server command line."
archive_mode,enum,"Whenarchive_modeis enabled, completed WAL segments are sent to archive storage by settingarchive_commandorarchive_library. In addition tooff, to disable, there are two modes:on, andalways. During normal operation, there is no difference between the two modes, but when set toalwaysthe WAL archiver is enabled also during archive recovery or standby mode. Inalwaysmode, all files restored from the archive or streamed with streaming replication will be archived (again). SeeSection 26.2.9for details.archive_modeis a separate setting fromarchive_commandandarchive_libraryso thatarchive_commandandarchive_librarycan be changed without leaving archiving mode. This parameter can only be set at server start.archive_modecannot be enabled whenwal_levelis set tominimal."
archive_command,string,"The local shell command to execute to archive a completed WAL file segment. Any%pin the string is replaced by the path name of the file to archive, and any%fis replaced by only the file name. (The path name is relative to the working directory of the server, i.e., the cluster's data directory.) Use%%to embed an actual%character in the command. It is important for the command to return a zero exit status only if it succeeds. For more information seeSection 25.3.1.This parameter can only be set in thepostgresql.conffile or on the server command line. It is only used ifarchive_modewas enabled at server start andarchive_libraryis set to an empty string. If botharchive_commandandarchive_libraryare set, an error will be raised. Ifarchive_commandis an empty string (the default) whilearchive_modeis enabled (andarchive_libraryis set to an empty string), WAL archiving is temporarily disabled, but the server continues to accumulate WAL segment files in the expectation that a command will soon be provided. Settingarchive_commandto a command that does nothing but return true, e.g.,/bin/true(REMon Windows), effectively disables archiving, but also breaks the chain of WAL files needed for archive recovery, so it should only be used in unusual circumstances."
archive_library,string,"The library to use for archiving completed WAL file segments. If set to an empty string (the default), archiving via shell is enabled, andarchive_commandis used. If botharchive_commandandarchive_libraryare set, an error will be raised. Otherwise, the specified shared library is used for archiving. The WAL archiver process is restarted by the postmaster when this parameter changes. For more information, seeSection 25.3.1andChapter 49.This parameter can only be set in thepostgresql.conffile or on the server command line."
archive_timeout,integer,"Thearchive_commandorarchive_libraryis only invoked for completed WAL segments. Hence, if your server generates little WAL traffic (or has slack periods where it does so), there could be a long delay between the completion of a transaction and its safe recording in archive storage. To limit how old unarchived data can be, you can setarchive_timeoutto force the server to switch to a new WAL segment file periodically. When this parameter is greater than zero, the server will switch to a new segment file whenever this amount of time has elapsed since the last segment file switch, and there has been any database activity, including a single checkpoint (checkpoints are skipped if there is no database activity). Note that archived files that are closed early due to a forced switch are still the same length as completely full files. Therefore, it is unwise to use a very shortarchive_timeout— it will bloat your archive storage.archive_timeoutsettings of a minute or so are usually reasonable. You should consider using streaming replication, instead of archiving, if you want data to be copied off the primary server more quickly than that. If this value is specified without units, it is taken as seconds. This parameter can only be set in thepostgresql.conffile or on the server command line."
recovery_prefetch,enum,"Whether to try to prefetch blocks that are referenced in the WAL that are not yet in the buffer pool, during recovery. Valid values areoff,onandtry(the default). The settingtryenables prefetching only if the operating system provides theposix_fadvisefunction, which is currently used to implement prefetching. Note that some operating systems provide the function, but it doesn't do anything.Prefetching blocks that will soon be needed can reduce I/O wait times during recovery with some workloads. See also thewal_decode_buffer_sizeandmaintenance_io_concurrencysettings, which limit prefetching activity."
wal_decode_buffer_size,integer,"A limit on how far ahead the server can look in the WAL, to find blocks to prefetch. If this value is specified without units, it is taken as bytes. The default is 512kB."
restore_command,string,"The local shell command to execute to retrieve an archived segment of the WAL file series. This parameter is required for archive recovery, but optional for streaming replication. Any%fin the string is replaced by the name of the file to retrieve from the archive, and any%pis replaced by the copy destination path name on the server. (The path name is relative to the current working directory, i.e., the cluster's data directory.) Any%ris replaced by the name of the file containing the last valid restart point. That is the earliest file that must be kept to allow a restore to be restartable, so this information can be used to truncate the archive to just the minimum required to support restarting from the current restore.%ris typically only used by warm-standby configurations (seeSection 26.2). Write%%to embed an actual%character.It is important for the command to return a zero exit status only if it succeeds. The commandwillbe asked for file names that are not present in the archive; it must return nonzero when so asked. Examples:restore_command = 'cp /mnt/server/archivedir/%f ""%p""'
restore_command = 'copy ""C:\\server\\archivedir\\%f"" ""%p""'  # WindowsAn exception is that if the command was terminated by a signal (other thanSIGTERM, which is used as part of a database server shutdown) or an error by the shell (such as command not found), then recovery will abort and the server will not start up.This parameter can only be set in thepostgresql.conffile or on the server command line."
archive_cleanup_command,string,"This optional parameter specifies a shell command that will be executed at every restartpoint. The purpose ofarchive_cleanup_commandis to provide a mechanism for cleaning up old archived WAL files that are no longer needed by the standby server. Any%ris replaced by the name of the file containing the last valid restart point. That is the earliest file that must bekeptto allow a restore to be restartable, and so all files earlier than%rmay be safely removed. This information can be used to truncate the archive to just the minimum required to support restart from the current restore. Thepg_archivecleanupmodule is often used inarchive_cleanup_commandfor single-standby configurations, for example:archive_cleanup_command = 'pg_archivecleanup /mnt/server/archivedir %r'Note however that if multiple standby servers are restoring from the same archive directory, you will need to ensure that you do not delete WAL files until they are no longer needed by any of the servers.archive_cleanup_commandwould typically be used in a warm-standby configuration (seeSection 26.2). Write%%to embed an actual%character in the command.If the command returns a nonzero exit status then a warning log message will be written. An exception is that if the command was terminated by a signal or an error by the shell (such as command not found), a fatal error will be raised.This parameter can only be set in thepostgresql.conffile or on the server command line."
recovery_end_command,string,"This parameter specifies a shell command that will be executed once only at the end of recovery. This parameter is optional. The purpose of therecovery_end_commandis to provide a mechanism for cleanup following replication or recovery. Any%ris replaced by the name of the file containing the last valid restart point, like inarchive_cleanup_command.If the command returns a nonzero exit status then a warning log message will be written and the database will proceed to start up anyway. An exception is that if the command was terminated by a signal or an error by the shell (such as command not found), the database will not proceed with startup.This parameter can only be set in thepostgresql.conffile or on the server command line."
recovery_target,,"This parameter specifies that recovery should end as soon as a consistent state is reached, i.e., as early as possible. When restoring from an online backup, this means the point where taking the backup ended.Technically, this is a string parameter, but'immediate'is currently the only allowed value."
recovery_target_name,string,This parameter specifies the named restore point (created withpg_create_restore_point()) to which recovery will proceed.
recovery_target_time,timestamp,"This parameter specifies the time stamp up to which recovery will proceed. The precise stopping point is also influenced byrecovery_target_inclusive.The value of this parameter is a time stamp in the same format accepted by thetimestamp with time zonedata type, except that you cannot use a time zone abbreviation (unless thetimezone_abbreviationsvariable has been set earlier in the configuration file). Preferred style is to use a numeric offset from UTC, or you can write a full time zone name, e.g.,Europe/HelsinkinotEEST."
recovery_target_xid,string,"This parameter specifies the transaction ID up to which recovery will proceed. Keep in mind that while transaction IDs are assigned sequentially at transaction start, transactions can complete in a different numeric order. The transactions that will be recovered are those that committed before (and optionally including) the specified one. The precise stopping point is also influenced byrecovery_target_inclusive."
recovery_target_lsn,pg_lsn,This parameter specifies the LSN of the write-ahead log location up to which recovery will proceed. The precise stopping point is also influenced byrecovery_target_inclusive. This parameter is parsed using the system data typepg_lsn.
recovery_target_inclusive,boolean,"Specifies whether to stop just after the specified recovery target (on), or just before the recovery target (off). Applies whenrecovery_target_lsn,recovery_target_time, orrecovery_target_xidis specified. This setting controls whether transactions having exactly the target WAL location (LSN), commit time, or transaction ID, respectively, will be included in the recovery. Default ison."
recovery_target_timeline,string,"Specifies recovering into a particular timeline. The value can be a numeric timeline ID or a special value. The valuecurrentrecovers along the same timeline that was current when the base backup was taken. The valuelatestrecovers to the latest timeline found in the archive, which is useful in a standby server.latestis the default.To specify a timeline ID in hexadecimal (for example, if extracted from a WAL file name or history file), prefix it with a0x. For instance, if the WAL file name is00000011000000A10000004F, then the timeline ID is0x11(or 17 decimal).You usually only need to set this parameter in complex re-recovery situations, where you need to return to a state that itself was reached after a point-in-time recovery. SeeSection 25.3.6for discussion."
recovery_target_action,enum,"Specifies what action the server should take once the recovery target is reached. The default ispause, which means recovery will be paused.promotemeans the recovery process will finish and the server will start to accept connections. Finallyshutdownwill stop the server after reaching the recovery target.The intended use of thepausesetting is to allow queries to be executed against the database to check if this recovery target is the most desirable point for recovery. The paused state can be resumed by usingpg_wal_replay_resume()(seeTable 9.97), which then causes recovery to end. If this recovery target is not the desired stopping point, then shut down the server, change the recovery target settings to a later target and restart to continue recovery.Theshutdownsetting is useful to have the instance ready at the exact replay point desired. The instance will still be able to replay more WAL records (and in fact will have to replay WAL records since the last checkpoint next time it is started).Note that becauserecovery.signalwill not be removed whenrecovery_target_actionis set toshutdown, any subsequent start will end with immediate shutdown unless the configuration is changed or therecovery.signalfile is removed manually.This setting has no effect if no recovery target is set. Ifhot_standbyis not enabled, a setting ofpausewill act the same asshutdown. If the recovery target is reached while a promotion is ongoing, a setting ofpausewill act the same aspromote.In any case, if a recovery target is configured but the archive recovery ends before the target is reached, the server will shut down with a fatal error."
summarize_wal,boolean,"Enables the WAL summarizer process. Note that WAL summarization can be enabled either on a primary or on a standby. This parameter can only be set in thepostgresql.conffile or on the server command line. The default isoff.The server cannot be started withsummarize_wal=onifwal_levelis set tominimal. Ifsummarize_wal=onis configured after server startup whilewal_level=minimal, the summarizer will run but refuse to generate summary files for any WAL generated withwal_level=minimal."
wal_summary_keep_time,integer,"Configures the amount of time after which the WAL summarizer automatically removes old WAL summaries. The file timestamp is used to determine which files are old enough to remove. Typically, you should set this comfortably higher than the time that could pass between a backup and a later incremental backup that depends on it. WAL summaries must be available for the entire range of WAL records between the preceding backup and the new one being taken; if not, the incremental backup will fail. If this parameter is set to zero, WAL summaries will not be automatically deleted, but it is safe to manually remove files that you know will not be required for future incremental backups. This parameter can only be set in thepostgresql.conffile or on the server command line. If this value is specified without units, it is taken as minutes. The default is 10 days. Ifsummarize_wal = off, existing WAL summaries will not be removed regardless of the value of this parameter, because the WAL summarizer will not run."
max_wal_senders,integer,"Specifies the maximum number of concurrent connections from standby servers or streaming base backup clients (i.e., the maximum number of simultaneously running WAL sender processes). The default is10. The value0means replication is disabled. Abrupt disconnection of a streaming client might leave an orphaned connection slot behind until a timeout is reached, so this parameter should be set slightly higher than the maximum number of expected clients so disconnected clients can immediately reconnect. This parameter can only be set at server start. Also,wal_levelmust be set toreplicaor higher to allow connections from standby servers.When running a standby server, you must set this parameter to the same or higher value than on the primary server. Otherwise, queries will not be allowed in the standby server."
max_replication_slots,integer,"Specifies the maximum number of replication slots (seeSection 26.2.6) that the server can support. The default is 10. This parameter can only be set at server start. Setting it to a lower value than the number of currently existing replication slots will prevent the server from starting. Also,wal_levelmust be set toreplicaor higher to allow replication slots to be used.Note that this parameter also applies on the subscriber side, but with a different meaning."
wal_keep_size,integer,"Specifies the minimum size of past WAL files kept in thepg_waldirectory, in case a standby server needs to fetch them for streaming replication. If a standby server connected to the sending server falls behind by more thanwal_keep_sizemegabytes, the sending server might remove a WAL segment still needed by the standby, in which case the replication connection will be terminated. Downstream connections will also eventually fail as a result. (However, the standby server can recover by fetching the segment from archive, if WAL archiving is in use.)This sets only the minimum size of segments retained inpg_wal; the system might need to retain more segments for WAL archival or to recover from a checkpoint. Ifwal_keep_sizeis zero (the default), the system doesn't keep any extra segments for standby purposes, so the number of old WAL segments available to standby servers is a function of the location of the previous checkpoint and status of WAL archiving. If this value is specified without units, it is taken as megabytes. This parameter can only be set in thepostgresql.conffile or on the server command line."
max_slot_wal_keep_size,integer,"Specify the maximum size of WAL files thatreplication slotsare allowed to retain in thepg_waldirectory at checkpoint time. Ifmax_slot_wal_keep_sizeis -1 (the default), replication slots may retain an unlimited amount of WAL files. Otherwise, if restart_lsn of a replication slot falls behind the current LSN by more than the given size, the standby using the slot may no longer be able to continue replication due to removal of required WAL files. You can see the WAL availability of replication slots inpg_replication_slots. If this value is specified without units, it is taken as megabytes. This parameter can only be set in thepostgresql.conffile or on the server command line."
wal_sender_timeout,integer,"Terminate replication connections that are inactive for longer than this amount of time. This is useful for the sending server to detect a standby crash or network outage. If this value is specified without units, it is taken as milliseconds. The default value is 60 seconds. A value of zero disables the timeout mechanism.With a cluster distributed across multiple geographic locations, using different values per location brings more flexibility in the cluster management. A smaller value is useful for faster failure detection with a standby having a low-latency network connection, and a larger value helps in judging better the health of a standby if located on a remote location, with a high-latency network connection."
track_commit_timestamp,boolean,Record commit time of transactions. This parameter can only be set inpostgresql.conffile or on the server command line. The default value isoff.
synchronized_standby_slots,string,"A comma-separated list of streaming replication standby server slot names that logical WAL sender processes will wait for. Logical WAL sender processes will send decoded changes to plugins only after the specified replication slots confirm receiving WAL. This guarantees that logical replication failover slots do not consume changes until those changes are received and flushed to corresponding physical standbys. If a logical replication connection is meant to switch to a physical standby after the standby is promoted, the physical replication slot for the standby should be listed here. Note that logical replication will not proceed if the slots specified in thesynchronized_standby_slotsdo not exist or are invalidated. Additionally, the replication management functionspg_replication_slot_advance,pg_logical_slot_get_changes, andpg_logical_slot_peek_changes, when used with logical failover slots, will block until all physical slots specified insynchronized_standby_slotshave confirmed WAL receipt.The standbys corresponding to the physical replication slots insynchronized_standby_slotsmust configuresync_replication_slots = trueso they can receive logical failover slot changes from the primary."
synchronous_standby_names,string,"Specifies a list of standby servers that can supportsynchronous replication, as described inSection 26.2.8. There will be one or more active synchronous standbys; transactions waiting for commit will be allowed to proceed after these standby servers confirm receipt of their data. The synchronous standbys will be those whose names appear in this list, and that are both currently connected and streaming data in real-time (as shown by a state ofstreamingin thepg_stat_replicationview). Specifying more than one synchronous standby can allow for very high availability and protection against data loss.The name of a standby server for this purpose is theapplication_namesetting of the standby, as set in the standby's connection information. In case of a physical replication standby, this should be set in theprimary_conninfosetting; the default is the setting ofcluster_nameif set, elsewalreceiver. For logical replication, this can be set in the connection information of the subscription, and it defaults to the subscription name. For other replication stream consumers, consult their documentation.This parameter specifies a list of standby servers using either of the following syntaxes:[FIRST]num_sync(standby_name[, ...] )
ANYnum_sync(standby_name[, ...] )standby_name[, ...]wherenum_syncis the number of synchronous standbys that transactions need to wait for replies from, andstandby_nameis the name of a standby server.FIRSTandANYspecify the method to choose synchronous standbys from the listed servers.The keywordFIRST, coupled withnum_sync, specifies a priority-based synchronous replication and makes transaction commits wait until their WAL records are replicated tonum_syncsynchronous standbys chosen based on their priorities. For example, a setting ofFIRST 3 (s1, s2, s3, s4)will cause each commit to wait for replies from three higher-priority standbys chosen from standby serverss1,s2,s3ands4. The standbys whose names appear earlier in the list are given higher priority and will be considered as synchronous. Other standby servers appearing later in this list represent potential synchronous standbys. If any of the current synchronous standbys disconnects for whatever reason, it will be replaced immediately with the next-highest-priority standby. The keywordFIRSTis optional.The keywordANY, coupled withnum_sync, specifies a quorum-based synchronous replication and makes transaction commits wait until their WAL records are replicated toat leastnum_synclisted standbys. For example, a setting ofANY 3 (s1, s2, s3, s4)will cause each commit to proceed as soon as at least any three standbys ofs1,s2,s3ands4reply.FIRSTandANYare case-insensitive. If these keywords are used as the name of a standby server, itsstandby_namemust be double-quoted.The third syntax was used beforePostgreSQLversion 9.6 and is still supported. It's the same as the first syntax withFIRSTandnum_syncequal to 1. For example,FIRST 1 (s1, s2)ands1, s2have the same meaning: eithers1ors2is chosen as a synchronous standby.The special entry*matches any standby name.There is no mechanism to enforce uniqueness of standby names. In case of duplicates one of the matching standbys will be considered as higher priority, though exactly which one is indeterminate.NoteEachstandby_nameshould have the form of a valid SQL identifier, unless it is*. You can use double-quoting if necessary. But note thatstandby_names are compared to standby application names case-insensitively, whether double-quoted or not.If no synchronous standby names are specified here, then synchronous replication is not enabled and transaction commits will not wait for replication. This is the default configuration. Even when synchronous replication is enabled, individual transactions can be configured not to wait for replication by setting thesynchronous_commitparameter tolocaloroff.This parameter can only be set in thepostgresql.conffile or on the server command line."
primary_conninfo,string,"Specifies a connection string to be used for the standby server to connect with a sending server. This string is in the format described inSection 32.1.1. If any option is unspecified in this string, then the corresponding environment variable (seeSection 32.15) is checked. If the environment variable is not set either, then defaults are used.The connection string should specify the host name (or address) of the sending server, as well as the port number if it is not the same as the standby server's default. Also specify a user name corresponding to a suitably-privileged role on the sending server (seeSection 26.2.5.1). A password needs to be provided too, if the sender demands password authentication. It can be provided in theprimary_conninfostring, or in a separate~/.pgpassfile on the standby server (usereplicationas the database name).For replication slot synchronization (seeSection 47.2.3), it is also necessary to specify a validdbnamein theprimary_conninfostring. This will only be used for slot synchronization. It is ignored for streaming.This parameter can only be set in thepostgresql.conffile or on the server command line. If this parameter is changed while the WAL receiver process is running, that process is signaled to shut down and expected to restart with the new setting (except ifprimary_conninfois an empty string). This setting has no effect if the server is not in standby mode."
primary_slot_name,string,"Optionally specifies an existing replication slot to be used when connecting to the sending server via streaming replication to control resource removal on the upstream node (seeSection 26.2.6). This parameter can only be set in thepostgresql.conffile or on the server command line. If this parameter is changed while the WAL receiver process is running, that process is signaled to shut down and expected to restart with the new setting. This setting has no effect ifprimary_conninfois not set or the server is not in standby mode."
hot_standby,boolean,"Specifies whether or not you can connect and run queries during recovery, as described inSection 26.4. The default value ison. This parameter can only be set at server start. It only has effect during archive recovery or in standby mode."
max_standby_archive_delay,integer,"When hot standby is active, this parameter determines how long the standby server should wait before canceling standby queries that conflict with about-to-be-applied WAL entries, as described inSection 26.4.2.max_standby_archive_delayapplies when WAL data is being read from WAL archive (and is therefore not current). If this value is specified without units, it is taken as milliseconds. The default is 30 seconds. A value of -1 allows the standby to wait forever for conflicting queries to complete. This parameter can only be set in thepostgresql.conffile or on the server command line.Note thatmax_standby_archive_delayis not the same as the maximum length of time a query can run before cancellation; rather it is the maximum total time allowed to apply any one WAL segment's data. Thus, if one query has resulted in significant delay earlier in the WAL segment, subsequent conflicting queries will have much less grace time."
max_standby_streaming_delay,integer,"When hot standby is active, this parameter determines how long the standby server should wait before canceling standby queries that conflict with about-to-be-applied WAL entries, as described inSection 26.4.2.max_standby_streaming_delayapplies when WAL data is being received via streaming replication. If this value is specified without units, it is taken as milliseconds. The default is 30 seconds. A value of -1 allows the standby to wait forever for conflicting queries to complete. This parameter can only be set in thepostgresql.conffile or on the server command line.Note thatmax_standby_streaming_delayis not the same as the maximum length of time a query can run before cancellation; rather it is the maximum total time allowed to apply WAL data once it has been received from the primary server. Thus, if one query has resulted in significant delay, subsequent conflicting queries will have much less grace time until the standby server has caught up again."
wal_receiver_create_temp_slot,boolean,"Specifies whether the WAL receiver process should create a temporary replication slot on the remote instance when no permanent replication slot to use has been configured (usingprimary_slot_name). The default is off. This parameter can only be set in thepostgresql.conffile or on the server command line. If this parameter is changed while the WAL receiver process is running, that process is signaled to shut down and expected to restart with the new setting."
wal_receiver_status_interval,integer,"Specifies the minimum frequency for the WAL receiver process on the standby to send information about replication progress to the primary or upstream standby, where it can be seen using thepg_stat_replicationview. The standby will report the last write-ahead log location it has written, the last position it has flushed to disk, and the last position it has applied. This parameter's value is the maximum amount of time between reports. Updates are sent each time the write or flush positions change, or as often as specified by this parameter if set to a non-zero value. There are additional cases where updates are sent while ignoring this parameter; for example, when processing of the existing WAL completes or whensynchronous_commitis set toremote_apply. Thus, the apply position may lag slightly behind the true position. If this value is specified without units, it is taken as seconds. The default value is 10 seconds. This parameter can only be set in thepostgresql.conffile or on the server command line."
hot_standby_feedback,boolean,"Specifies whether or not a hot standby will send feedback to the primary or upstream standby about queries currently executing on the standby. This parameter can be used to eliminate query cancels caused by cleanup records, but can cause database bloat on the primary for some workloads. Feedback messages will not be sent more frequently than once perwal_receiver_status_interval. The default value isoff. This parameter can only be set in thepostgresql.conffile or on the server command line.If cascaded replication is in use the feedback is passed upstream until it eventually reaches the primary. Standbys make no other use of feedback they receive other than to pass upstream."
wal_receiver_timeout,integer,"Terminate replication connections that are inactive for longer than this amount of time. This is useful for the receiving standby server to detect a primary node crash or network outage. If this value is specified without units, it is taken as milliseconds. The default value is 60 seconds. A value of zero disables the timeout mechanism. This parameter can only be set in thepostgresql.conffile or on the server command line."
wal_retrieve_retry_interval,integer,"Specifies how long the standby server should wait when WAL data is not available from any sources (streaming replication, localpg_walor WAL archive) before trying again to retrieve WAL data. If this value is specified without units, it is taken as milliseconds. The default value is 5 seconds. This parameter can only be set in thepostgresql.conffile or on the server command line.This parameter is useful in configurations where a node in recovery needs to control the amount of time to wait for new WAL data to be available. For example, in archive recovery, it is possible to make the recovery more responsive in the detection of a new WAL file by reducing the value of this parameter. On a system with low WAL activity, increasing it reduces the amount of requests necessary to access WAL archives, something useful for example in cloud environments where the number of times an infrastructure is accessed is taken into account.In logical replication, this parameter also limits how often a failing replication apply worker will be respawned."
recovery_min_apply_delay,integer,"By default, a standby server restores WAL records from the sending server as soon as possible. It may be useful to have a time-delayed copy of the data, offering opportunities to correct data loss errors. This parameter allows you to delay recovery by a specified amount of time. For example, if you set this parameter to5min, the standby will replay each transaction commit only when the system time on the standby is at least five minutes past the commit time reported by the primary. If this value is specified without units, it is taken as milliseconds. The default is zero, adding no delay.It is possible that the replication delay between servers exceeds the value of this parameter, in which case no delay is added. Note that the delay is calculated between the WAL time stamp as written on primary and the current time on the standby. Delays in transfer because of network lag or cascading replication configurations may reduce the actual wait time significantly. If the system clocks on primary and standby are not synchronized, this may lead to recovery applying records earlier than expected; but that is not a major issue because useful settings of this parameter are much larger than typical time deviations between servers.The delay occurs only on WAL records for transaction commits. Other records are replayed as quickly as possible, which is not a problem because MVCC visibility rules ensure their effects are not visible until the corresponding commit record is applied.The delay occurs once the database in recovery has reached a consistent state, until the standby is promoted or triggered. After that the standby will end recovery without further waiting.WAL records must be kept on the standby until they are ready to be applied. Therefore, longer delays will result in a greater accumulation of WAL files, increasing disk space requirements for the standby'spg_waldirectory.This parameter is intended for use with streaming replication deployments; however, if the parameter is specified it will be honored in all cases except crash recovery.hot_standby_feedbackwill be delayed by use of this feature which could lead to bloat on the primary; use both together with care.WarningSynchronous replication is affected by this setting whensynchronous_commitis set toremote_apply; everyCOMMITwill need to wait to be applied.This parameter can only be set in thepostgresql.conffile or on the server command line."
sync_replication_slots,boolean,It enables a physical standby to synchronize logical failover slots from the primary server so that logical subscribers can resume replication from the new primary server after failover.It is disabled by default. This parameter can only be set in thepostgresql.conffile or on the server command line.
max_replication_slots,integer,"Specifies how many replication origins (seeChapter 48) can be tracked simultaneously, effectively limiting how many logical replication subscriptions can be created on the server. Setting it to a lower value than the current number of tracked replication origins (reflected inpg_replication_origin_status) will prevent the server from starting.max_replication_slotsmust be set to at least the number of subscriptions that will be added to the subscriber, plus some reserve for table synchronization.Note that this parameter also applies on a sending server, but with a different meaning."
max_logical_replication_workers,integer,"Specifies maximum number of logical replication workers. This includes leader apply workers, parallel apply workers, and table synchronization workers.Logical replication workers are taken from the pool defined bymax_worker_processes.The default value is 4. This parameter can only be set at server start."
max_sync_workers_per_subscription,integer,"Maximum number of synchronization workers per subscription. This parameter controls the amount of parallelism of the initial data copy during the subscription initialization or when new tables are added.Currently, there can be only one synchronization worker per table.The synchronization workers are taken from the pool defined bymax_logical_replication_workers.The default value is 2. This parameter can only be set in thepostgresql.conffile or on the server command line."
max_parallel_apply_workers_per_subscription,integer,Maximum number of parallel apply workers per subscription. This parameter controls the amount of parallelism for streaming of in-progress transactions with subscription parameterstreaming = parallel.The parallel apply workers are taken from the pool defined bymax_logical_replication_workers.The default value is 2. This parameter can only be set in thepostgresql.conffile or on the server command line.
enable_async_append,boolean,Enables or disables the query planner's use of async-aware append plan types. The default ison.
enable_bitmapscan,boolean,Enables or disables the query planner's use of bitmap-scan plan types. The default ison.
enable_gathermerge,boolean,Enables or disables the query planner's use of gather merge plan types. The default ison.
enable_group_by_reordering,boolean,"Controls if the query planner will produce a plan which will provideGROUP BYkeys sorted in the order of keys of a child node of the plan, such as an index scan. When disabled, the query planner will produce a plan withGROUP BYkeys only sorted to match theORDER BYclause, if any. When enabled, the planner will try to produce a more efficient plan. The default value ison."
enable_hashagg,boolean,Enables or disables the query planner's use of hashed aggregation plan types. The default ison.
enable_hashjoin,boolean,Enables or disables the query planner's use of hash-join plan types. The default ison.
enable_incremental_sort,boolean,Enables or disables the query planner's use of incremental sort steps. The default ison.
enable_indexscan,boolean,Enables or disables the query planner's use of index-scan and index-only-scan plan types. The default ison. Also seeenable_indexonlyscan.
enable_indexonlyscan,boolean,Enables or disables the query planner's use of index-only-scan plan types (seeSection 11.9). The default ison. Theenable_indexscansetting must also be enabled to have the query planner consider index-only-scans.
enable_material,boolean,"Enables or disables the query planner's use of materialization. It is impossible to suppress materialization entirely, but turning this variable off prevents the planner from inserting materialize nodes except in cases where it is required for correctness. The default ison."
enable_memoize,boolean,Enables or disables the query planner's use of memoize plans for caching results from parameterized scans inside nested-loop joins. This plan type allows scans to the underlying plans to be skipped when the results for the current parameters are already in the cache. Less commonly looked up results may be evicted from the cache when more space is required for new entries. The default ison.
enable_mergejoin,boolean,Enables or disables the query planner's use of merge-join plan types. The default ison.
enable_nestloop,boolean,"Enables or disables the query planner's use of nested-loop join plans. It is impossible to suppress nested-loop joins entirely, but turning this variable off discourages the planner from using one if there are other methods available. The default ison."
enable_parallel_append,boolean,Enables or disables the query planner's use of parallel-aware append plan types. The default ison.
enable_parallel_hash,boolean,Enables or disables the query planner's use of hash-join plan types with parallel hash. Has no effect if hash-join plans are not also enabled. The default ison.
enable_partition_pruning,boolean,Enables or disables the query planner's ability to eliminate a partitioned table's partitions from query plans. This also controls the planner's ability to generate query plans which allow the query executor to remove (ignore) partitions during query execution. The default ison. SeeSection 5.12.4for details.
enable_partitionwise_join,boolean,"Enables or disables the query planner's use of partitionwise join, which allows a join between partitioned tables to be performed by joining the matching partitions. Partitionwise join currently applies only when the join conditions include all the partition keys, which must be of the same data type and have one-to-one matching sets of child partitions. With this setting enabled, the number of nodes whose memory usage is restricted bywork_memappearing in the final plan can increase linearly according to the number of partitions being scanned. This can result in a large increase in overall memory consumption during the execution of the query. Query planning also becomes significantly more expensive in terms of memory and CPU. The default value isoff."
enable_partitionwise_aggregate,boolean,"Enables or disables the query planner's use of partitionwise grouping or aggregation, which allows grouping or aggregation on partitioned tables to be performed separately for each partition. If theGROUP BYclause does not include the partition keys, only partial aggregation can be performed on a per-partition basis, and finalization must be performed later. With this setting enabled, the number of nodes whose memory usage is restricted bywork_memappearing in the final plan can increase linearly according to the number of partitions being scanned. This can result in a large increase in overall memory consumption during the execution of the query. Query planning also becomes significantly more expensive in terms of memory and CPU. The default value isoff."
enable_presorted_aggregate,boolean,"Controls if the query planner will produce a plan which will provide rows which are presorted in the order required for the query'sORDER BY/DISTINCTaggregate functions. When disabled, the query planner will produce a plan which will always require the executor to perform a sort before performing aggregation of each aggregate function containing anORDER BYorDISTINCTclause. When enabled, the planner will try to produce a more efficient plan which provides input to the aggregate functions which is presorted in the order they require for aggregation. The default value ison."
enable_seqscan,boolean,"Enables or disables the query planner's use of sequential scan plan types. It is impossible to suppress sequential scans entirely, but turning this variable off discourages the planner from using one if there are other methods available. The default ison."
enable_sort,boolean,"Enables or disables the query planner's use of explicit sort steps. It is impossible to suppress explicit sorts entirely, but turning this variable off discourages the planner from using one if there are other methods available. The default ison."
enable_tidscan,boolean,Enables or disables the query planner's use ofTIDscan plan types. The default ison.
seq_page_cost,floating point,Sets the planner's estimate of the cost of a disk page fetch that is part of a series of sequential fetches. The default is 1.0. This value can be overridden for tables and indexes in a particular tablespace by setting the tablespace parameter of the same name (seeALTER TABLESPACE).
random_page_cost,floating point,"Sets the planner's estimate of the cost of a non-sequentially-fetched disk page. The default is 4.0. This value can be overridden for tables and indexes in a particular tablespace by setting the tablespace parameter of the same name (seeALTER TABLESPACE).Reducing this value relative toseq_page_costwill cause the system to prefer index scans; raising it will make index scans look relatively more expensive. You can raise or lower both values together to change the importance of disk I/O costs relative to CPU costs, which are described by the following parameters.Random access to mechanical disk storage is normally much more expensive than four times sequential access. However, a lower default is used (4.0) because the majority of random accesses to disk, such as indexed reads, are assumed to be in cache. The default value can be thought of as modeling random access as 40 times slower than sequential, while expecting 90% of random reads to be cached.If you believe a 90% cache rate is an incorrect assumption for your workload, you can increase random_page_cost to better reflect the true cost of random storage reads. Correspondingly, if your data is likely to be completely in cache, such as when the database is smaller than the total server memory, decreasing random_page_cost can be appropriate. Storage that has a low random read cost relative to sequential, e.g., solid-state drives, might also be better modeled with a lower value for random_page_cost, e.g.,1.1.TipAlthough the system will let you setrandom_page_costto less thanseq_page_cost, it is not physically sensible to do so. However, setting them equal makes sense if the database is entirely cached in RAM, since in that case there is no penalty for touching pages out of sequence. Also, in a heavily-cached database you should lower both values relative to the CPU parameters, since the cost of fetching a page already in RAM is much smaller than it would normally be."
cpu_tuple_cost,floating point,Sets the planner's estimate of the cost of processing each row during a query. The default is 0.01.
cpu_index_tuple_cost,floating point,Sets the planner's estimate of the cost of processing each index entry during an index scan. The default is 0.005.
cpu_operator_cost,floating point,Sets the planner's estimate of the cost of processing each operator or function executed during a query. The default is 0.0025.
parallel_setup_cost,floating point,Sets the planner's estimate of the cost of launching parallel worker processes. The default is 1000.
parallel_tuple_cost,floating point,Sets the planner's estimate of the cost of transferring one tuple from a parallel worker process to another process. The default is 0.1.
min_parallel_table_scan_size,integer,"Sets the minimum amount of table data that must be scanned in order for a parallel scan to be considered. For a parallel sequential scan, the amount of table data scanned is always equal to the size of the table, but when indexes are used the amount of table data scanned will normally be less. If this value is specified without units, it is taken as blocks, that isBLCKSZbytes, typically 8kB. The default is 8 megabytes (8MB)."
min_parallel_index_scan_size,integer,"Sets the minimum amount of index data that must be scanned in order for a parallel scan to be considered. Note that a parallel index scan typically won't touch the entire index; it is the number of pages which the planner believes will actually be touched by the scan which is relevant. This parameter is also used to decide whether a particular index can participate in a parallel vacuum. SeeVACUUM. If this value is specified without units, it is taken as blocks, that isBLCKSZbytes, typically 8kB. The default is 512 kilobytes (512kB)."
effective_cache_size,integer,"Sets the planner's assumption about the effective size of the disk cache that is available to a single query. This is factored into estimates of the cost of using an index; a higher value makes it more likely index scans will be used, a lower value makes it more likely sequential scans will be used. When setting this parameter you should consider bothPostgreSQL's shared buffers and the portion of the kernel's disk cache that will be used forPostgreSQLdata files, though some data might exist in both places. Also, take into account the expected number of concurrent queries on different tables, since they will have to share the available space. This parameter has no effect on the size of shared memory allocated byPostgreSQL, nor does it reserve kernel disk cache; it is used only for estimation purposes. The system also does not assume data remains in the disk cache between queries. If this value is specified without units, it is taken as blocks, that isBLCKSZbytes, typically 8kB. The default is 4 gigabytes (4GB). (IfBLCKSZis not 8kB, the default value scales proportionally to it.)"
jit_above_cost,floating point,"Sets the query cost above which JIT compilation is activated, if enabled (seeChapter 30). PerformingJITcosts planning time but can accelerate query execution. Setting this to-1disables JIT compilation. The default is100000."
jit_inline_above_cost,floating point,"Sets the query cost above which JIT compilation attempts to inline functions and operators. Inlining adds planning time, but can improve execution speed. It is not meaningful to set this to less thanjit_above_cost. Setting this to-1disables inlining. The default is500000."
jit_optimize_above_cost,floating point,"Sets the query cost above which JIT compilation applies expensive optimizations. Such optimization adds planning time, but can improve execution speed. It is not meaningful to set this to less thanjit_above_cost, and it is unlikely to be beneficial to set it to more thanjit_inline_above_cost. Setting this to-1disables expensive optimizations. The default is500000."
geqo,boolean,Enables or disables genetic query optimization. This is on by default. It is usually best not to turn it off in production; thegeqo_thresholdvariable provides more granular control of GEQO.
geqo_threshold,integer,"Use genetic query optimization to plan queries with at least this manyFROMitems involved. (Note that aFULL OUTER JOINconstruct counts as only oneFROMitem.) The default is 12. For simpler queries it is usually best to use the regular, exhaustive-search planner, but for queries with many tables the exhaustive search takes too long, often longer than the penalty of executing a suboptimal plan. Thus, a threshold on the size of the query is a convenient way to manage use of GEQO."
geqo_effort,integer,"Controls the trade-off between planning time and query plan quality in GEQO. This variable must be an integer in the range from 1 to 10. The default value is five. Larger values increase the time spent doing query planning, but also increase the likelihood that an efficient query plan will be chosen.geqo_effortdoesn't actually do anything directly; it is only used to compute the default values for the other variables that influence GEQO behavior (described below). If you prefer, you can set the other parameters by hand instead."
geqo_pool_size,integer,"Controls the pool size used by GEQO, that is the number of individuals in the genetic population. It must be at least two, and useful values are typically 100 to 1000. If it is set to zero (the default setting) then a suitable value is chosen based ongeqo_effortand the number of tables in the query."
geqo_generations,integer,"Controls the number of generations used by GEQO, that is the number of iterations of the algorithm. It must be at least one, and useful values are in the same range as the pool size. If it is set to zero (the default setting) then a suitable value is chosen based ongeqo_pool_size."
geqo_selection_bias,floating point,Controls the selection bias used by GEQO. The selection bias is the selective pressure within the population. Values can be from 1.50 to 2.00; the latter is the default.
geqo_seed,floating point,"Controls the initial value of the random number generator used by GEQO to select random paths through the join order search space. The value can range from zero (the default) to one. Varying the value changes the set of join paths explored, and may result in a better or worse best path being found."
default_statistics_target,integer,"Sets the default statistics target for table columns without a column-specific target set viaALTER TABLE SET STATISTICS. Larger values increase the time needed to doANALYZE, but might improve the quality of the planner's estimates. The default is 100. For more information on the use of statistics by thePostgreSQLquery planner, refer toSection 14.2."
constraint_exclusion,enum,"Controls the query planner's use of table constraints to optimize queries. The allowed values ofconstraint_exclusionareon(examine constraints for all tables),off(never examine constraints), andpartition(examine constraints only for inheritance child tables andUNION ALLsubqueries).partitionis the default setting. It is often used with traditional inheritance trees to improve performance.When this parameter allows it for a particular table, the planner compares query conditions with the table'sCHECKconstraints, and omits scanning tables for which the conditions contradict the constraints. For example:CREATE TABLE parent(key integer, ...);
CREATE TABLE child1000(check (key between 1000 and 1999)) INHERITS(parent);
CREATE TABLE child2000(check (key between 2000 and 2999)) INHERITS(parent);
...
SELECT * FROM parent WHERE key = 2400;With constraint exclusion enabled, thisSELECTwill not scanchild1000at all, improving performance.Currently, constraint exclusion is enabled by default only for cases that are often used to implement table partitioning via inheritance trees. Turning it on for all tables imposes extra planning overhead that is quite noticeable on simple queries, and most often will yield no benefit for simple queries. If you have no tables that are partitioned using traditional inheritance, you might prefer to turn it off entirely. (Note that the equivalent feature for partitioned tables is controlled by a separate parameter,enable_partition_pruning.)Refer toSection 5.12.5for more information on using constraint exclusion to implement partitioning."
cursor_tuple_fraction,floating point,"Sets the planner's estimate of the fraction of a cursor's rows that will be retrieved. The default is 0.1. Smaller values of this setting bias the planner towards using“fast start”plans for cursors, which will retrieve the first few rows quickly while perhaps taking a long time to fetch all rows. Larger values put more emphasis on the total estimated time. At the maximum setting of 1.0, cursors are planned exactly like regular queries, considering only the total estimated time and not how soon the first rows might be delivered."
from_collapse_limit,integer,"The planner will merge sub-queries into upper queries if the resultingFROMlist would have no more than this many items. Smaller values reduce planning time but might yield inferior query plans. The default is eight. For more information seeSection 14.3.Setting this value togeqo_thresholdor more may trigger use of the GEQO planner, resulting in non-optimal plans. SeeSection 19.7.3."
jit,boolean,"Determines whetherJITcompilation may be used byPostgreSQL, if available (seeChapter 30). The default ison."
join_collapse_limit,integer,"The planner will rewrite explicitJOINconstructs (exceptFULL JOINs) into lists ofFROMitems whenever a list of no more than this many items would result. Smaller values reduce planning time but might yield inferior query plans.By default, this variable is set the same asfrom_collapse_limit, which is appropriate for most uses. Setting it to 1 prevents any reordering of explicitJOINs. Thus, the explicit join order specified in the query will be the actual order in which the relations are joined. Because the query planner does not always choose the optimal join order, advanced users can elect to temporarily set this variable to 1, and then specify the join order they desire explicitly. For more information seeSection 14.3.Setting this value togeqo_thresholdor more may trigger use of the GEQO planner, resulting in non-optimal plans. SeeSection 19.7.3."
plan_cache_mode,enum,"Prepared statements (either explicitly prepared or implicitly generated, for example by PL/pgSQL) can be executed using custom or generic plans. Custom plans are made afresh for each execution using its specific set of parameter values, while generic plans do not rely on the parameter values and can be re-used across executions. Thus, use of a generic plan saves planning time, but if the ideal plan depends strongly on the parameter values then a generic plan may be inefficient. The choice between these options is normally made automatically, but it can be overridden withplan_cache_mode. The allowed values areauto(the default),force_custom_planandforce_generic_plan. This setting is considered when a cached plan is to be executed, not when it is prepared. For more information seePREPARE."
recursive_worktable_factor,floating point,"Sets the planner's estimate of the average size of the working table of arecursive query, as a multiple of the estimated size of the initial non-recursive term of the query. This helps the planner choose the most appropriate method for joining the working table to the query's other tables. The default value is10.0. A smaller value such as1.0can be helpful when the recursion has low“fan-out”from one step to the next, as for example in shortest-path queries. Graph analytics queries may benefit from larger-than-default values."
log_destination,string,"PostgreSQLsupports several methods for logging server messages, includingstderr,csvlog,jsonlog, andsyslog. On Windows,eventlogis also supported. Set this parameter to a list of desired log destinations separated by commas. The default is to log tostderronly. This parameter can only be set in thepostgresql.conffile or on the server command line.Ifcsvlogis included inlog_destination, log entries are output in“comma separated value”(CSV) format, which is convenient for loading logs into programs. SeeSection 19.8.4for details.logging_collectormust be enabled to generate CSV-format log output.Ifjsonlogis included inlog_destination, log entries are output inJSONformat, which is convenient for loading logs into programs. SeeSection 19.8.5for details.logging_collectormust be enabled to generate JSON-format log output.When eitherstderr,csvlogorjsonlogare included, the filecurrent_logfilesis created to record the location of the log file(s) currently in use by the logging collector and the associated logging destination. This provides a convenient way to find the logs currently in use by the instance. Here is an example of this file's content:stderr log/postgresql.log
csvlog log/postgresql.csv
jsonlog log/postgresql.jsoncurrent_logfilesis recreated when a new log file is created as an effect of rotation, and whenlog_destinationis reloaded. It is removed when none ofstderr,csvlogorjsonlogare included inlog_destination, and when the logging collector is disabled.NoteOn most Unix systems, you will need to alter the configuration of your system'ssyslogdaemon in order to make use of thesyslogoption forlog_destination.PostgreSQLcan log tosyslogfacilitiesLOCAL0throughLOCAL7(seesyslog_facility), but the defaultsyslogconfiguration on most platforms will discard all such messages. You will need to add something like:local0.*    /var/log/postgresqlto thesyslogdaemon's configuration file to make it work.On Windows, when you use theeventlogoption forlog_destination, you should register an event source and its library with the operating system so that the Windows Event Viewer can display event log messages cleanly. SeeSection 18.12for details."
logging_collector,boolean,"This parameter enables thelogging collector, which is a background process that captures log messages sent tostderrand redirects them into log files. This approach is often more useful than logging tosyslog, since some types of messages might not appear insyslogoutput. (One common example is dynamic-linker failure messages; another is error messages produced by scripts such asarchive_command.) This parameter can only be set at server start.NoteIt is possible to log tostderrwithout using the logging collector; the log messages will just go to wherever the server'sstderris directed. However, that method is only suitable for low log volumes, since it provides no convenient way to rotate log files. Also, on some platforms not using the logging collector can result in lost or garbled log output, because multiple processes writing concurrently to the same log file can overwrite each other's output.NoteThe logging collector is designed to never lose messages. This means that in case of extremely high load, server processes could be blocked while trying to send additional log messages when the collector has fallen behind. In contrast,syslogprefers to drop messages if it cannot write them, which means it may fail to log some messages in such cases but it will not block the rest of the system."
log_directory,string,"Whenlogging_collectoris enabled, this parameter determines the directory in which log files will be created. It can be specified as an absolute path, or relative to the cluster data directory. This parameter can only be set in thepostgresql.conffile or on the server command line. The default islog."
log_filename,string,"Whenlogging_collectoris enabled, this parameter sets the file names of the created log files. The value is treated as astrftimepattern, so%-escapes can be used to specify time-varying file names. (Note that if there are any time-zone-dependent%-escapes, the computation is done in the zone specified bylog_timezone.) The supported%-escapes are similar to those listed in the Open Group'sstrftimespecification. Note that the system'sstrftimeis not used directly, so platform-specific (nonstandard) extensions do not work. The default ispostgresql-%Y-%m-%d_%H%M%S.log.If you specify a file name without escapes, you should plan to use a log rotation utility to avoid eventually filling the entire disk. In releases prior to 8.4, if no%escapes were present,PostgreSQLwould append the epoch of the new log file's creation time, but this is no longer the case.If CSV-format output is enabled inlog_destination,.csvwill be appended to the timestamped log file name to create the file name for CSV-format output. (Iflog_filenameends in.log, the suffix is replaced instead.)If JSON-format output is enabled inlog_destination,.jsonwill be appended to the timestamped log file name to create the file name for JSON-format output. (Iflog_filenameends in.log, the suffix is replaced instead.)This parameter can only be set in thepostgresql.conffile or on the server command line."
log_file_mode,integer,"On Unix systems this parameter sets the permissions for log files whenlogging_collectoris enabled. (On Microsoft Windows this parameter is ignored.) The parameter value is expected to be a numeric mode specified in the format accepted by thechmodandumasksystem calls. (To use the customary octal format the number must start with a0(zero).)The default permissions are0600, meaning only the server owner can read or write the log files. The other commonly useful setting is0640, allowing members of the owner's group to read the files. Note however that to make use of such a setting, you'll need to alterlog_directoryto store the files somewhere outside the cluster data directory. In any case, it's unwise to make the log files world-readable, since they might contain sensitive data.This parameter can only be set in thepostgresql.conffile or on the server command line."
log_rotation_age,integer,"Whenlogging_collectoris enabled, this parameter determines the maximum amount of time to use an individual log file, after which a new log file will be created. If this value is specified without units, it is taken as minutes. The default is 24 hours. Set to zero to disable time-based creation of new log files. This parameter can only be set in thepostgresql.conffile or on the server command line."
log_rotation_size,integer,"Whenlogging_collectoris enabled, this parameter determines the maximum size of an individual log file. After this amount of data has been emitted into a log file, a new log file will be created. If this value is specified without units, it is taken as kilobytes. The default is 10 megabytes. Set to zero to disable size-based creation of new log files. This parameter can only be set in thepostgresql.conffile or on the server command line."
log_truncate_on_rotation,boolean,"Whenlogging_collectoris enabled, this parameter will causePostgreSQLto truncate (overwrite), rather than append to, any existing log file of the same name. However, truncation will occur only when a new file is being opened due to time-based rotation, not during server startup or size-based rotation. When off, pre-existing files will be appended to in all cases. For example, using this setting in combination with alog_filenamelikepostgresql-%H.logwould result in generating twenty-four hourly log files and then cyclically overwriting them. This parameter can only be set in thepostgresql.conffile or on the server command line.Example: To keep 7 days of logs, one log file per day namedserver_log.Mon,server_log.Tue, etc., and automatically overwrite last week's log with this week's log, setlog_filenametoserver_log.%a,log_truncate_on_rotationtoon, andlog_rotation_ageto1440.Example: To keep 24 hours of logs, one log file per hour, but also rotate sooner if the log file size exceeds 1GB, setlog_filenametoserver_log.%H%M,log_truncate_on_rotationtoon,log_rotation_ageto60, andlog_rotation_sizeto1000000. Including%Minlog_filenameallows any size-driven rotations that might occur to select a file name different from the hour's initial file name."
syslog_facility,enum,"When logging tosyslogis enabled, this parameter determines thesyslog“facility”to be used. You can choose fromLOCAL0,LOCAL1,LOCAL2,LOCAL3,LOCAL4,LOCAL5,LOCAL6,LOCAL7; the default isLOCAL0. See also the documentation of your system'ssyslogdaemon. This parameter can only be set in thepostgresql.conffile or on the server command line."
syslog_ident,string,"When logging tosyslogis enabled, this parameter determines the program name used to identifyPostgreSQLmessages insysloglogs. The default ispostgres. This parameter can only be set in thepostgresql.conffile or on the server command line."
syslog_sequence_numbers,boolean,"When logging tosyslogand this is on (the default), then each message will be prefixed by an increasing sequence number (such as[2]). This circumvents the“--- last message repeated N times ---”suppression that many syslog implementations perform by default. In more modern syslog implementations, repeated message suppression can be configured (for example,$RepeatedMsgReductioninrsyslog), so this might not be necessary. Also, you could turn this off if you actually want to suppress repeated messages.This parameter can only be set in thepostgresql.conffile or on the server command line."
syslog_split_messages,boolean,"When logging tosyslogis enabled, this parameter determines how messages are delivered to syslog. When on (the default), messages are split by lines, and long lines are split so that they will fit into 1024 bytes, which is a typical size limit for traditional syslog implementations. When off, PostgreSQL server log messages are delivered to the syslog service as is, and it is up to the syslog service to cope with the potentially bulky messages.If syslog is ultimately logging to a text file, then the effect will be the same either way, and it is best to leave the setting on, since most syslog implementations either cannot handle large messages or would need to be specially configured to handle them. But if syslog is ultimately writing into some other medium, it might be necessary or more useful to keep messages logically together.This parameter can only be set in thepostgresql.conffile or on the server command line."
event_source,string,"When logging toevent logis enabled, this parameter determines the program name used to identifyPostgreSQLmessages in the log. The default isPostgreSQL. This parameter can only be set in thepostgresql.conffile or on the server command line."
log_min_messages,enum,"Controls whichmessage levelsare written to the server log. Valid values areDEBUG5,DEBUG4,DEBUG3,DEBUG2,DEBUG1,INFO,NOTICE,WARNING,ERROR,LOG,FATAL, andPANIC. Each level includes all the levels that follow it. The later the level, the fewer messages are sent to the log. The default isWARNING. Note thatLOGhas a different rank here than inclient_min_messages. Only superusers and users with the appropriateSETprivilege can change this setting."
log_min_error_statement,enum,"Controls which SQL statements that cause an error condition are recorded in the server log. The current SQL statement is included in the log entry for any message of the specifiedseverityor higher. Valid values areDEBUG5,DEBUG4,DEBUG3,DEBUG2,DEBUG1,INFO,NOTICE,WARNING,ERROR,LOG,FATAL, andPANIC. The default isERROR, which means statements causing errors, log messages, fatal errors, or panics will be logged. To effectively turn off logging of failing statements, set this parameter toPANIC. Only superusers and users with the appropriateSETprivilege can change this setting."
log_min_duration_statement,integer,"Causes the duration of each completed statement to be logged if the statement ran for at least the specified amount of time. For example, if you set it to250msthen all SQL statements that run 250ms or longer will be logged. Enabling this parameter can be helpful in tracking down unoptimized queries in your applications. If this value is specified without units, it is taken as milliseconds. Setting this to zero prints all statement durations.-1(the default) disables logging statement durations. Only superusers and users with the appropriateSETprivilege can change this setting.This overrideslog_min_duration_sample, meaning that queries with duration exceeding this setting are not subject to sampling and are always logged.For clients using extended query protocol, durations of the Parse, Bind, and Execute steps are logged independently.NoteWhen using this option together withlog_statement, the text of statements that are logged because oflog_statementwill not be repeated in the duration log message. If you are not usingsyslog, it is recommended that you log the PID or session ID usinglog_line_prefixso that you can link the statement message to the later duration message using the process ID or session ID."
log_min_duration_sample,integer,"Allows sampling the duration of completed statements that ran for at least the specified amount of time. This produces the same kind of log entries aslog_min_duration_statement, but only for a subset of the executed statements, with sample rate controlled bylog_statement_sample_rate. For example, if you set it to100msthen all SQL statements that run 100ms or longer will be considered for sampling. Enabling this parameter can be helpful when the traffic is too high to log all queries. If this value is specified without units, it is taken as milliseconds. Setting this to zero samples all statement durations.-1(the default) disables sampling statement durations. Only superusers and users with the appropriateSETprivilege can change this setting.This setting has lower priority thanlog_min_duration_statement, meaning that statements with durations exceedinglog_min_duration_statementare not subject to sampling and are always logged.Other notes forlog_min_duration_statementapply also to this setting."
log_statement_sample_rate,floating point,"Determines the fraction of statements with duration exceedinglog_min_duration_samplethat will be logged. Sampling is stochastic, for example0.5means there is statistically one chance in two that any given statement will be logged. The default is1.0, meaning to log all sampled statements. Setting this to zero disables sampled statement-duration logging, the same as settinglog_min_duration_sampleto-1. Only superusers and users with the appropriateSETprivilege can change this setting."
log_transaction_sample_rate,floating point,"Sets the fraction of transactions whose statements are all logged, in addition to statements logged for other reasons. It applies to each new transaction regardless of its statements' durations. Sampling is stochastic, for example0.1means there is statistically one chance in ten that any given transaction will be logged.log_transaction_sample_ratecan be helpful to construct a sample of transactions. The default is0, meaning not to log statements from any additional transactions. Setting this to1logs all statements of all transactions. Only superusers and users with the appropriateSETprivilege can change this setting.NoteLike all statement-logging options, this option can add significant overhead."
log_startup_progress_interval,integer,"Sets the amount of time after which the startup process will log a message about a long-running operation that is still in progress, as well as the interval between further progress messages for that operation. The default is 10 seconds. A setting of0disables the feature. If this value is specified without units, it is taken as milliseconds. This setting is applied separately to each operation. This parameter can only be set in thepostgresql.conffile or on the server command line.For example, if syncing the data directory takes 25 seconds and thereafter resetting unlogged relations takes 8 seconds, and if this setting has the default value of 10 seconds, then a messages will be logged for syncing the data directory after it has been in progress for 10 seconds and again after it has been in progress for 20 seconds, but nothing will be logged for resetting unlogged relations."
application_name,string,Theapplication_namecan be any string of less thanNAMEDATALENcharacters (64 characters in a standard build). It is typically set by an application upon connection to the server. The name will be displayed in thepg_stat_activityview and included in CSV log entries. It can also be included in regular log entries via thelog_line_prefixparameter. Only printable ASCII characters may be used in theapplication_namevalue. Other characters are replaced withC-style hexadecimal escapes.
debug_print_parse,boolean,"These parameters enable various debugging output to be emitted. When set, they print the resulting parse tree, the query rewriter output, or the execution plan for each executed query. These messages are emitted atLOGmessage level, so by default they will appear in the server log but will not be sent to the client. You can change that by adjustingclient_min_messagesand/orlog_min_messages. These parameters are off by default."
debug_pretty_print,boolean,"When set,debug_pretty_printindents the messages produced bydebug_print_parse,debug_print_rewritten, ordebug_print_plan. This results in more readable but much longer output than the“compact”format used when it is off. It is on by default."
log_autovacuum_min_duration,integer,"Causes each action executed by autovacuum to be logged if it ran for at least the specified amount of time. Setting this to zero logs all autovacuum actions.-1disables logging autovacuum actions. If this value is specified without units, it is taken as milliseconds. For example, if you set this to250msthen all automatic vacuums and analyzes that run 250ms or longer will be logged. In addition, when this parameter is set to any value other than-1, a message will be logged if an autovacuum action is skipped due to a conflicting lock or a concurrently dropped relation. The default is10min. Enabling this parameter can be helpful in tracking autovacuum activity. This parameter can only be set in thepostgresql.conffile or on the server command line; but the setting can be overridden for individual tables by changing table storage parameters."
log_checkpoints,boolean,"Causes checkpoints and restartpoints to be logged in the server log. Some statistics are included in the log messages, including the number of buffers written and the time spent writing them. This parameter can only be set in thepostgresql.conffile or on the server command line. The default is on."
log_connections,boolean,"Causes each attempted connection to the server to be logged, as well as successful completion of both client authentication (if necessary) and authorization. Only superusers and users with the appropriateSETprivilege can change this parameter at session start, and it cannot be changed at all within a session. The default isoff.NoteSome client programs, likepsql, attempt to connect twice while determining if a password is required, so duplicate“connection received”messages do not necessarily indicate a problem."
log_disconnections,boolean,"Causes session terminations to be logged. The log output provides information similar tolog_connections, plus the duration of the session. Only superusers and users with the appropriateSETprivilege can change this parameter at session start, and it cannot be changed at all within a session. The default isoff."
log_duration,boolean,"Causes the duration of every completed statement to be logged. The default isoff. Only superusers and users with the appropriateSETprivilege can change this setting.For clients using extended query protocol, durations of the Parse, Bind, and Execute steps are logged independently.NoteThe difference between enablinglog_durationand settinglog_min_duration_statementto zero is that exceedinglog_min_duration_statementforces the text of the query to be logged, but this option doesn't. Thus, iflog_durationisonandlog_min_duration_statementhas a positive value, all durations are logged but the query text is included only for statements exceeding the threshold. This behavior can be useful for gathering statistics in high-load installations."
log_error_verbosity,enum,"Controls the amount of detail written in the server log for each message that is logged. Valid values areTERSE,DEFAULT, andVERBOSE, each adding more fields to displayed messages.TERSEexcludes the logging ofDETAIL,HINT,QUERY, andCONTEXTerror information.VERBOSEoutput includes theSQLSTATEerror code (see alsoAppendix A) and the source code file name, function name, and line number that generated the error. Only superusers and users with the appropriateSETprivilege can change this setting."
log_hostname,boolean,"By default, connection log messages only show the IP address of the connecting host. Turning this parameter on causes logging of the host name as well. Note that depending on your host name resolution setup this might impose a non-negligible performance penalty. This parameter can only be set in thepostgresql.conffile or on the server command line."
log_line_prefix,string,"This is aprintf-style string that is output at the beginning of each log line.%characters begin“escape sequences”that are replaced with status information as outlined below. Unrecognized escapes are ignored. Other characters are copied straight to the log line. Some escapes are only recognized by session processes, and will be treated as empty by background processes such as the main server process. Status information may be aligned either left or right by specifying a numeric literal after the % and before the option. A negative value will cause the status information to be padded on the right with spaces to give it a minimum width, whereas a positive value will pad on the left. Padding can be useful to aid human readability in log files.This parameter can only be set in thepostgresql.conffile or on the server command line. The default is'%m [%p] 'which logs a time stamp and the process ID.EscapeEffectSession only%aApplication nameyes%uUser nameyes%dDatabase nameyes%rRemote host name or IP address, and remote portyes%hRemote host name or IP addressyes%bBackend typeno%pProcess IDno%PProcess ID of the parallel group leader, if this process is a parallel query workerno%tTime stamp without millisecondsno%mTime stamp with millisecondsno%nTime stamp with milliseconds (as a Unix epoch)no%iCommand tag: type of session's current commandyes%eSQLSTATE error codeno%cSession ID: see belowno%lNumber of the log line for each session or process, starting at 1no%sProcess start time stampno%vVirtual transaction ID (procNumber/localXID); seeSection 66.1no%xTransaction ID (0 if none is assigned); seeSection 66.1no%qProduces no output, but tells non-session processes to stop at this point in the string; ignored by session processesno%QQuery identifier of the current query. Query identifiers are not computed by default, so this field will be zero unlesscompute_query_idparameter is enabled or a third-party module that computes query identifiers is configured.yes%%Literal%noThe backend type corresponds to the columnbackend_typein the viewpg_stat_activity, but additional types can appear in the log that don't show in that view.The%cescape prints a quasi-unique session identifier, consisting of two 4-byte hexadecimal numbers (without leading zeros) separated by a dot. The numbers are the process start time and the process ID, so%ccan also be used as a space saving way of printing those items. For example, to generate the session identifier frompg_stat_activity, use this query:SELECT to_hex(trunc(EXTRACT(EPOCH FROM backend_start))::integer) || '.' ||
       to_hex(pid)
FROM pg_stat_activity;TipIf you set a nonempty value forlog_line_prefix, you should usually make its last character be a space, to provide visual separation from the rest of the log line. A punctuation character can be used too.TipSyslogproduces its own time stamp and process ID information, so you probably do not want to include those escapes if you are logging tosyslog.TipThe%qescape is useful when including information that is only available in session (backend) context like user or database name. For example:log_line_prefix = '%m [%p] %q%u@%d/%a 'NoteThe%Qescape always reports a zero identifier for lines output bylog_statementbecauselog_statementgenerates output before an identifier can be calculated, including invalid statements for which an identifier cannot be calculated."
log_lock_waits,boolean,Controls whether a log message is produced when a session waits longer thandeadlock_timeoutto acquire a lock. This is useful in determining if lock waits are causing poor performance. The default isoff. Only superusers and users with the appropriateSETprivilege can change this setting.
log_recovery_conflict_waits,boolean,Controls whether a log message is produced when the startup process waits longer thandeadlock_timeoutfor recovery conflicts. This is useful in determining if recovery conflicts prevent the recovery from applying WAL.The default isoff. This parameter can only be set in thepostgresql.conffile or on the server command line.
log_parameter_max_length,integer,"If greater than zero, each bind parameter value logged with a non-error statement-logging message is trimmed to this many bytes. Zero disables logging of bind parameters for non-error statement logs.-1(the default) allows bind parameters to be logged in full. If this value is specified without units, it is taken as bytes. Only superusers and users with the appropriateSETprivilege can change this setting.This setting only affects log messages printed as a result oflog_statement,log_duration, and related settings. Non-zero values of this setting add some overhead, particularly if parameters are sent in binary form, since then conversion to text is required."
log_parameter_max_length_on_error,integer,"If greater than zero, each bind parameter value reported in error messages is trimmed to this many bytes. Zero (the default) disables including bind parameters in error messages.-1allows bind parameters to be printed in full. If this value is specified without units, it is taken as bytes.Non-zero values of this setting add overhead, asPostgreSQLwill need to store textual representations of parameter values in memory at the start of each statement, whether or not an error eventually occurs. The overhead is greater when bind parameters are sent in binary form than when they are sent as text, since the former case requires data conversion while the latter only requires copying the string."
log_statement,enum,"Controls which SQL statements are logged. Valid values arenone(off),ddl,mod, andall(all statements).ddllogs all data definition statements, such asCREATE,ALTER, andDROPstatements.modlogs allddlstatements, plus data-modifying statements such asINSERT,UPDATE,DELETE,TRUNCATE, andCOPY FROM.PREPARE,EXECUTE, andEXPLAIN ANALYZEstatements are also logged if their contained command is of an appropriate type. For clients using extended query protocol, logging occurs when an Execute message is received, and values of the Bind parameters are included (with any embedded single-quote marks doubled).The default isnone. Only superusers and users with the appropriateSETprivilege can change this setting.NoteStatements that contain simple syntax errors are not logged even by thelog_statement=allsetting, because the log message is emitted only after basic parsing has been done to determine the statement type. In the case of extended query protocol, this setting likewise does not log statements that fail before the Execute phase (i.e., during parse analysis or planning). Setlog_min_error_statementtoERROR(or lower) to log such statements.Logged statements might reveal sensitive data and even contain plaintext passwords."
log_replication_commands,boolean,Causes each replication command andwalsenderprocess's replication slot acquisition/release to be logged in the server log. SeeSection 53.4for more information about replication command. The default value isoff. Only superusers and users with the appropriateSETprivilege can change this setting.
log_temp_files,integer,"Controls logging of temporary file names and sizes. Temporary files can be created for sorts, hashes, and temporary query results. If enabled by this setting, a log entry is emitted for each temporary file, with the file size specified in bytes, when it is deleted. A value of zero logs all temporary file information, while positive values log only files whose size is greater than or equal to the specified amount of data. If this value is specified without units, it is taken as kilobytes. The default setting is -1, which disables such logging. Only superusers and users with the appropriateSETprivilege can change this setting."
log_timezone,string,"Sets the time zone used for timestamps written in the server log. UnlikeTimeZone, this value is cluster-wide, so that all sessions will report timestamps consistently. The built-in default isGMT, but that is typically overridden inpostgresql.conf;initdbwill install a setting there corresponding to its system environment. SeeSection 8.5.3for more information. This parameter can only be set in thepostgresql.conffile or on the server command line."
cluster_name,string,"Sets a name that identifies this database cluster (instance) for various purposes. The cluster name appears in the process title for all server processes in this cluster. Moreover, it is the default application name for a standby connection (seesynchronous_standby_names).The name can be any string of less thanNAMEDATALENcharacters (64 characters in a standard build). Only printable ASCII characters may be used in thecluster_namevalue. Other characters are replaced withC-style hexadecimal escapes. No name is shown if this parameter is set to the empty string''(which is the default). This parameter can only be set at server start."
update_process_title,boolean,"Enables updating of the process title every time a new SQL command is received by the server. This setting defaults toonon most platforms, but it defaults tooffon Windows due to that platform's larger overhead for updating the process title. Only superusers and users with the appropriateSETprivilege can change this setting."
track_activities,boolean,"Enables the collection of information on the currently executing command of each session, along with its identifier and the time when that command began execution. This parameter is on by default. Note that even when enabled, this information is only visible to superusers, roles with privileges of thepg_read_all_statsrole and the user owning the sessions being reported on (including sessions belonging to a role they have the privileges of), so it should not represent a security risk. Only superusers and users with the appropriateSETprivilege can change this setting."
track_activity_query_size,integer,"Specifies the amount of memory reserved to store the text of the currently executing command for each active session, for thepg_stat_activity.queryfield. If this value is specified without units, it is taken as bytes. The default value is 1024 bytes. This parameter can only be set at server start."
track_counts,boolean,"Enables collection of statistics on database activity. This parameter is on by default, because the autovacuum daemon needs the collected information. Only superusers and users with the appropriateSETprivilege can change this setting."
track_io_timing,boolean,"Enables timing of database I/O calls. This parameter is off by default, as it will repeatedly query the operating system for the current time, which may cause significant overhead on some platforms. You can use thepg_test_timingtool to measure the overhead of timing on your system. I/O timing information is displayed inpg_stat_database,pg_stat_io, in the output ofEXPLAINwhen theBUFFERSoption is used, in the output ofVACUUMwhen theVERBOSEoption is used, by autovacuum for auto-vacuums and auto-analyzes, whenlog_autovacuum_min_durationis set and bypg_stat_statements. Only superusers and users with the appropriateSETprivilege can change this setting."
track_wal_io_timing,boolean,"Enables timing of WAL I/O calls. This parameter is off by default, as it will repeatedly query the operating system for the current time, which may cause significant overhead on some platforms. You can use thepg_test_timingtool to measure the overhead of timing on your system. I/O timing information is displayed inpg_stat_wal. Only superusers and users with the appropriateSETprivilege can change this setting."
track_functions,enum,"Enables tracking of function call counts and time used. Specifyplto track only procedural-language functions,allto also track SQL and C language functions. The default isnone, which disables function statistics tracking. Only superusers and users with the appropriateSETprivilege can change this setting.NoteSQL-language functions that are simple enough to be“inlined”into the calling query will not be tracked, regardless of this setting."
stats_fetch_consistency,enum,"Determines the behavior when cumulative statistics are accessed multiple times within a transaction. When set tonone, each access re-fetches counters from shared memory. When set tocache, the first access to statistics for an object caches those statistics until the end of the transaction unlesspg_stat_clear_snapshot()is called. When set tosnapshot, the first statistics access caches all statistics accessible in the current database, until the end of the transaction unlesspg_stat_clear_snapshot()is called. Changing this parameter in a transaction discards the statistics snapshot. The default iscache.Notenoneis most suitable for monitoring systems. If values are only accessed once, it is the most efficient.cacheensures repeat accesses yield the same values, which is important for queries involving e.g. self-joins.snapshotcan be useful when interactively inspecting statistics, but has higher overhead, particularly if many database objects exist."
compute_query_id,enum,"Enables in-core computation of a query identifier. Query identifiers can be displayed in thepg_stat_activityview, usingEXPLAIN, or emitted in the log if configured via thelog_line_prefixparameter. Thepg_stat_statementsextension also requires a query identifier to be computed. Note that an external module can alternatively be used if the in-core query identifier computation method is not acceptable. In this case, in-core computation must be always disabled. Valid values areoff(always disabled),on(always enabled),auto, which lets modules such aspg_stat_statementsautomatically enable it, andregresswhich has the same effect asauto, except that the query identifier is not shown in theEXPLAINoutput in order to facilitate automated regression testing. The default isauto.NoteTo ensure that only one query identifier is calculated and displayed, extensions that calculate query identifiers should throw an error if a query identifier has already been computed."
log_statement_stats,boolean,"For each query, output performance statistics of the respective module to the server log. This is a crude profiling instrument, similar to the Unixgetrusage()operating system facility.log_statement_statsreports total statement statistics, while the others report per-module statistics.log_statement_statscannot be enabled together with any of the per-module options. All of these options are disabled by default. Only superusers and users with the appropriateSETprivilege can change these settings."
autovacuum,boolean,"Controls whether the server should run the autovacuum launcher daemon. This is on by default; however,track_countsmust also be enabled for autovacuum to work. This parameter can only be set in thepostgresql.conffile or on the server command line; however, autovacuuming can be disabled for individual tables by changing table storage parameters.Note that even when this parameter is disabled, the system will launch autovacuum processes if necessary to prevent transaction ID wraparound. SeeSection 24.1.5for more information."
autovacuum_max_workers,integer,Specifies the maximum number of autovacuum processes (other than the autovacuum launcher) that may be running at any one time. The default is three. This parameter can only be set at server start.
autovacuum_naptime,integer,"Specifies the minimum delay between autovacuum runs on any given database. In each round the daemon examines the database and issuesVACUUMandANALYZEcommands as needed for tables in that database. If this value is specified without units, it is taken as seconds. The default is one minute (1min). This parameter can only be set in thepostgresql.conffile or on the server command line."
autovacuum_vacuum_threshold,integer,Specifies the minimum number of updated or deleted tuples needed to trigger aVACUUMin any one table. The default is 50 tuples. This parameter can only be set in thepostgresql.conffile or on the server command line; but the setting can be overridden for individual tables by changing table storage parameters.
autovacuum_vacuum_insert_threshold,integer,"Specifies the number of inserted tuples needed to trigger aVACUUMin any one table. The default is 1000 tuples. If -1 is specified, autovacuum will not trigger aVACUUMoperation on any tables based on the number of inserts. This parameter can only be set in thepostgresql.conffile or on the server command line; but the setting can be overridden for individual tables by changing table storage parameters."
autovacuum_analyze_threshold,integer,"Specifies the minimum number of inserted, updated or deleted tuples needed to trigger anANALYZEin any one table. The default is 50 tuples. This parameter can only be set in thepostgresql.conffile or on the server command line; but the setting can be overridden for individual tables by changing table storage parameters."
autovacuum_vacuum_scale_factor,floating point,Specifies a fraction of the table size to add toautovacuum_vacuum_thresholdwhen deciding whether to trigger aVACUUM. The default is 0.2 (20% of table size). This parameter can only be set in thepostgresql.conffile or on the server command line; but the setting can be overridden for individual tables by changing table storage parameters.
autovacuum_vacuum_insert_scale_factor,floating point,Specifies a fraction of the table size to add toautovacuum_vacuum_insert_thresholdwhen deciding whether to trigger aVACUUM. The default is 0.2 (20% of table size). This parameter can only be set in thepostgresql.conffile or on the server command line; but the setting can be overridden for individual tables by changing table storage parameters.
autovacuum_analyze_scale_factor,floating point,Specifies a fraction of the table size to add toautovacuum_analyze_thresholdwhen deciding whether to trigger anANALYZE. The default is 0.1 (10% of table size). This parameter can only be set in thepostgresql.conffile or on the server command line; but the setting can be overridden for individual tables by changing table storage parameters.
autovacuum_freeze_max_age,integer,"Specifies the maximum age (in transactions) that a table'spg_class.relfrozenxidfield can attain before aVACUUMoperation is forced to prevent transaction ID wraparound within the table. Note that the system will launch autovacuum processes to prevent wraparound even when autovacuum is otherwise disabled.Vacuum also allows removal of old files from thepg_xactsubdirectory, which is why the default is a relatively low 200 million transactions. This parameter can only be set at server start, but the setting can be reduced for individual tables by changing table storage parameters. For more information seeSection 24.1.5."
autovacuum_multixact_freeze_max_age,integer,"Specifies the maximum age (in multixacts) that a table'spg_class.relminmxidfield can attain before aVACUUMoperation is forced to prevent multixact ID wraparound within the table. Note that the system will launch autovacuum processes to prevent wraparound even when autovacuum is otherwise disabled.Vacuuming multixacts also allows removal of old files from thepg_multixact/membersandpg_multixact/offsetssubdirectories, which is why the default is a relatively low 400 million multixacts. This parameter can only be set at server start, but the setting can be reduced for individual tables by changing table storage parameters. For more information seeSection 24.1.5.1."
autovacuum_vacuum_cost_delay,floating point,"Specifies the cost delay value that will be used in automaticVACUUMoperations. If -1 is specified, the regularvacuum_cost_delayvalue will be used. If this value is specified without units, it is taken as milliseconds. The default value is 2 milliseconds. This parameter can only be set in thepostgresql.conffile or on the server command line; but the setting can be overridden for individual tables by changing table storage parameters."
autovacuum_vacuum_cost_limit,integer,"Specifies the cost limit value that will be used in automaticVACUUMoperations. If -1 is specified (which is the default), the regularvacuum_cost_limitvalue will be used. Note that the value is distributed proportionally among the running autovacuum workers, if there is more than one, so that the sum of the limits for each worker does not exceed the value of this variable. This parameter can only be set in thepostgresql.conffile or on the server command line; but the setting can be overridden for individual tables by changing table storage parameters."
client_min_messages,enum,"Controls whichmessage levelsare sent to the client. Valid values areDEBUG5,DEBUG4,DEBUG3,DEBUG2,DEBUG1,LOG,NOTICE,WARNING, andERROR. Each level includes all the levels that follow it. The later the level, the fewer messages are sent. The default isNOTICE. Note thatLOGhas a different rank here than inlog_min_messages.INFOlevel messages are always sent to the client."
search_path,string,"This variable specifies the order in which schemas are searched when an object (table, data type, function, etc.) is referenced by a simple name with no schema specified. When there are objects of identical names in different schemas, the one found first in the search path is used. An object that is not in any of the schemas in the search path can only be referenced by specifying its containing schema with a qualified (dotted) name.The value forsearch_pathmust be a comma-separated list of schema names. Any name that is not an existing schema, or is a schema for which the user does not haveUSAGEpermission, is silently ignored.If one of the list items is the special name$user, then the schema having the name returned byCURRENT_USERis substituted, if there is such a schema and the user hasUSAGEpermission for it. (If not,$useris ignored.)The system catalog schema,pg_catalog, is always searched, whether it is mentioned in the path or not. If it is mentioned in the path then it will be searched in the specified order. Ifpg_catalogis not in the path then it will be searchedbeforesearching any of the path items.Likewise, the current session's temporary-table schema,pg_temp_nnn, is always searched if it exists. It can be explicitly listed in the path by using the aliaspg_temp. If it is not listed in the path then it is searched first (even beforepg_catalog). However, the temporary schema is only searched for relation (table, view, sequence, etc.) and data type names. It is never searched for function or operator names.When objects are created without specifying a particular target schema, they will be placed in the first valid schema named insearch_path. An error is reported if the search path is empty.The default value for this parameter is""$user"", public. This setting supports shared use of a database (where no users have private schemas, and all share use ofpublic), private per-user schemas, and combinations of these. Other effects can be obtained by altering the default search path setting, either globally or per-user.For more information on schema handling, seeSection 5.10. In particular, the default configuration is suitable only when the database has a single user or a few mutually-trusting users.The current effective value of the search path can be examined via theSQLfunctioncurrent_schemas(seeSection 9.27). This is not quite the same as examining the value ofsearch_path, sincecurrent_schemasshows how the items appearing insearch_pathwere resolved."
row_security,boolean,"This variable controls whether to raise an error in lieu of applying a row security policy. When set toon, policies apply normally. When set tooff, queries fail which would otherwise apply at least one policy. The default ison. Change tooffwhere limited row visibility could cause incorrect results; for example,pg_dumpmakes that change by default. This variable has no effect on roles which bypass every row security policy, to wit, superusers and roles with theBYPASSRLSattribute.For more information on row security policies, seeCREATE POLICY."
default_table_access_method,string,"This parameter specifies the default table access method to use when creating tables or materialized views if theCREATEcommand does not explicitly specify an access method, or whenSELECT ... INTOis used, which does not allow specifying a table access method. The default isheap."
default_tablespace,string,"This variable specifies the default tablespace in which to create objects (tables and indexes) when aCREATEcommand does not explicitly specify a tablespace.The value is either the name of a tablespace, or an empty string to specify using the default tablespace of the current database. If the value does not match the name of any existing tablespace,PostgreSQLwill automatically use the default tablespace of the current database. If a nondefault tablespace is specified, the user must haveCREATEprivilege for it, or creation attempts will fail.This variable is not used for temporary tables; for them,temp_tablespacesis consulted instead.This variable is also not used when creating databases. By default, a new database inherits its tablespace setting from the template database it is copied from.If this parameter is set to a value other than the empty string when a partitioned table is created, the partitioned table's tablespace will be set to that value, which will be used as the default tablespace for partitions created in the future, even ifdefault_tablespacehas changed since then.For more information on tablespaces, seeSection 22.6."
default_toast_compression,enum,This variable sets the defaultTOASTcompression method for values of compressible columns. (This can be overridden for individual columns by setting theCOMPRESSIONcolumn option inCREATE TABLEorALTER TABLE.) The supported compression methods arepglzand (ifPostgreSQLwas compiled with--with-lz4)lz4. The default ispglz.
temp_tablespaces,string,"This variable specifies tablespaces in which to create temporary objects (temp tables and indexes on temp tables) when aCREATEcommand does not explicitly specify a tablespace. Temporary files for purposes such as sorting large data sets are also created in these tablespaces.The value is a list of names of tablespaces. When there is more than one name in the list,PostgreSQLchooses a random member of the list each time a temporary object is to be created; except that within a transaction, successively created temporary objects are placed in successive tablespaces from the list. If the selected element of the list is an empty string,PostgreSQLwill automatically use the default tablespace of the current database instead.Whentemp_tablespacesis set interactively, specifying a nonexistent tablespace is an error, as is specifying a tablespace for which the user does not haveCREATEprivilege. However, when using a previously set value, nonexistent tablespaces are ignored, as are tablespaces for which the user lacksCREATEprivilege. In particular, this rule applies when using a value set inpostgresql.conf.The default value is an empty string, which results in all temporary objects being created in the default tablespace of the current database.See alsodefault_tablespace."
check_function_bodies,boolean,"This parameter is normally on. When set tooff, it disables validation of the routine body string duringCREATE FUNCTIONandCREATE PROCEDURE. Disabling validation avoids side effects of the validation process, in particular preventing false positives due to problems such as forward references. Set this parameter tooffbefore loading functions on behalf of other users;pg_dumpdoes so automatically."
default_transaction_isolation,enum,"Each SQL transaction has an isolation level, which can be either“read uncommitted”,“read committed”,“repeatable read”, or“serializable”. This parameter controls the default isolation level of each new transaction. The default is“read committed”.ConsultChapter 13andSET TRANSACTIONfor more information."
default_transaction_read_only,boolean,A read-only SQL transaction cannot alter non-temporary tables. This parameter controls the default read-only status of each new transaction. The default isoff(read/write).ConsultSET TRANSACTIONfor more information.
default_transaction_deferrable,boolean,"When running at theserializableisolation level, a deferrable read-only SQL transaction may be delayed before it is allowed to proceed. However, once it begins executing it does not incur any of the overhead required to ensure serializability; so serialization code will have no reason to force it to abort because of concurrent updates, making this option suitable for long-running read-only transactions.This parameter controls the default deferrable status of each new transaction. It currently has no effect on read-write transactions or those operating at isolation levels lower thanserializable. The default isoff.ConsultSET TRANSACTIONfor more information."
transaction_isolation,enum,"This parameter reflects the current transaction's isolation level. At the beginning of each transaction, it is set to the current value ofdefault_transaction_isolation. Any subsequent attempt to change it is equivalent to aSET TRANSACTIONcommand."
transaction_read_only,boolean,"This parameter reflects the current transaction's read-only status. At the beginning of each transaction, it is set to the current value ofdefault_transaction_read_only. Any subsequent attempt to change it is equivalent to aSET TRANSACTIONcommand."
transaction_deferrable,boolean,"This parameter reflects the current transaction's deferrability status. At the beginning of each transaction, it is set to the current value ofdefault_transaction_deferrable. Any subsequent attempt to change it is equivalent to aSET TRANSACTIONcommand."
session_replication_role,enum,"Controls firing of replication-related triggers and rules for the current session. Possible values areorigin(the default),replicaandlocal. Setting this parameter results in discarding any previously cached query plans. Only superusers and users with the appropriateSETprivilege can change this setting.The intended use of this setting is that logical replication systems set it toreplicawhen they are applying replicated changes. The effect of that will be that triggers and rules (that have not been altered from their default configuration) will not fire on the replica. See theALTER TABLEclausesENABLE TRIGGERandENABLE RULEfor more information.PostgreSQL treats the settingsoriginandlocalthe same internally. Third-party replication systems may use these two values for their internal purposes, for example usinglocalto designate a session whose changes should not be replicated.Since foreign keys are implemented as triggers, setting this parameter toreplicaalso disables all foreign key checks, which can leave data in an inconsistent state if improperly used."
statement_timeout,integer,"Abort any statement that takes more than the specified amount of time. Iflog_min_error_statementis set toERRORor lower, the statement that timed out will also be logged. If this value is specified without units, it is taken as milliseconds. A value of zero (the default) disables the timeout.The timeout is measured from the time a command arrives at the server until it is completed by the server. If multiple SQL statements appear in a single simple-query message, the timeout is applied to each statement separately. (PostgreSQLversions before 13 usually treated the timeout as applying to the whole query string.) In extended query protocol, the timeout starts running when any query-related message (Parse, Bind, Execute, Describe) arrives, and it is canceled by completion of an Execute or Sync message.Settingstatement_timeoutinpostgresql.confis not recommended because it would affect all sessions."
transaction_timeout,integer,"Terminate any session that spans longer than the specified amount of time in a transaction. The limit applies both to explicit transactions (started withBEGIN) and to an implicitly started transaction corresponding to a single statement. If this value is specified without units, it is taken as milliseconds. A value of zero (the default) disables the timeout.Iftransaction_timeoutis shorter or equal toidle_in_transaction_session_timeoutorstatement_timeoutthen the longer timeout is ignored.Settingtransaction_timeoutinpostgresql.confis not recommended because it would affect all sessions.NotePrepared transactions are not subject to this timeout."
lock_timeout,integer,"Abort any statement that waits longer than the specified amount of time while attempting to acquire a lock on a table, index, row, or other database object. The time limit applies separately to each lock acquisition attempt. The limit applies both to explicit locking requests (such asLOCK TABLE, orSELECT FOR UPDATEwithoutNOWAIT) and to implicitly-acquired locks. If this value is specified without units, it is taken as milliseconds. A value of zero (the default) disables the timeout.Unlikestatement_timeout, this timeout can only occur while waiting for locks. Note that ifstatement_timeoutis nonzero, it is rather pointless to setlock_timeoutto the same or larger value, since the statement timeout would always trigger first. Iflog_min_error_statementis set toERRORor lower, the statement that timed out will be logged.Settinglock_timeoutinpostgresql.confis not recommended because it would affect all sessions."
idle_in_transaction_session_timeout,integer,"Terminate any session that has been idle (that is, waiting for a client query) within an open transaction for longer than the specified amount of time. If this value is specified without units, it is taken as milliseconds. A value of zero (the default) disables the timeout.This option can be used to ensure that idle sessions do not hold locks for an unreasonable amount of time. Even when no significant locks are held, an open transaction prevents vacuuming away recently-dead tuples that may be visible only to this transaction; so remaining idle for a long time can contribute to table bloat. SeeSection 24.1for more details."
idle_session_timeout,integer,"Terminate any session that has been idle (that is, waiting for a client query), but not within an open transaction, for longer than the specified amount of time. If this value is specified without units, it is taken as milliseconds. A value of zero (the default) disables the timeout.Unlike the case with an open transaction, an idle session without a transaction imposes no large costs on the server, so there is less need to enable this timeout thanidle_in_transaction_session_timeout.Be wary of enforcing this timeout on connections made through connection-pooling software or other middleware, as such a layer may not react well to unexpected connection closure. It may be helpful to enable this timeout only for interactive sessions, perhaps by applying it only to particular users."
vacuum_freeze_table_age,integer,"VACUUMperforms an aggressive scan if the table'spg_class.relfrozenxidfield has reached the age specified by this setting. An aggressive scan differs from a regularVACUUMin that it visits every page that might contain unfrozen XIDs or MXIDs, not just those that might contain dead tuples. The default is 150 million transactions. Although users can set this value anywhere from zero to two billion,VACUUMwill silently limit the effective value to 95% ofautovacuum_freeze_max_age, so that a periodic manualVACUUMhas a chance to run before an anti-wraparound autovacuum is launched for the table. For more information seeSection 24.1.5."
vacuum_freeze_min_age,integer,"Specifies the cutoff age (in transactions) thatVACUUMshould use to decide whether to trigger freezing of pages that have an older XID. The default is 50 million transactions. Although users can set this value anywhere from zero to one billion,VACUUMwill silently limit the effective value to half the value ofautovacuum_freeze_max_age, so that there is not an unreasonably short time between forced autovacuums. For more information seeSection 24.1.5."
vacuum_failsafe_age,integer,"Specifies the maximum age (in transactions) that a table'spg_class.relfrozenxidfield can attain beforeVACUUMtakes extraordinary measures to avoid system-wide transaction ID wraparound failure. This isVACUUM's strategy of last resort. The failsafe typically triggers when an autovacuum to prevent transaction ID wraparound has already been running for some time, though it's possible for the failsafe to trigger during anyVACUUM.When the failsafe is triggered, any cost-based delay that is in effect will no longer be applied, further non-essential maintenance tasks (such as index vacuuming) are bypassed, and anyBuffer Access Strategyin use will be disabled resulting inVACUUMbeing free to make use of all ofshared buffers.The default is 1.6 billion transactions. Although users can set this value anywhere from zero to 2.1 billion,VACUUMwill silently adjust the effective value to no less than 105% ofautovacuum_freeze_max_age."
vacuum_multixact_freeze_table_age,integer,"VACUUMperforms an aggressive scan if the table'spg_class.relminmxidfield has reached the age specified by this setting. An aggressive scan differs from a regularVACUUMin that it visits every page that might contain unfrozen XIDs or MXIDs, not just those that might contain dead tuples. The default is 150 million multixacts. Although users can set this value anywhere from zero to two billion,VACUUMwill silently limit the effective value to 95% ofautovacuum_multixact_freeze_max_age, so that a periodic manualVACUUMhas a chance to run before an anti-wraparound is launched for the table. For more information seeSection 24.1.5.1."
vacuum_multixact_freeze_min_age,integer,"Specifies the cutoff age (in multixacts) thatVACUUMshould use to decide whether to trigger freezing of pages with an older multixact ID. The default is 5 million multixacts. Although users can set this value anywhere from zero to one billion,VACUUMwill silently limit the effective value to half the value ofautovacuum_multixact_freeze_max_age, so that there is not an unreasonably short time between forced autovacuums. For more information seeSection 24.1.5.1."
vacuum_multixact_failsafe_age,integer,"Specifies the maximum age (in multixacts) that a table'spg_class.relminmxidfield can attain beforeVACUUMtakes extraordinary measures to avoid system-wide multixact ID wraparound failure. This isVACUUM's strategy of last resort. The failsafe typically triggers when an autovacuum to prevent transaction ID wraparound has already been running for some time, though it's possible for the failsafe to trigger during anyVACUUM.When the failsafe is triggered, any cost-based delay that is in effect will no longer be applied, and further non-essential maintenance tasks (such as index vacuuming) are bypassed.The default is 1.6 billion multixacts. Although users can set this value anywhere from zero to 2.1 billion,VACUUMwill silently adjust the effective value to no less than 105% ofautovacuum_multixact_freeze_max_age."
bytea_output,enum,"Sets the output format for values of typebytea. Valid values arehex(the default) andescape(the traditional PostgreSQL format). SeeSection 8.4for more information. Thebyteatype always accepts both formats on input, regardless of this setting."
xmlbinary,enum,"Sets how binary values are to be encoded in XML. This applies for example whenbyteavalues are converted to XML by the functionsxmlelementorxmlforest. Possible values arebase64andhex, which are both defined in the XML Schema standard. The default isbase64. For further information about XML-related functions, seeSection 9.15.The actual choice here is mostly a matter of taste, constrained only by possible restrictions in client applications. Both methods support all possible values, although the hex encoding will be somewhat larger than the base64 encoding."
xmloption,enum,"Sets whetherDOCUMENTorCONTENTis implicit when converting between XML and character string values. SeeSection 8.13for a description of this. Valid values areDOCUMENTandCONTENT. The default isCONTENT.According to the SQL standard, the command to set this option isSET XML OPTION { DOCUMENT | CONTENT };This syntax is also available in PostgreSQL."
gin_pending_list_limit,integer,"Sets the maximum size of a GIN index's pending list, which is used whenfastupdateis enabled. If the list grows larger than this maximum size, it is cleaned up by moving the entries in it to the index's main GIN data structure in bulk. If this value is specified without units, it is taken as kilobytes. The default is four megabytes (4MB). This setting can be overridden for individual GIN indexes by changing index storage parameters. SeeSection 64.4.4.1andSection 64.4.5for more information."
createrole_self_grant,string,"If a user who hasCREATEROLEbut notSUPERUSERcreates a role, and if this is set to a non-empty value, the newly-created role will be granted to the creating user with the options specified. The value must beset,inherit, or a comma-separated list of these. The default value is an empty string, which disables the feature.The purpose of this option is to allow aCREATEROLEuser who is not a superuser to automatically inherit, or automatically gain the ability toSET ROLEto, any created users. Since aCREATEROLEuser is always implicitly grantedADMIN OPTIONon created roles, that user could always execute aGRANTstatement that would achieve the same effect as this setting. However, it can be convenient for usability reasons if the grant happens automatically. A superuser automatically inherits the privileges of every role and can alwaysSET ROLEto any role, and this setting can be used to produce a similar behavior forCREATEROLEusers for users which they create."
event_triggers,boolean,"Allow temporarily disabling execution of event triggers in order to troubleshoot and repair faulty event triggers. All event triggers will be disabled by setting it tofalse. Setting the value totrueallows all event triggers to fire, this is the default value. Only superusers and users with the appropriateSETprivilege can change this setting."
restrict_nonsystem_relation_kind,string,"Set relation kinds for which access to non-system relations is prohibited. The value takes the form of a comma-separated list of relation kinds. Currently, the supported relation kinds areviewandforeign-table."
DateStyle,string,"Sets the display format for date and time values, as well as the rules for interpreting ambiguous date input values. For historical reasons, this variable contains two independent components: the output format specification (ISO,Postgres,SQL, orGerman) and the input/output specification for year/month/day ordering (DMY,MDY, orYMD). These can be set separately or together. The keywordsEuroandEuropeanare synonyms forDMY; the keywordsUS,NonEuro, andNonEuropeanare synonyms forMDY. SeeSection 8.5for more information. The built-in default isISO, MDY, butinitdbwill initialize the configuration file with a setting that corresponds to the behavior of the chosenlc_timelocale."
IntervalStyle,enum,Sets the display format for interval values. The valuesql_standardwill produce output matchingSQLstandard interval literals. The valuepostgres(which is the default) will produce output matchingPostgreSQLreleases prior to 8.4 when theDateStyleparameter was set toISO. The valuepostgres_verbosewill produce output matchingPostgreSQLreleases prior to 8.4 when theDateStyleparameter was set to non-ISOoutput. The valueiso_8601will produce output matching the time interval“format with designators”defined in section 4.4.3.2 of ISO 8601.TheIntervalStyleparameter also affects the interpretation of ambiguous interval input. SeeSection 8.5.4for more information.
TimeZone,string,"Sets the time zone for displaying and interpreting time stamps. The built-in default isGMT, but that is typically overridden inpostgresql.conf;initdbwill install a setting there corresponding to its system environment. SeeSection 8.5.3for more information."
timezone_abbreviations,string,"Sets the collection of time zone abbreviations that will be accepted by the server for datetime input. The default is'Default', which is a collection that works in most of the world; there are also'Australia'and'India', and other collections can be defined for a particular installation. SeeSection B.4for more information."
extra_float_digits,integer,"This parameter adjusts the number of digits used for textual output of floating-point values, includingfloat4,float8, and geometric data types.If the value is 1 (the default) or above, float values are output in shortest-precise format; seeSection 8.1.3. The actual number of digits generated depends only on the value being output, not on the value of this parameter. At most 17 digits are required forfloat8values, and 9 forfloat4values. This format is both fast and precise, preserving the original binary float value exactly when correctly read. For historical compatibility, values up to 3 are permitted.If the value is zero or negative, then the output is rounded to a given decimal precision. The precision used is the standard number of digits for the type (FLT_DIGorDBL_DIGas appropriate) reduced according to the value of this parameter. (For example, specifying -1 will causefloat4values to be output rounded to 5 significant digits, andfloat8values rounded to 14 digits.) This format is slower and does not preserve all the bits of the binary float value, but may be more human-readable.NoteThe meaning of this parameter, and its default value, changed inPostgreSQL12; seeSection 8.1.3for further discussion."
client_encoding,string,Sets the client-side encoding (character set). The default is to use the database encoding. The character sets supported by thePostgreSQLserver are described inSection 23.3.1.
lc_messages,string,"Sets the language in which messages are displayed. Acceptable values are system-dependent; seeSection 23.1for more information. If this variable is set to the empty string (which is the default) then the value is inherited from the execution environment of the server in a system-dependent way.On some systems, this locale category does not exist. Setting this variable will still work, but there will be no effect. Also, there is a chance that no translated messages for the desired language exist. In that case you will continue to see the English messages.Only superusers and users with the appropriateSETprivilege can change this setting."
lc_monetary,string,"Sets the locale to use for formatting monetary amounts, for example with theto_charfamily of functions. Acceptable values are system-dependent; seeSection 23.1for more information. If this variable is set to the empty string (which is the default) then the value is inherited from the execution environment of the server in a system-dependent way."
lc_numeric,string,"Sets the locale to use for formatting numbers, for example with theto_charfamily of functions. Acceptable values are system-dependent; seeSection 23.1for more information. If this variable is set to the empty string (which is the default) then the value is inherited from the execution environment of the server in a system-dependent way."
lc_time,string,"Sets the locale to use for formatting dates and times, for example with theto_charfamily of functions. Acceptable values are system-dependent; seeSection 23.1for more information. If this variable is set to the empty string (which is the default) then the value is inherited from the execution environment of the server in a system-dependent way."
icu_validation_level,enum,"When ICU locale validation problems are encountered, controls whichmessage levelis used to report the problem. Valid values areDISABLED,DEBUG5,DEBUG4,DEBUG3,DEBUG2,DEBUG1,INFO,NOTICE,WARNING,ERROR, andLOG.If set toDISABLED, does not report validation problems at all. Otherwise reports problems at the given message level. The default isWARNING."
default_text_search_config,string,"Selects the text search configuration that is used by those variants of the text search functions that do not have an explicit argument specifying the configuration. SeeChapter 12for further information. The built-in default ispg_catalog.simple, butinitdbwill initialize the configuration file with a setting that corresponds to the chosenlc_ctypelocale, if a configuration matching that locale can be identified."
local_preload_libraries,string,"This variable specifies one or more shared libraries that are to be preloaded at connection start. It contains a comma-separated list of library names, where each name is interpreted as for theLOADcommand. Whitespace between entries is ignored; surround a library name with double quotes if you need to include whitespace or commas in the name. The parameter value only takes effect at the start of the connection. Subsequent changes have no effect. If a specified library is not found, the connection attempt will fail.This option can be set by any user. Because of that, the libraries that can be loaded are restricted to those appearing in thepluginssubdirectory of the installation's standard library directory. (It is the database administrator's responsibility to ensure that only“safe”libraries are installed there.) Entries inlocal_preload_librariescan specify this directory explicitly, for example$libdir/plugins/mylib, or just specify the library name —mylibwould have the same effect as$libdir/plugins/mylib.The intent of this feature is to allow unprivileged users to load debugging or performance-measurement libraries into specific sessions without requiring an explicitLOADcommand. To that end, it would be typical to set this parameter using thePGOPTIONSenvironment variable on the client or by usingALTER ROLE SET.However, unless a module is specifically designed to be used in this way by non-superusers, this is usually not the right setting to use. Look atsession_preload_librariesinstead."
session_preload_libraries,string,"This variable specifies one or more shared libraries that are to be preloaded at connection start. It contains a comma-separated list of library names, where each name is interpreted as for theLOADcommand. Whitespace between entries is ignored; surround a library name with double quotes if you need to include whitespace or commas in the name. The parameter value only takes effect at the start of the connection. Subsequent changes have no effect. If a specified library is not found, the connection attempt will fail. Only superusers and users with the appropriateSETprivilege can change this setting.The intent of this feature is to allow debugging or performance-measurement libraries to be loaded into specific sessions without an explicitLOADcommand being given. For example,auto_explaincould be enabled for all sessions under a given user name by setting this parameter withALTER ROLE SET. Also, this parameter can be changed without restarting the server (but changes only take effect when a new session is started), so it is easier to add new modules this way, even if they should apply to all sessions.Unlikeshared_preload_libraries, there is no large performance advantage to loading a library at session start rather than when it is first used. There is some advantage, however, when connection pooling is used."
shared_preload_libraries,string,"This variable specifies one or more shared libraries to be preloaded at server start. It contains a comma-separated list of library names, where each name is interpreted as for theLOADcommand. Whitespace between entries is ignored; surround a library name with double quotes if you need to include whitespace or commas in the name. This parameter can only be set at server start. If a specified library is not found, the server will fail to start.Some libraries need to perform certain operations that can only take place at postmaster start, such as allocating shared memory, reserving light-weight locks, or starting background workers. Those libraries must be loaded at server start through this parameter. See the documentation of each library for details.Other libraries can also be preloaded. By preloading a shared library, the library startup time is avoided when the library is first used. However, the time to start each new server process might increase slightly, even if that process never uses the library. So this parameter is recommended only for libraries that will be used in most sessions. Also, changing this parameter requires a server restart, so this is not the right setting to use for short-term debugging tasks, say. Usesession_preload_librariesfor that instead.NoteOn Windows hosts, preloading a library at server start will not reduce the time required to start each new server process; each server process will re-load all preload libraries. However,shared_preload_librariesis still useful on Windows hosts for libraries that need to perform operations at postmaster start time."
jit_provider,string,"This variable is the name of the JIT provider library to be used (seeSection 30.4.2). The default isllvmjit. This parameter can only be set at server start.If set to a non-existent library,JITwill not be available, but no error will be raised. This allows JIT support to be installed separately from the mainPostgreSQLpackage."
dynamic_library_path,string,"If a dynamically loadable module needs to be opened and the file name specified in theCREATE FUNCTIONorLOADcommand does not have a directory component (i.e., the name does not contain a slash), the system will search this path for the required file.The value fordynamic_library_pathmust be a list of absolute directory paths separated by colons (or semi-colons on Windows). If a list element starts with the special string$libdir, the compiled-inPostgreSQLpackage library directory is substituted for$libdir; this is where the modules provided by the standardPostgreSQLdistribution are installed. (Usepg_config --pkglibdirto find out the name of this directory.) For example:dynamic_library_path = '/usr/local/lib/postgresql:/home/my_project/lib:$libdir'or, in a Windows environment:dynamic_library_path = 'C:\tools\postgresql;H:\my_project\lib;$libdir'The default value for this parameter is'$libdir'. If the value is set to an empty string, the automatic path search is turned off.This parameter can be changed at run time by superusers and users with the appropriateSETprivilege, but a setting done that way will only persist until the end of the client connection, so this method should be reserved for development purposes. The recommended way to set this parameter is in thepostgresql.confconfiguration file."
gin_fuzzy_search_limit,integer,Soft upper limit of the size of the set returned by GIN index scans. For more information seeSection 64.4.5.
deadlock_timeout,integer,"This is the amount of time to wait on a lock before checking to see if there is a deadlock condition. The check for deadlock is relatively expensive, so the server doesn't run it every time it waits for a lock. We optimistically assume that deadlocks are not common in production applications and just wait on the lock for a while before checking for a deadlock. Increasing this value reduces the amount of time wasted in needless deadlock checks, but slows down reporting of real deadlock errors. If this value is specified without units, it is taken as milliseconds. The default is one second (1s), which is probably about the smallest value you would want in practice. On a heavily loaded server you might want to raise it. Ideally the setting should exceed your typical transaction time, so as to improve the odds that a lock will be released before the waiter decides to check for deadlock. Only superusers and users with the appropriateSETprivilege can change this setting.Whenlog_lock_waitsis set, this parameter also determines the amount of time to wait before a log message is issued about the lock wait. If you are trying to investigate locking delays you might want to set a shorter than normaldeadlock_timeout."
max_locks_per_transaction,integer,"The shared lock table has space formax_locks_per_transactionobjects (e.g., tables) per server process or prepared transaction; hence, no more than this many distinct objects can be locked at any one time. This parameter limits the average number of object locks used by each transaction; individual transactions can lock more objects as long as the locks of all transactions fit in the lock table. This isnotthe number of rows that can be locked; that value is unlimited. The default, 64, has historically proven sufficient, but you might need to raise this value if you have queries that touch many different tables in a single transaction, e.g., query of a parent table with many children. This parameter can only be set at server start.When running a standby server, you must set this parameter to have the same or higher value as on the primary server. Otherwise, queries will not be allowed in the standby server."
max_pred_locks_per_transaction,integer,"The shared predicate lock table has space formax_pred_locks_per_transactionobjects (e.g., tables) per server process or prepared transaction; hence, no more than this many distinct objects can be locked at any one time. This parameter limits the average number of object locks used by each transaction; individual transactions can lock more objects as long as the locks of all transactions fit in the lock table. This isnotthe number of rows that can be locked; that value is unlimited. The default, 64, has historically proven sufficient, but you might need to raise this value if you have clients that touch many different tables in a single serializable transaction. This parameter can only be set at server start."
max_pred_locks_per_relation,integer,"This controls how many pages or tuples of a single relation can be predicate-locked before the lock is promoted to covering the whole relation. Values greater than or equal to zero mean an absolute limit, while negative values meanmax_pred_locks_per_transactiondivided by the absolute value of this setting. The default is -2, which keeps the behavior from previous versions ofPostgreSQL. This parameter can only be set in thepostgresql.conffile or on the server command line."
max_pred_locks_per_page,integer,This controls how many rows on a single page can be predicate-locked before the lock is promoted to covering the whole page. The default is 2. This parameter can only be set in thepostgresql.conffile or on the server command line.
array_nulls,boolean,"This controls whether the array input parser recognizes unquotedNULLas specifying a null array element. By default, this ison, allowing array values containing null values to be entered. However,PostgreSQLversions before 8.2 did not support null values in arrays, and therefore would treatNULLas specifying a normal array element with the string value“NULL”. For backward compatibility with applications that require the old behavior, this variable can be turnedoff.Note that it is possible to create array values containing null values even when this variable isoff."
backslash_quote,enum,"This controls whether a quote mark can be represented by\'in a string literal. The preferred, SQL-standard way to represent a quote mark is by doubling it ('') butPostgreSQLhas historically also accepted\'. However, use of\'creates security risks because in some client character set encodings, there are multibyte characters in which the last byte is numerically equivalent to ASCII\. If client-side code does escaping incorrectly then an SQL-injection attack is possible. This risk can be prevented by making the server reject queries in which a quote mark appears to be escaped by a backslash. The allowed values ofbackslash_quoteareon(allow\'always),off(reject always), andsafe_encoding(allow only if client encoding does not allow ASCII\within a multibyte character).safe_encodingis the default setting.Note that in a standard-conforming string literal,\just means\anyway. This parameter only affects the handling of non-standard-conforming literals, including escape string syntax (E'...')."
escape_string_warning,boolean,"When on, a warning is issued if a backslash (\) appears in an ordinary string literal ('...'syntax) andstandard_conforming_stringsis off. The default ison.Applications that wish to use backslash as escape should be modified to use escape string syntax (E'...'), because the default behavior of ordinary strings is now to treat backslash as an ordinary character, per SQL standard. This variable can be enabled to help locate code that needs to be changed."
lo_compat_privileges,boolean,"InPostgreSQLreleases prior to 9.0, large objects did not have access privileges and were, therefore, always readable and writable by all users. Setting this variable toondisables the new privilege checks, for compatibility with prior releases. The default isoff. Only superusers and users with the appropriateSETprivilege can change this setting.Setting this variable does not disable all security checks related to large objects — only those for which the default behavior has changed inPostgreSQL9.0."
quote_all_identifiers,boolean,"When the database generates SQL, force all identifiers to be quoted, even if they are not (currently) keywords. This will affect the output ofEXPLAINas well as the results of functions likepg_get_viewdef. See also the--quote-all-identifiersoption ofpg_dumpandpg_dumpall."
standard_conforming_strings,boolean,"This controls whether ordinary string literals ('...') treat backslashes literally, as specified in the SQL standard. Beginning inPostgreSQL9.1, the default ison(prior releases defaulted tooff). Applications can check this parameter to determine how string literals will be processed. The presence of this parameter can also be taken as an indication that the escape string syntax (E'...') is supported. Escape string syntax (Section 4.1.2.2) should be used if an application desires backslashes to be treated as escape characters."
synchronize_seqscans,boolean,"This allows sequential scans of large tables to synchronize with each other, so that concurrent scans read the same block at about the same time and hence share the I/O workload. When this is enabled, a scan might start in the middle of the table and then“wrap around”the end to cover all rows, so as to synchronize with the activity of scans already in progress. This can result in unpredictable changes in the row ordering returned by queries that have noORDER BYclause. Setting this parameter tooffensures the pre-8.3 behavior in which a sequential scan always starts from the beginning of the table. The default ison."
transform_null_equals,boolean,"When on, expressions of the formexpr= NULL(orNULL =expr) are treated asexprIS NULL, that is, they return true ifexprevaluates to the null value, and false otherwise. The correct SQL-spec-compliant behavior ofexpr= NULLis to always return null (unknown). Therefore this parameter defaults tooff.However, filtered forms inMicrosoft Accessgenerate queries that appear to useexpr= NULLto test for null values, so if you use that interface to access the database you might want to turn this option on. Since expressions of the formexpr= NULLalways return the null value (using the SQL standard interpretation), they are not very useful and do not appear often in normal applications so this option does little harm in practice. But new users are frequently confused about the semantics of expressions involving null values, so this option is off by default.Note that this option only affects the exact form= NULL, not other comparison operators or other expressions that are computationally equivalent to some expression involving the equals operator (such asIN). Thus, this option is not a general fix for bad programming.Refer toSection 9.2for related information."
allow_alter_system,boolean,"Whenallow_alter_systemis set tooff, an error is returned if theALTER SYSTEMcommand is executed. This parameter can only be set in thepostgresql.conffile or on the server command line. The default value ison.Note that this setting must not be regarded as a security feature. It only disables theALTER SYSTEMcommand. It does not prevent a superuser from changing the configuration using other SQL commands. A superuser has many ways of executing shell commands at the operating system level, and can therefore modifypostgresql.auto.confregardless of the value of this setting.Turning this setting off is intended for environments where the configuration ofPostgreSQLis managed by some external tool. In such environments, a well intentioned superuser mightmistakenlyuseALTER SYSTEMto change the configuration instead of using the external tool. This might result in unintended behavior, such as the external tool overwriting the change at some later point in time when it updates the configuration. Setting this parameter tooffcan help avoid such mistakes.This parameter only controls the use ofALTER SYSTEM. The settings stored inpostgresql.auto.conftake effect even ifallow_alter_systemis set tooff."
exit_on_error,boolean,"If on, any error will terminate the current session. By default, this is set to off, so that only FATAL errors will terminate the session."
restart_after_crash,boolean,"When set to on, which is the default,PostgreSQLwill automatically reinitialize after a backend crash. Leaving this value set to on is normally the best way to maximize the availability of the database. However, in some circumstances, such as whenPostgreSQLis being invoked by clusterware, it may be useful to disable the restart so that the clusterware can gain control and take any actions it deems appropriate.This parameter can only be set in thepostgresql.conffile or on the server command line."
data_sync_retry,boolean,"When set to off, which is the default,PostgreSQLwill raise a PANIC-level error on failure to flush modified data files to the file system. This causes the database server to crash. This parameter can only be set at server start.On some operating systems, the status of data in the kernel's page cache is unknown after a write-back failure. In some cases it might have been entirely forgotten, making it unsafe to retry; the second attempt may be reported as successful, when in fact the data has been lost. In these circumstances, the only way to avoid data loss is to recover from the WAL after any failure is reported, preferably after investigating the root cause of the failure and replacing any faulty hardware.If set to on,PostgreSQLwill instead report an error but continue to run so that the data flushing operation can be retried in a later checkpoint. Only set it to on after investigating the operating system's treatment of buffered data in case of write-back failure."
recovery_init_sync_method,enum,"When set tofsync, which is the default,PostgreSQLwill recursively open and synchronize all files in the data directory before crash recovery begins. The search for files will follow symbolic links for the WAL directory and each configured tablespace (but not any other symbolic links). This is intended to make sure that all WAL and data files are durably stored on disk before replaying changes. This applies whenever starting a database cluster that did not shut down cleanly, including copies created withpg_basebackup.On Linux,syncfsmay be used instead, to ask the operating system to synchronize the file systems that contain the data directory, the WAL files and each tablespace (but not any other file systems that may be reachable through symbolic links). This may be a lot faster than thefsyncsetting, because it doesn't need to open each file one by one. On the other hand, it may be slower if a file system is shared by other applications that modify a lot of files, since those files will also be written to disk. Furthermore, on versions of Linux before 5.8, I/O errors encountered while writing data to disk may not be reported toPostgreSQL, and relevant error messages may appear only in kernel logs.This parameter can only be set in thepostgresql.conffile or on the server command line."
block_size,integer,Reports the size of a disk block. It is determined by the value ofBLCKSZwhen building the server. The default value is 8192 bytes. The meaning of some configuration variables (such asshared_buffers) is influenced byblock_size. SeeSection 19.4for information.
data_checksums,boolean,Reports whether data checksums are enabled for this cluster. Seedata checksumsfor more information.
data_directory_mode,integer,On Unix systems this parameter reports the permissions the data directory (defined bydata_directory) had at server startup. (On Microsoft Windows this parameter will always display0700.) Seegroup accessfor more information.
debug_assertions,boolean,"Reports whetherPostgreSQLhas been built with assertions enabled. That is the case if the macroUSE_ASSERT_CHECKINGis defined whenPostgreSQLis built (accomplished e.g., by theconfigureoption--enable-cassert). By defaultPostgreSQLis built without assertions."
huge_pages_status,enum,"Reports the state of huge pages in the current instance:on,off, orunknown(if displayed withpostgres -C). This parameter is useful to determine whether allocation of huge pages was successful underhuge_pages=try. Seehuge_pagesfor more information."
integer_datetimes,boolean,"Reports whetherPostgreSQLwas built with support for 64-bit-integer dates and times. As ofPostgreSQL10, this is alwayson."
in_hot_standby,boolean,"Reports whether the server is currently in hot standby mode. When this ison, all transactions are forced to be read-only. Within a session, this can change only if the server is promoted to be primary. SeeSection 26.4for more information."
max_function_args,integer,Reports the maximum number of function arguments. It is determined by the value ofFUNC_MAX_ARGSwhen building the server. The default value is 100 arguments.
max_identifier_length,integer,"Reports the maximum identifier length. It is determined as one less than the value ofNAMEDATALENwhen building the server. The default value ofNAMEDATALENis 64; therefore the defaultmax_identifier_lengthis 63 bytes, which can be less than 63 characters when using multibyte encodings."
max_index_keys,integer,Reports the maximum number of index keys. It is determined by the value ofINDEX_MAX_KEYSwhen building the server. The default value is 32 keys.
segment_size,integer,Reports the number of blocks (pages) that can be stored within a file segment. It is determined by the value ofRELSEG_SIZEwhen building the server. The maximum size of a segment file in bytes is equal tosegment_sizemultiplied byblock_size; by default this is 1GB.
server_encoding,string,"Reports the database encoding (character set). It is determined when the database is created. Ordinarily, clients need only be concerned with the value ofclient_encoding."
server_version,string,Reports the version number of the server. It is determined by the value ofPG_VERSIONwhen building the server.
server_version_num,integer,Reports the version number of the server as an integer. It is determined by the value ofPG_VERSION_NUMwhen building the server.
shared_memory_size,integer,"Reports the size of the main shared memory area, rounded up to the nearest megabyte."
shared_memory_size_in_huge_pages,integer,"Reports the number of huge pages that are needed for the main shared memory area based on the specifiedhuge_page_size. If huge pages are not supported, this will be-1.This setting is supported only onLinux. It is always set to-1on other platforms. For more details about using huge pages onLinux, seeSection 18.4.5."
ssl_library,string,"Reports the name of the SSL library that thisPostgreSQLserver was built with (even if SSL is not currently configured or in use on this instance), for exampleOpenSSL, or an empty string if none."
wal_block_size,integer,Reports the size of a WAL disk block. It is determined by the value ofXLOG_BLCKSZwhen building the server. The default value is 8192 bytes.
wal_segment_size,integer,Reports the size of write ahead log segments. The default value is 16MB. SeeSection 28.5for more information.
allow_in_place_tablespaces,boolean,"Allows tablespaces to be created as directories insidepg_tblspc, when an empty location string is provided to theCREATE TABLESPACEcommand. This is intended to allow testing replication scenarios where primary and standby servers are running on the same machine. Such directories are likely to confuse backup tools that expect to find only symbolic links in that location. Only superusers and users with the appropriateSETprivilege can change this setting."
allow_system_table_mods,boolean,Allows modification of the structure of system tables as well as certain other risky actions on system tables. This is otherwise not allowed even for superusers. Ill-advised use of this setting can cause irretrievable data loss or seriously corrupt the database system. Only superusers and users with the appropriateSETprivilege can change this setting.
backtrace_functions,string,"This parameter contains a comma-separated list of C function names. If an error is raised and the name of the internal C function where the error happens matches a value in the list, then a backtrace is written to the server log together with the error message. This can be used to debug specific areas of the source code.Backtrace support is not available on all platforms, and the quality of the backtraces depends on compilation options.Only superusers and users with the appropriateSETprivilege can change this setting."
debug_discard_caches,integer,"When set to1, each system catalog cache entry is invalidated at the first possible opportunity, whether or not anything that would render it invalid really occurred. Caching of system catalogs is effectively disabled as a result, so the server will run extremely slowly. Higher values run the cache invalidation recursively, which is even slower and only useful for testing the caching logic itself. The default value of0selects normal catalog caching behavior.This parameter can be very helpful when trying to trigger hard-to-reproduce bugs involving concurrent catalog changes, but it is otherwise rarely needed. See the source code filesinval.candpg_config_manual.hfor details.This parameter is supported whenDISCARD_CACHES_ENABLEDwas defined at compile time (which happens automatically when using theconfigureoption--enable-cassert). In production builds, its value will always be0and attempts to set it to another value will raise an error."
debug_io_direct,string,"Ask the kernel to minimize caching effects for relation data and WAL files usingO_DIRECT(most Unix-like systems),F_NOCACHE(macOS) orFILE_FLAG_NO_BUFFERING(Windows).May be set to an empty string (the default) to disable use of direct I/O, or a comma-separated list of operations that should use direct I/O. The valid options aredatafor main data files,walfor WAL files, andwal_initfor WAL files when being initially allocated.Some operating systems and file systems do not support direct I/O, so non-default settings may be rejected at startup or cause errors.Currently this feature reduces performance, and is intended for developer testing only."
debug_parallel_query,enum,"Allows the use of parallel queries for testing purposes even in cases where no performance benefit is expected. The allowed values ofdebug_parallel_queryareoff(use parallel mode only when it is expected to improve performance),on(force parallel query for all queries for which it is thought to be safe), andregress(likeon, but with additional behavior changes as explained below).More specifically, setting this value toonwill add aGathernode to the top of any query plan for which this appears to be safe, so that the query runs inside of a parallel worker. Even when a parallel worker is not available or cannot be used, operations such as starting a subtransaction that would be prohibited in a parallel query context will be prohibited unless the planner believes that this will cause the query to fail. If failures or unexpected results occur when this option is set, some functions used by the query may need to be markedPARALLEL UNSAFE(or, possibly,PARALLEL RESTRICTED).Setting this value toregresshas all of the same effects as setting it toonplus some additional effects that are intended to facilitate automated regression testing. Normally, messages from a parallel worker include a context line indicating that, but a setting ofregresssuppresses this line so that the output is the same as in non-parallel execution. Also, theGathernodes added to plans by this setting are hidden inEXPLAINoutput so that the output matches what would be obtained if this setting were turnedoff."
ignore_system_indexes,boolean,Ignore system indexes when reading system tables (but still update the indexes when modifying the tables). This is useful when recovering from damaged system indexes. This parameter cannot be changed after session start.
post_auth_delay,integer,"The amount of time to delay when a new server process is started, after it conducts the authentication procedure. This is intended to give developers an opportunity to attach to the server process with a debugger. If this value is specified without units, it is taken as seconds. A value of zero (the default) disables the delay. This parameter cannot be changed after session start."
pre_auth_delay,integer,"The amount of time to delay just after a new server process is forked, before it conducts the authentication procedure. This is intended to give developers an opportunity to attach to the server process with a debugger to trace down misbehavior in authentication. If this value is specified without units, it is taken as seconds. A value of zero (the default) disables the delay. This parameter can only be set in thepostgresql.conffile or on the server command line."
trace_notify,boolean,"Generates a great amount of debugging output for theLISTENandNOTIFYcommands.client_min_messagesorlog_min_messagesmust beDEBUG1or lower to send this output to the client or server logs, respectively."
trace_sort,boolean,"If on, emit information about resource usage during sort operations. This parameter is only available if theTRACE_SORTmacro was defined whenPostgreSQLwas compiled. (However,TRACE_SORTis currently defined by default.)"
trace_locks,boolean,"If on, emit information about lock usage. Information dumped includes the type of lock operation, the type of lock and the unique identifier of the object being locked or unlocked. Also included are bit masks for the lock types already granted on this object as well as for the lock types awaited on this object. For each lock type a count of the number of granted locks and waiting locks is also dumped as well as the totals. An example of the log file output is shown here:LOG:  LockAcquire: new: lock(0xb7acd844) id(24688,24696,0,0,0,1)
      grantMask(0) req(0,0,0,0,0,0,0)=0 grant(0,0,0,0,0,0,0)=0
      wait(0) type(AccessShareLock)
LOG:  GrantLock: lock(0xb7acd844) id(24688,24696,0,0,0,1)
      grantMask(2) req(1,0,0,0,0,0,0)=1 grant(1,0,0,0,0,0,0)=1
      wait(0) type(AccessShareLock)
LOG:  UnGrantLock: updated: lock(0xb7acd844) id(24688,24696,0,0,0,1)
      grantMask(0) req(0,0,0,0,0,0,0)=0 grant(0,0,0,0,0,0,0)=0
      wait(0) type(AccessShareLock)
LOG:  CleanUpLock: deleting: lock(0xb7acd844) id(24688,24696,0,0,0,1)
      grantMask(0) req(0,0,0,0,0,0,0)=0 grant(0,0,0,0,0,0,0)=0
      wait(0) type(INVALID)Details of the structure being dumped may be found insrc/include/storage/lock.h.This parameter is only available if theLOCK_DEBUGmacro was defined whenPostgreSQLwas compiled."
trace_lwlocks,boolean,"If on, emit information about lightweight lock usage. Lightweight locks are intended primarily to provide mutual exclusion of access to shared-memory data structures.This parameter is only available if theLOCK_DEBUGmacro was defined whenPostgreSQLwas compiled."
trace_userlocks,boolean,"If on, emit information about user lock usage. Output is the same as fortrace_locks, only for advisory locks.This parameter is only available if theLOCK_DEBUGmacro was defined whenPostgreSQLwas compiled."
trace_lock_oidmin,integer,"If set, do not trace locks for tables below this OID (used to avoid output on system tables).This parameter is only available if theLOCK_DEBUGmacro was defined whenPostgreSQLwas compiled."
trace_lock_table,integer,Unconditionally trace locks on this table (OID).This parameter is only available if theLOCK_DEBUGmacro was defined whenPostgreSQLwas compiled.
debug_deadlocks,boolean,"If set, dumps information about all current locks when a deadlock timeout occurs.This parameter is only available if theLOCK_DEBUGmacro was defined whenPostgreSQLwas compiled."
log_btree_build_stats,boolean,"If set, logs system resource usage statistics (memory and CPU) on various B-tree operations.This parameter is only available if theBTREE_BUILD_STATSmacro was defined whenPostgreSQLwas compiled."
wal_consistency_checking,string,"This parameter is intended to be used to check for bugs in the WAL redo routines. When enabled, full-page images of any buffers modified in conjunction with the WAL record are added to the record. If the record is subsequently replayed, the system will first apply each record and then test whether the buffers modified by the record match the stored images. In certain cases (such as hint bits), minor variations are acceptable, and will be ignored. Any unexpected differences will result in a fatal error, terminating recovery.The default value of this setting is the empty string, which disables the feature. It can be set toallto check all records, or to a comma-separated list of resource managers to check only records originating from those resource managers. Currently, the supported resource managers areheap,heap2,btree,hash,gin,gist,sequence,spgist,brin, andgeneric. Extensions may define additional resource managers. Only superusers and users with the appropriateSETprivilege can change this setting."
wal_debug,boolean,"If on, emit WAL-related debugging output. This parameter is only available if theWAL_DEBUGmacro was defined whenPostgreSQLwas compiled."
ignore_checksum_failure,boolean,"Only has effect ifdata checksumsare enabled.Detection of a checksum failure during a read normally causesPostgreSQLto report an error, aborting the current transaction. Settingignore_checksum_failureto on causes the system to ignore the failure (but still report a warning), and continue processing. This behavior maycause crashes, propagate or hide corruption, or other serious problems. However, it may allow you to get past the error and retrieve undamaged tuples that might still be present in the table if the block header is still sane. If the header is corrupt an error will be reported even if this option is enabled. The default setting isoff. Only superusers and users with the appropriateSETprivilege can change this setting."
zero_damaged_pages,boolean,"Detection of a damaged page header normally causesPostgreSQLto report an error, aborting the current transaction. Settingzero_damaged_pagesto on causes the system to instead report a warning, zero out the damaged page in memory, and continue processing. This behaviorwill destroy data, namely all the rows on the damaged page. However, it does allow you to get past the error and retrieve rows from any undamaged pages that might be present in the table. It is useful for recovering data if corruption has occurred due to a hardware or software error. You should generally not set this on until you have given up hope of recovering data from the damaged pages of a table. Zeroed-out pages are not forced to disk so it is recommended to recreate the table or the index before turning this parameter off again. The default setting isoff. Only superusers and users with the appropriateSETprivilege can change this setting."
ignore_invalid_pages,boolean,"If set tooff(the default), detection of WAL records having references to invalid pages during recovery causesPostgreSQLto raise a PANIC-level error, aborting the recovery. Settingignore_invalid_pagestooncauses the system to ignore invalid page references in WAL records (but still report a warning), and continue the recovery. This behavior maycause crashes, data loss, propagate or hide corruption, or other serious problems. However, it may allow you to get past the PANIC-level error, to finish the recovery, and to cause the server to start up. The parameter can only be set at server start. It only has effect during recovery or in standby mode."
jit_debugging_support,boolean,"If LLVM has the required functionality, register generated functions withGDB. This makes debugging easier. The default setting isoff. This parameter can only be set at server start."
jit_dump_bitcode,boolean,"Writes the generatedLLVMIR out to the file system, insidedata_directory. This is only useful for working on the internals of the JIT implementation. The default setting isoff. Only superusers and users with the appropriateSETprivilege can change this setting."
jit_expressions,boolean,"Determines whether expressions are JIT compiled, when JIT compilation is activated (seeSection 30.2). The default ison."
jit_profiling_support,boolean,"If LLVM has the required functionality, emit the data needed to allowperfto profile functions generated by JIT. This writes out files to~/.debug/jit/; the user is responsible for performing cleanup when desired. The default setting isoff. This parameter can only be set at server start."
jit_tuple_deforming,boolean,"Determines whether tuple deforming is JIT compiled, when JIT compilation is activated (seeSection 30.2). The default ison."
remove_temp_files_after_crash,boolean,"When set toon, which is the default,PostgreSQLwill automatically remove temporary files after a backend crash. If disabled, the files will be retained and may be used for debugging, for example. Repeated crashes may however result in accumulation of useless files. This parameter can only be set in thepostgresql.conffile or on the server command line."
send_abort_for_crash,boolean,"By default, after a backend crash the postmaster will stop remaining child processes by sending themSIGQUITsignals, which permits them to exit more-or-less gracefully. When this option is set toon,SIGABRTis sent instead. That normally results in production of a core dump file for each such child process. This can be handy for investigating the states of other processes after a crash. It can also consume lots of disk space in the event of repeated crashes, so do not enable this on systems you are not monitoring carefully. Beware that no support exists for cleaning up the core file(s) automatically. This parameter can only be set in thepostgresql.conffile or on the server command line."
send_abort_for_kill,boolean,"By default, after attempting to stop a child process withSIGQUIT, the postmaster will wait five seconds and then sendSIGKILLto force immediate termination. When this option is set toon,SIGABRTis sent instead ofSIGKILL. That normally results in production of a core dump file for each such child process. This can be handy for investigating the states of“stuck”child processes. It can also consume lots of disk space in the event of repeated crashes, so do not enable this on systems you are not monitoring carefully. Beware that no support exists for cleaning up the core file(s) automatically. This parameter can only be set in thepostgresql.conffile or on the server command line."
debug_logical_replication_streaming,enum,"The allowed values arebufferedandimmediate. The default isbuffered. This parameter is intended to be used to test logical decoding and replication of large transactions. The effect ofdebug_logical_replication_streamingis different for the publisher and subscriber:On the publisher side,debug_logical_replication_streamingallows streaming or serializing changes immediately in logical decoding. When set toimmediate, stream each change if thestreamingoption ofCREATE SUBSCRIPTIONis enabled, otherwise, serialize each change. When set tobuffered, the decoding will stream or serialize changes whenlogical_decoding_work_memis reached.On the subscriber side, if thestreamingoption is set toparallel,debug_logical_replication_streamingcan be used to direct the leader apply worker to send changes to the shared memory queue or to serialize all changes to the file. When set tobuffered, the leader sends changes to parallel apply workers via a shared memory queue. When set toimmediate, the leader serializes all changes to files and notifies the parallel apply workers to read and apply them at the end of the transaction."
